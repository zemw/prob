[6.4.7]-[6.5.3] Exercises Markov chains

If G has 7 (< oo) edges, show that the stationary distribution is given by ty = dy/(2n), where dy is
the degree of vertex v.

7. Show that a random walk on the infinite binary tree is transient.

8. At each time n = 0,1,2,... a number Y, of particles enters a chamber, where {Y, : n > 0}
are independent and Poisson distributed with parameter 1. Lifetimes of particles are independent and
geometrically distributed with parameter p. Let X, be the number of particles in the chamber at time
n. Show that X is a Markov chain, and find its stationary distribution.

9. Arandom sequence of convex polygons is generated by picking two edges of the current polygon
at random, joining their midpoints, and picking one of the two resulting smaller polygons at random
to be the next in the sequence. Let X, +3 be the number of edges of the nth polygon thus constructed.
Find E(X;,) in terms of Xo, and find the stationary distribution of the Markov chain X.

10. Lets be a state of an irreducible Markov chain on the non-negative integers. Show that the chain
is persistent if there exists a solution y to the equations y; > }> jrjgts BipVjpt FS, satisfying yj —> oo.

11. Bow ties. A particle performs a random walk on a bow tie ABCDE drawn beneath on the left,
where C is the knot. From any vertex its next step is equally likely to be to any neighbouring vertex.
Initially it is at A. Find the expected value of:

(a) the time of first return to A,

(b) the number of visits to D before returning to A,

(c) the number of visits to C before returning to A,

(d) the time of first return to A, given no prior visit by the particle to E,

(e) the number of visits to D before returning to A, given no prior visit by the particle to E.

A D

A B

12. A particle starts at A and executes a symmetric random walk on the graph drawn above on the
right. Find the expected number of visits to B before it returns to A.

6.5 Exercises. Reversibility

1. A random walk on the set {0, 1,2, ..., b} has transition matrix given by pop = 1 — Ag. Pop =
1 — pp, Pig. = AG and pj41G = Mi4, forO <i < b, where 0 < Aj, 4; < 1 for all i, and
Ai + wy = 1 for 1 <i < b. Show that this process is reversible in equilibrium.

2. Kolmogorov’s criterion for reversibility. Let X be an irreducible non-null persistent aperiodic
Markov chain. Show that X is reversible in equilibrium if and only if

Pjy jo Pinj3°*° Pin-tinPiniy = PivinPinin-1*° Pini
for all n and all finite sequences j1, j2,..., jn of states.

3. Let X be a reversible Markov chain, and let C be a non-empty subset of the state space S. Define
the Markov chain Y on S by the transition matrix Q = (q;;) where

Bp ifie Candj ¢C,
ij = :
pi; — otherwise,

68

