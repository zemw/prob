[5.1.6]-[5.2.1] Solutions Generating functions and their applications

where p+q =1.

(ii) More generally, if each toss results in one of ¢ possible outcomes, the ith of which has probability
pi, then the corresponding quantity is a function of ¢ variables, x,,x2,...,x,, and is found to be
(pix, + poxe +-++ + prxt)”.

6. We have that

1— stl

’

1
B6%) = (es* |) = ft tus — Dy)" du =
0 n+1 l-s
the probability generating function of the uniform distribution. See also Exercise (4.6.5).
7. We have that

Gy y,z%, y,z7) =G,y,z,D = (xyz txey+yz+ezxtx+y4+z4+1)
= 3x + D504 D564) =GCx)Gy(Gz@,

whence X, Y, Z are independent. The same conclusion holds for any other set of exactly three random
variables. However, G(x, y, z, w) # Gy(x)Gy(y)Gz(z)Gw(w).

8. (a) We have by differentiating that E(X 2n) — 0, whence P(X = 0) = 1. This is not a moment
generating function.

(b) This is a moment generating function if and only if 5°, p- = 1, in which case it is that of a random
variable X with P(X = a;) = pr.

9. The coefficients of s” in both combinations of G;, G2 are non-negative and sum to 1. They are
therefore probability generating functions, as is G(as)/G(q) for the same reasons.

5.2 Solutions. Some applications
1. Let G(s) = E(s*) and Gs(s) = Lj=0 si S;. By the result of Exercise (5.1.2),

s(1-—G(s)) _ 1-sG)
l-s l-s °

[o@) [o.<)
T(s)= Do s™P(X =m) =14+5 > >s*P(X > WH =14

Now,

. m Xx ~ m x x
Gs(s) = So s"E =E{ Sos = E{(1+s)*} =G(1 4s)
m=0 m m=0 m

T(s)-T@) _ Gs(s — 1) ~ Gs(0)
Ss s—1
where we have used the fact that T(0) = Gs (0) = 1. Therefore

n n
Sos P(x > i) = Sos - 17155.
i=l j=l

so that

Equating coefficients of s‘—!, we obtain as required that
n j-1 .
P(X >i= S; -1)/7, l<i<n.
(X > i) (/71) ) Sin

232
