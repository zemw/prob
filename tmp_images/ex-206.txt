Functions of random variables Solutions [4.7.6]-[4.7.9]

where a = —tan7! (o/V1 _ p?) = —sin7! p-

6. We confine ourselves to the more interesting case when p # 1. Writing X = U, Y = pU +
V1 —*V, we have that U and V are independent N(0, 1) variables. It is easy to check that Y > X
if and only if (1 — p)U < ./1 — o2V. Turning to polar coordinates,

1.2
00 pe 3h woe ¥
E X,Yp= 6+ry/1—p? sind > do
(max{X, Y}) i on [/ {pr eos +r p* sin \ +f

C2 —n

rcosé ao] dr

where tan yy = ./(1 — e)/(1 + p). Some algebra yields the result. For the second part,
E(max{X, Y}?) = E(X7I{x>¥)) + EW? Iy>xy) = E(X* Ix cy}) + EP My <xy),

by the symmetry of the marginals of X and Y. Adding, we obtain 2E(max{X, Y}?) = E(x?) +
E(Y?) =2.
7. We have that

rs
P(X <¥, Z> 2 =P@<X <¥) =e OH = PX < Y)PCZ > 2).
a

Xr
a) P(X = Z) = PX < Y) = ——.
(a) P(X = Z) =P <¥) =
(b) By conditioning on Y,

thw for w > 0.

P(X -¥)+ =0) =P SY) =<, P((X ~Y)t >w)= sy

+

By conditioning on X,

P(V > v) = P(X -Y|> n= [ew > vtxdfxcnde+ [~ Po <x—v)fx(x)dx
v

_ pe” 4 pe HY

; v>0.
Ath

(c) By conditioning on X, the required probability is found to be

wax [* a a
| heg «f pe dydx = {e7M — eT HY.
0 t—x h-A

8. Either make a change of variables and find the Jacobian, or argue directly. With the convention
that /r2 — u2 = 0 when r2 — u2 < 0, we have that

x
F(x) =P(R <r, X <x) = - | Jaw du,
-r

a2 F or

f(x)= bran > pV a

9. As in the previous exercise,

|jxf<r <1.

z
P(R <1, Z<20= z/ nr? — w) dw.

—r

197
