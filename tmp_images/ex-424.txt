Stochastic calculus Solutions [13.7.1]-[13.7.5]

13.7 Solutions. Stochastic calculus
1. Let F = o(W, :0< u <s). Fixn > 1 and define X,(k) = | Wee 727 | forO < k < 2",
By Jensen’s inequality, the sequence {X,(k) : 0 < k < 2”} is a non-negative submartingale with

respect to the filtration ¥%;/2n , with finite variance. Hence, by Exercise (4.3.3) and equation (12.6.2),
Xx = max{Xn(k) : 0 < k < 2"} satisfies

ore) 0° XR
E(X*) = 2 [ xP(X* > x)dx <2 [ E(W;* Iry#>.)) dx = 2e{ w/t [ ax}
= 2E(W,* X nS 2y E(W2)E(X#2) by the Cauchy—Schwarz inequality.

Hence E(X*?) < 4E(W?). Now xe? is monotone increasing in n, and W has continuous sample
paths. By monotone convergence,

2\_ 1: «2 2
(max | We ) = lim E(X}?) < 4E(W?).

2. See the solution to Exercise (8.5.4).
3. (a) We have that

n—l n—l
Nn) = dopa — VP) —- SOV - yy}.
j=0 j=0

The first summation equals w?, by successive concellation, and the mean-square limit of the second
summation is ¢, by Exercise (8.5.4). Hence limy+o0 11 (”) = 5W? - st in mean square.
Likewise, we obtain the mean-square limits:

: 1 wy2 1 . : 1 y2

lim, Inn) = 5 Wr t at, pam, h(n) = wim, iy) = 3W/.

4. Clearly E(U(t)) = 0. The process U is Gaussian with autocovariance function
E(U(s)U(s +1) =E(E(U()UGs +1) | Fs)) = Pe P+ BW EPA?) = “FF,

Thus U is a stationary Gaussian Markov process, namely the Ornstein—Uhlenbeck process. [See
Example (9.6.10).]

5. Clearly E(U;) = 0. Fors <t,

S t
E(U;Us44) = E(WsW;) + B2E ( | ; | oe ue PE Wy du av)
us i

Ss t
-e(wis [ e PS) yw, au) - E(w, [ e Pl) yw, av)
0 0

Ss t
=s + preP St) | / eP UF) min{u, v} du dv
u=0 /v=0

S t

-— B i e PS) min{u, t}du — [ e PE-Y) min{s, v} dv
0 0

e2Bs _ |

e bCtt)

415

