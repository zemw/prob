6

Markov chains

6.1 Exercises. Markov processes

1. Show that any sequence of independent random variables taking values in the countable set S is
a Markov chain. Under what condition is this chain homogeneous?

2. Adie is rolled repeatedly. Which of the following are Markov chains? For those that are, supply
the transition matrix.

(a) The largest number X, shown up to the mth roll.

(b) The number N,, of sixes in n rolls.

(c) At time r, the time C, since the most recent six.

(d) At time r, the time B, until the next six.

3. Let {S, : 2 > 0} be a simple random walk with Sg = 0, and show that X, = |S,| defines a

Markov chain; find the transition probabilities of this chain. Let M, = max{S, : 0 < k <n}, and
show that Y, = My — Sy, defines a Markov chain. What happens if Sg 4 0?

4. Let X be a Markov chain and let {n; : r > 0} be an unbounded increasing sequence of positive
integers. Show that ¥, = X»y, constitutes a (possibly inhomogeneous) Markov chain. Find the
transition matrix of Y when ny = 2r and X is: (a) simple random walk, and (b) a branching process.

5. Let X be a Markov chain on S, and let J : S" — {0,1}. Show that the distribution of
Xn, Xn41,---, conditional on {7(X1,...,Xn) = 1} (Xn = 1}, is identical to the distribution
of Xn, Xn41,... conditional on {X, = i}.

6. Strong Markov property. Let X be a Markov chain on S, and let T be a random variable taking
values in {0, 1, 2, ... } with the property that the indicator function I;7—n}, of the event that T = n, is
a function of the variables X;, X2,..., Xn. Such a random variable T is called a stopping time, and
the above definition requires that it is decidable whether or not T = n with a knowledge only of the
past and present, Xg, X1,..., Xn, and with no further information about the future.

Show that
P(Xrim = j|X~ =x forO<k <T, Xp =i) =P(Xtim = Jj | X7 =i)

for m > 0, i, j € S, and all sequences (x;) of states.

7. Let X be a Markov chain with state space S, and suppose that h : § — T is one-one. Show that
Yn = h(Xn) defines a Markov chain on T. Must this be so if h is not one-one?

8. Let X and Y be Markov chains on the set Z of integers. Is the sequence Zy = Xn + Yn necessarily
a Markov chain?

9. Let X be a Markov chain. Which of the following are Markov chains?

64

