Large deviations Solutions [5.10.8]-[5.11.3]

by the result of Problem (5.12.18c), or by consulting a table of integrals. The required conclusion
follows by analytic continuation in the upper half-plane. See Moran 1968, p. 271.

8. (a) The sum Sp = 57)_, X, has characteristic function E(eitSn) = @(t)" = b(tn”), whence
Un = Sn/n has characteristic function ¢(tn) = E(e#"*1). Therefore,

P(Sn <¢) = P(X) <c)=P(X1 <=) +0 as n —> 00.

(b) E(e"7n) = b(t) = Ee**1).

9. (a) Yes, because X, is the sum of independent identically distributed random variables with
non-zero variance.

(b) It cannot in general obey what we have called the central limit theorem, because var(Xn) =
(n2 — n) var(@) + nE(©)(1 — E()) and n var(X;) = nE(©)(1 — E(@)) are different whenever
var(@) + 0. Indeed the right ‘normalization’ involves dividing by n rather than ./n. It may be shown
when var(@) # 0 that the distribution of X,/n converges to that of the random variable ©.

5.11 Solutions. Large deviations

1. We may write S, = >>] X; where the X; have moment generating function M(t) = 5(e +e-*),
Applying the large deviation theorem (5.11.4), we obtain that, for 0 < a < 1, P(S, > an)!/" >
inf,o{g(¢)} where g(t) = e~% M(t). Now g has a minimum when e’ = ./(1 +. a)/(1 — a), where
it takes the value 1/./(1 + a)!+4(1 — a)!~4 as required. If a > 1, then P(S, > an) = 0 for all n.

2. (i) Let Y, have the binomial distribution with parameters n and 5. Then 2Y, — n has the same
distribution as the random variable S, in Exercise (5.11.1). Therefore, if 0 < a < 1,

1

Pn —- jn > dan)'/” = P(S, > an)!/" 5 Jaratad sia’
a —a

and similarly for PY, — 5n <- 5an), by symmetry. Hence

4
Vd tayad ayia

tin = {2"P(|¥n — 5n| > dan)}1/" a

(ii) This time let S, = X,+--++Xy, the sum of independent Poisson variables with parameter 1. Then
T, = e"P(Sp, > n(1 + a)). The moment generating function of X; — 1 is M(t) = exp(e’ — 1 — 2),

and the large deviation theorem gives that tT; in, einf;,9{g(t)} where g(t) = e~% M(t). Now
g’(t) = (ef — a — 1) exp(e" — at — t — 1) whence g has a minimum at t = log(a + 1). Therefore
l/” _s eg(log(1 +.a)) = {e/(a + 1)}441.

3. Suppose that M(t) = E(e!*) is finite on the interval [—6, 6]. Now, fora > 0, M(6) > 6°? P(X >
a), so that P(X > a) < M(5)e~®¢. Similarly, P(X < —a) < M(—é)e~*4.
Suppose conversely that such A, jz exist. Then

M(t) < Eel) = | ell® d F(x)
[0,00)

where F is the distribution function of |X|. Integrate by parts to obtain
oO
M(t) <1+ [-el*[1 — F@)]]9° +f lle” [1 — F(x) dx
0

253
