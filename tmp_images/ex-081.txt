[6.9.1]-[6.9.8] Exercises Markov chains

6.9 Exercises. Continuous-time Markov chains

1. Let Ay > Oand let X be a Markov chain on {1, 2} with generator

_{-h om
c=(5' 4).
(a) Write down the forward equations and solve them for the transition probabilities p;;(¢), i, 7 =
1,2.
(b) Calculate G" and hence find 57°29 (t” /n!)}G". Compare your answer with that to part (a).

(c) Solve the equation #G = 0 in order to find the stationary distribution. Verify that p; jt) > 1;
ast > oo.

2. Asa continuation of the previous exercise, find:
(a) P(X@) =2| XO) =1, XBt) = 1),
(b) P(X(t) =2| XO) = 1, XBN = 1, X40 = 1).

3. Jobs arrive in a computer queue in the manner of a Poisson process with intensity A. The central
processor handles them one by one in the order of their arrival, and each has an exponentially distributed
runtime with parameter jz, the runtimes of different jobs being independent of each other and of the
arrival process. Let X(t) be the number of jobs in the system (either running or waiting) at time t,
where X(0) = 0. Explain why X is a Markov chain, and write down its generator. Show that a
stationary distribution exists if and only if A < y, and find it in this case.

4. Pasta property. Let X = {X(t) : t > 0} be a Markov chain having stationary distribution
wz. We may sample X at the times of a Poisson process: let N be a Poisson process with intensity
A, independent of X, and define Y, = X(T,+), the value taken by X immediately after the epoch
Ty of the nth arrival of N. Show that Y = {¥, : n > 0} is a discrete-time Markov chain with the
same stationary distribution as X. (This exemplifies the ‘Pasta’ property: Poisson arrivals see time
averages.)

[The full assumption of the independence of N and X is not necessary for the conclusion. It suffices
that {N(s) : s > t} be independent of {X(s) : s < 1}, a property known as ‘lack of anticipation’. It is
not even necessary that X be Markov; the Pasta property holds for many suitable ergodic processes. ]

5. Let X be a continuous-time Markov chain with generator G satisfying gj = —g;; > 0 for all i.
Let H4 = inf{t > 0: X(t) € A} be the hitting time of the set A of states, and let nj = P(H4 < 00 |
X(0) = j) be the chance of ever reaching A from j. By using properties of the jump chain, which
you may assume to be well behaved, show that }°, gjxng =O for j ¢ A.

6. In continuation of the preceding exercise, let 4; = E(H, | X(0) = j). Show that the vector
is the minimal non-negative solution of the equations

wy =O iffFEA, 14+D° gem =O iff EA.
keS

7. Let X be a continuous-time Markov chain with transition probabilities p;j(t) and define Fj =
inf{t > T, : X(t) = i} where 7; is the time of the first jump of X. Show that, if g;; ~ 0, then
P(F; < co | X(0) =i) = 1 if and only if i is persistent.

8. Let X be the simple symmetric random walk on the integers in continuous time, so that

Piit1 (2) = pii-1 (A) = Zan + off).

Show that the walk is persistent. Let T be the time spent visiting m during an excursion from 0. Find
the distribution of T.

72

