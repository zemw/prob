[6.15.1]-[6.15.7] Exercises Markov chains
(b) Let X and Y be discrete-time Markov chains with the same transition matrix P, and show that

So |P(Xn =k) -P(¥, =1| < dP)” So|P(Xo = & — P(X =).
k k

6.15 Problems

1. Classify the states of the discrete-time Markov chains with state space S = {1, 2,3, 4} and
transition matrices

(a) (b)

Oflenl—uje
O° Ne uN
of- OO
SNi= Oo O
Co rw ©
oo one
RP OONe
Oo Own ©

In case (a), calculate /4(n), and deduce that the probability of ultimate absorption in state 4, starting
from 3, equals 5. Find the mean recurrence times of the states in case (b).

2. A transition matrix is called doubly stochastic if all its column sums equal 1, thatis, if }7; pij = 1
for all j € S.

(a) Show that if a finite chain has a doubly stochastic transition matrix, then all its states are non-null
persistent, and that if it is, in addition, irreducible and aperiodic then p; j(n) > N —lasn — ov,
where N is the number of states.

(b) Show that, if an infinite irreducible chain has a doubly stochastic transition matrix, then its states
are either all null persistent or all transient.

3. Prove that intercommunicating states of a Markov chain have the same period.
4. (a) Show that for each pairi, 7 of states of an irreducible aperiodic chain, there exists N = N(i, j)
such that pj;j (1) > O for alln > N.

(b) Let X and Y be independent irreducible aperiodic chains with the same state space S and transition
matrix P. Show that the bivariate chain Z, = (Xn, Yn), n > 0, is irreducible and aperiodic.

(c) Show that the bivariate chain Z may be reducible if X and Y are periodic.

5. Suppose {Xy, : n > 0} is a discrete-time Markov chain with Xg = i. Let N be the total number
of visits made subsequently by the chain to the state 7. Show that

1— fi ifn =0,
P(N =”) = |
fig fp” -A—-fij) ifn>1,

and deduce that P(N = oo) = 1 if and only if fjj = fjj = 1.

6. Leti and j be two states of a discrete-time Markov chain. Show that if i communicates with /,
then there is positive probability of reaching j from i without revisiting i in the meantime. Deduce
that, if the chain is irreducible and persistent, then the probability f,; of ever reaching j from i equals
1 for alli and j.

7. Let {Xp : n > 0} bea persistent irreducible discrete-time Markov chain on the state space S with
transition matrix P, and let x be a positive solution of the equation x = xP.

(a) Show that
xj . .
qij (2) = ~ Pji(), i,jeS,n>1,
t

76
