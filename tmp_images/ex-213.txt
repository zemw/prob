{4.11.1]-[4.11.7] Solutions Continuous random variables

4.11 Solutions. Sampling from a distribution

1. Uniform on the set {1, 2,... , n}.
2. The result holds trivially when n = 2, and more generally by induction on n.

3. We may assume without loss of generality that A = 1 (since Z/A is (A, t) if Zis TC, t)). Let U,
V be independent random variables which are uniformly distributed on [0, 1]. We set X = —tlog V
and note that X has the exponential distribution with parameter 1/t. It is easy to check that

1
ro

xf 1p < cfx(x) for x > 0,

where c = t'e—'t!/ T(z). Also, conditional on the event A that

xt-le-t Xx
U < ——— te *!,
= "Fo
X has the required gamma distribution. This observation may be used as a basis for sampling using
the rejection method. We note that A = {log U < (n — 1) (log(X/n) — (X/n) + 1)}. We have that
P(A) = 1/c, and therefore there is a mean number c of attempts before a sample of size 1 is obtained.

4. Use your answer to Exercise (4.11.3) to sample X from (1, w) and Y from T'(1, B). By Exercise
(4.7.14), Z = X/(X + Y) has the required distribution.

5. (a) This is the beta distribution with parameters 2, 2. Use the result of Exercise (4).

(b) The required (1, 2) variables may be more easily obtained and used by forming X = — log(U, U2)
and Y — log(U3U4) where {U; : 1 <i < 4} are independent and uniform on [0, 1].

(c) Let U1, Uz, U3 be as in (b) above, and let Z be the second order statistic U2). That is, Z is the
middle of the three values taken by the U;; see Problem (4.14.21). The random variable Z has the
required distribution.

(d) As a slight variant, take Z = max{U,, U2} conditional on the event {Z < U3}.

(e) Finally, let X = /U/(./U) + /U2), ¥Y = /U, + /U3. The distribution of X, conditional on
the event {Y < 1}, is as required.

6. Weuse induction. The result is obvious when n = 2. Letn > 3 and let p = (pj, p2,-..., Pn) be
a probability vector. Since p sums to 1, its minimum entry pcj) and maximum entry pi») must satisfy

1 1 1— pay _ 1+(@—2)pqay . 1

<e- —— > .
PY Se? Pay + Pin) = Pay + n—-1 n-1 n-1

We relabel the entries of the vector p such that py = pj) and py = pin), and set vy = ((a- 1)py,1-
(n — 1)p1,0,...,0). Then

n-1l

—2 1
Pn-1 Where py] = 0, py + pz - ———
n—-1 n—-2 n—1

1 n
P= —TVW+
n—-1

Lasso +P)

is a probability vector with at most n — 1 non-zero entries. The induction step is complete.

It is a consequence that sampling from a discrete distribution may be achieved by sampling from
a collection of Bernoulli random variables.
7. Jtisanelementary exercise to show that P(R2 <)= im, and that, conditional on this event, the

vector (J,, T+) is uniformly distributed on the unit disk. Assume henceforth that R2 < 1, and write
(R, ©) for the point (7, T>) expressed in polar coordinates. We have that R and © are independent
with joint density function fr.@(7, 0) = r/x,0<r<1,0< 6 < 2. Let (Q, W) be the polar

204

