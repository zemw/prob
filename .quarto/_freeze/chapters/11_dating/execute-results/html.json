{
  "hash": "dbb33758fa0295b75deed5ad29e3797f",
  "result": {
    "engine": "knitr",
    "markdown": "# Optimal mating problem\\*\n\n**The question**\n\nHow many people should you date before you settle down with someone for\nmarriage? The answer is you should date 37% of your potential options\nand choose the next one who is better. [^11_dating-1]\n\n[^11_dating-1]: See [Kissing the frog: A mathematician's guide to\n    mating](https://plus.maths.org/content/kissing-frog-mathematicians-guide-mating-0)\n    and [Strategic dating: The 37%\n    rule](https://plus.maths.org/content/mathematical-dating) for\n    reference.\n\n::: callout-note\n## The 37% rule\n\nThe 37% Rule, also known as the **Optimal Stopping Theory**, provides a\nstrategy to maximize the chances of making the best choice when faced\nwith a sequence of options where decisions are irreversible. It suggests\nthat you should review and reject the first 37% of the total options\nwithout selecting any, then choose the next option that is better than\nall those previously considered.\n:::\n\n**Mathematical framework**\n\nLet's assume there's a pool of $N$ people out there from which you are\nchoosing. We'll also assume that you have a clear-cut way of rating\npeople. You know who is the best to be your partner. We will call that\nperson Mr/Ms $X$. \nThe people that you will meet show up one by one in random order. $X$ may\nshow up anywhere in the sequence. Sadly, a person you have dated and\nthen rejected isn't available to you any longer later on. So you cannot\ndate all of them and pick the best one.\n\nYour dating strategy is to date $M$ of the $N$ people and then settle\nwith the next person who is better. Our task is to find the optimal $M$.\nIf $M$ is too small, you will likely land with someone before $X$ shows\nup. If $M$ is too large, $X$ will likely pass $X$ and pick someone less\noptimal. Of course, there is no perfect solution. We want to find the\n$M$ that maximizes the probability of landing $X$.\n\nLet $P(M,N)$ be the probability of successfully picking $X$ if you date\n$M$ people out of $N$ and then go for the next person who is better than\nthe previous ones. \nLet $S$ be the event of successfully picking $X$, and $X_j$ means $X$ is\nin the $j$th position in the sequence.\nThe overall probability is: \n$$P(M,N) = P(S|X_1)P(X_1)+P(S|X_2)P(X_2)+\\cdots+P(S|X_n)P(X_n)$$\n\nFor a given value of $M$, if $X$ is among the first $M$ people you date,\nthen you have missed your chance. The probability of settling with $X$ is\nzero. Therefore, the first $M$ terms are all zero.\n\nIf $X$ is in $M+1$, you're in luck: since $X$ is better than all others so\nfar, you will pick $X$ for sure. Therefore,\n$$P(S|X_{M+1})P(X_{M+1}) = 1\\cdot P(X_{M+1})= \\frac{1}{N}$$\nSince\n$X$ is equally likely to be in any position, the probability of $X$ being in\n$M+1$ out of $N$ people is $1/N$.\n\nIf $X$ is in $M+2$, you'll pick him/her up as long as the $(M+1)$st person\ndidn't have a higher rating than all the previous $M$ people. \nIn other words, you would pass the $(M+1)$st person and pick $X$ if the best \none out of the $(M+1)$ people has shown up among the first $M$ people. \nThe change is $M/(M+1)$. Thus,\n$$\nP(S|X_{M+2})P(X_{M+2})=\\frac{M}{M+1}\\frac{1}{N}\n$$\n\nSimilarly, if $X$ shows up in $M+3$, you'll pick him/her up to as long\nas neither the $(M+1)$st nor the $(M+2)$nd person have a higher rating than all\nthe previous $M$ people. \nIn other words, the best one out of the first $(M+2)$ people has to show up\namong the first $M$ people. The chance is $M/(M+2)$. Thus,\n\n$$\nP(S|X_{M+3})P(X_{M+3})=\\frac{M}{M+2}\\frac{1}{N}\n$$\n\nPutting them all together, we have\n$$\n\\begin{aligned}\nP(M,N) &=\\frac{1}{N} +\\frac{M}{N(M+1)} +\\frac{M}{N(M+2)}+\\dots +\\frac{M}{N(N-1)}\\\\\n&= \\frac{M}{N}\\left(\\frac{1}{M}+\\frac{1}{M+1} +\\frac{1}{M+2}+\\dots+\\frac{1}{N-1}\\right)\n\\end{aligned}\n$$\n\n**Maximizing your chance of success**\n\nAssuming $P(M,N)$ is strictly concave (fortunately this is the case), \nthe $M$ the maximizes the chance satisfies\n$$\nP(M-1,N) < P(M,N) \\text{ and } P(M+1,N) < P(M,N)\n$$\n\nWe can ask the computer to find the solution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 100\np <- sapply(1:(N-1), function(m) m/N*sum(1/seq(m, N-1)))\nplot(1:(N-1), p, type=\"l\")\n```\n\n::: {.cell-output-display}\n![](11_dating_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nFor $N=100$, the highest probability if achieved at $M=37$.\n\n**The limiting solution**\n\nWe can find the solution analytically if $M,N$ are large. For large $n$,\nthe harmonic sequence can be approximated by the logarithm function:\n$$\nH_n=1+\\frac{1}{2}+\\frac{1}{3}+\\dots+\\frac{1}{n}\\approx \\ln(n)+\\gamma\n$$\nwhere $\\gamma$ is a constant. \n\nWe rewrite the function $P(M,N)$ as\n$$\nP(M,N)\n=\\sum_{k=M}^{N-1}\\frac{M}{N}\\cdot\\frac{1}{k}\n=\\frac{M}{N}\\sum_{k=M}^{N-1}\\frac{1}{k}\n=\\frac{M}{N}\\Big(H_{N-1}-H_{M-1}\\Big)\n$$\n\nFor large $M$ and $N$, it is approximated by\n$$\nP(M,N)=\\frac{M}{N}(H_{N-1}-H_{M-1})\\approx\n  \\frac{M}{N}\\left[\\ln(N-1)-\\ln(M-1)\\right]\\approx\n  \\frac{M}{N}\\ln\\left(\\frac{N}{M}\\right)\n$$\n\nLet $x=\\frac{M}{N}\\in(0,1)$. We want to maximize\n$$\nf(x)=x\\ln\\left(\\frac{1}{x}\\right)= -x\\ln x\n$$\n\nDifferentiate:\n$$\nf'(x)=\\ln\\left(\\frac{1}{x}\\right)-1=-\\ln x -1\n$$\n\nSet $f'(x)=0 \\Rightarrow -\\ln x -1=0 \\Rightarrow \\ln x=-1 \\Rightarrow x=e^{-1}.$\nSecond derivative $f''(x)=-1/x<0$, so itâ€™s a maximum.\n\nTherefore, the maximizing fraction satisfies\n$$\n\\frac{M^\\star}{N}\\;\\longrightarrow\\;\\frac{1}{e}\\quad\\text{as }N\\to\\infty,\n$$\n\nand the maximal success probability tends to\n$$\nf(1/e)=\\frac{1}{e}.\n$$",
    "supporting": [
      "11_dating_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}