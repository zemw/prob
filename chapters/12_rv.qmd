# What is a random variable?

In the previous chapter, we have been working with *events*, which is a
conceptualization of real world outcomes occurred with probabilities. In
this chapter, we introduce a much more powerful conceptualization that
deals with uncertain outcomes --- random variables, which is the
foundation of all probability and statistical studies.

In high school, all mathematical models come with certainty. For
example, the falling time of any object from height $h$ down to the
earth is: $t=\sqrt{2h/g}$, where $g$ is the gravity constant.
The outcome is *deterministic*. The variables that enter into the
equation either have unknown values or known certain values. Errors are
possible only due to frictions or measurement errors.

But many real world processes come naturally with uncertainty. Think
about the temperature tomorrow, or the stock market returns. We can only
make predictions with probabilities. Yes, you may argue this uncertainly
is due to incomplete information. If we have all the knowledge regarding
the climate, we can predict exactly the temperature. But given the
imperfection of the human knowledge, the only feasible option is to
build this uncertainly into our mathematical models. Random variable is
core concept and the Swiss knife that we use to deal with uncertainties
mathematically.

Informally, a random variable differs from a normal variable as it is
"random".

> A random variable is a variable whose value is uncertain, but comes
> with probabilities.

A random variable, say $X$, is never associated with a certain value,
such as $X=1$, or $X=2$. It could be any of these values, but with
different probabilities, say, $X$ takes the value 1 with probability 0.4, and
takes the value 2 with probability 0.3. 
The formal definition of a random variable is as follows.

::: {#def-rv}
## Random variable
Given an experiment with sample space $S$, a random variable is a
function from the sample space $S$ to the real numbers $\mathbb{R}$.
:::

As an example, flipping a coin twice, let $X$ be the number of heads.
Then $X(\cdot)$ is a functions that maps events in
$\left\{ HH,HT,TH,TT\right\}$ into real numbers. In our case, the
mapping goes like $$\begin{aligned}
X(HH) & =2,X(HT)=1,X(TH)=1,X(TT)=0.\end{aligned}$$ $X$ is therefore an
[encoding]{.underline} of events in the sample space into real numbers.
We could, of course, have different encodings. Conder the random
variable $Y$ as the number of tails. Then we have $Y=2-X$.
$$\begin{aligned}
Y(HH) & =0,Y(HT)=1,Y(TH)=2,Y(TT)=2.\end{aligned}$$ We could also define
$Z$ as the number heads in the 1st toss only. The encoding goes like
$$Z(HH)=1,Z(HT)=1,Z(TH)=0,Z(TT)=0.$$ We have listed three ways of
"encoding" the same experiment as random variables. All of them are
valid random variables, but they map the outcomes into different
numbers. We can say that, a random variable is a [numeric]{.underline}
"summary" of an aspect of an experiment.

::: callout-note
### Notation for random variables
We usually use capital letters, such as $X,Y,Z$, to denote random
variables. We use small letters, such as $x,y,z$, to denote specific
values. $P(X=x)$ means the probability of $X$ taking the value $x$.
Don't confuse the random variable $X$ with the number $x$.
:::

::: callout-note
### Don't confuse random variables, numbers, and events
Random variables are never fixed numbers. Functions of random variables, 
such as $X^2$, $|X|$, $e^X$, are also random variables. 
Random variables are not events. It does not make sense to write $P(X)$, 
because $X$ is not an event. But $X=a$ is an event, it makes sense to 
write $P(X=a)$.
:::

::: {#def-dist}
## Distribution
Let $X$ be a random variable. The distribution of $X$ is the
collection of all probabilities of the form $P(X\in C)$ for all sets $C$
of real numbers such that $\left\{ X\in C\right\}$ is an event.
:::

A distribution specifies the probabilities associated with
[all]{.underline} values of a random variable. In the above example, the
distribution of $X$ is given by
$$P(X=0)=\frac{1}{4},P(X=1)=\frac{1}{2},P(X=2)=\frac{1}{4}.$$ The
distribution of $Y$ is given by
$$P(Y=0)=\frac{1}{4},P(Y=1)=\frac{1}{2},P(Y=2)=\frac{1}{4}.$$ The
distribution of $Z$ is given by
$$P(Z=0)=\frac{1}{2},P(Z=1)=\frac{1}{2}.$$

You may have noted that the probabilities in a distribution always sums
up to $1$, as all possible events constitute the entire sample space.

::: callout-note
## Specifying the distribution
Listing all the values is not a smart way to specify a distribution.
We like to use a function (if possible),  such as $f(x) \overset{?}{=} e^{-x}$, 
to specify the probability of a random variable $X$ taking the value $x$. 
This is convenient, because once we know the function, we know all the probabilities.
But how to specify this function depends on whether a random variable 
is discrete or continuous.
:::
