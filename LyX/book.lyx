#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\usepackage{xurl}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams-chap-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\noun on
Introduction to Probability
\end_layout

\begin_layout Author

\noun on
Z.m.
 Wang
\noun default

\begin_inset Foot
status open

\begin_layout Plain Layout
Research Institute of Economics and Management (RIEM), Southwest University
 of Finance and Economics, Chengdu, China.
 Email: zwang@swufe.edu.cn.
\end_layout

\end_inset


\end_layout

\begin_layout Date
1st Edition
\end_layout

\begin_layout Address
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Formula $\varcopyright$
\end_inset

 All rights reserved.
 No portion of this manuscript may be reproduced, distributed, or transmitted
 in any form or by any means without the prior written permission of the
 author.
 This manuscript is a preliminary edition.
 While efforts have been made to ensure its content is accurate, no warranty
 is made regarding its quality or correctness.
 Readers are encouraged to report any typographical errors or inaccuracies
 to the author for correction.
 The manuscript may also contain citations that have not been properly acknowled
ged, which will be addressed in future editions.
\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
Preface
\end_layout

\begin_layout Standard
Embarking on the study of probability is both an opportunity and a challenge.
 This course represents a critical foundation for all subsequent studies
 in econometrics and data science.
 As we navigate an era of big data and artificial intelligence, proficiency
 in probability theory is indispensable.
 It not only builds the foundations for higher level courses but also cultivates
 a mindset geared towards probabilistic reasoning, which is essential for
 mitigating cognitive biases and making more informed decisions.
 Human cognition is often not well-equipped to handle probabilistic thinking.
 As we will see, human intuition and heuristics are mostly wrong about probabili
stic events.
 This course seeks to provide a mathematical framework for properly understandin
g and applying probability.
\end_layout

\begin_layout Standard
Probability theory is more than just a mathematical discipline; it is a
 vital tool for making sense of uncertainty in the real world.
 Consider the myriad of questions that we encounter daily: Will it rain
 tomorrow? What is the expected return on an investment? What are the odds
 of a particular political party winning an election? How can a business
 optimize its customer service strategy when customer arrival times are
 unpredictable? Probability theory provides a scientific approach to answering
 these questions, enabling us to model and analyze uncertainties with mathematic
al tools.
 
\end_layout

\begin_layout Standard
However, this journey is not without its difficulties.
 For freshmen, particularly those new to calculus and linear algebra, the
 course presents a steep learning curve.
 The breadth of new concepts—such as random variables, expectations, and
 various distributions—can be overwhelming if encountered for the first
 time.
 Additionally, the use of advanced calculus, particularly integrals, may
 pose challenges for those who are still familiarizing themselves with these
 mathematical tools.
\end_layout

\begin_layout Standard
Despite these challenges, the rewards of studying probability are substantial.
 Gaining a deep understanding of probability will not only enhance your
 knowledge base but also fundamentally transform your approach to problem-solvin
g.
 The principles you will learn are applicable to a wide range of fields
 beyond econometrics and data science, including engineering, finance, and
 social sciences.
 You will learn the tools to approach these problems systematically and
 make informed decisions based on statistical evidence and probability.
 So be prepared for a challenging and rewarding journey!
\end_layout

\begin_layout Paragraph*
Learning objectives
\end_layout

\begin_layout Itemize

\series bold
Review fundamental concepts:
\series default
 Revisit the probability and calculus concepts learned in high school to
 ensure a solid foundation for more advanced topics.
 
\end_layout

\begin_layout Itemize

\series bold
Understand core probability theory:
\series default
 Gain a thorough understanding of key concepts and theorems in probability
 theory, including random variables, expectations, covariances, and so on.
 
\end_layout

\begin_layout Itemize

\series bold
Develop probabilistic thinking:
\series default
 Learn to approach problems with a probabilistic mindset and use random
 variables to describe and analyze uncertain outcomes.
 
\end_layout

\begin_layout Itemize

\series bold
Model real-world events:
\series default
 Identify and apply important probability distributions to model and interpret
 real-world phenomena effectively.
 
\end_layout

\begin_layout Itemize

\series bold
Enjoy and have fun:
\series default
 Discover and appreciate the inherent elegance of mathematics and the beauty
 of probability theory.
\end_layout

\begin_layout Paragraph*
Study tips for new college students
\end_layout

\begin_layout Itemize

\series bold
Limit electronic distractions:
\series default
 While digital tools like slides and tablets are convenient, traditional
 paper and pencil methods remain the most effective way to engage with and
 learn mathematics.
 Writing out problems and solutions helps reinforce concepts and improve
 retention.
 
\end_layout

\begin_layout Itemize

\series bold
Focus on key concepts:
\series default
 College courses are often much more intensive than high school classes,
 and it is not feasible to master every detail.
 Concentrate on understanding the core ideas and principles, and don’t get
 overwhelmed by the technical details.
 
\end_layout

\begin_layout Itemize

\series bold
Understand the “why”:
\series default
 In mathematics, understanding the underlying reasons and logic behind methods
 is more important than just knowing how to do computations.
 The “why” helps you grasp the broader implications and applications of
 the techniques you learn.
\end_layout

\begin_layout Itemize

\series bold
Gain practical experience:
\series default
 Although this course emphasizes theoretical understanding and does not
 require programming, experimenting with statistical software such as R
 can be highly beneficial.
 Practical experience with data manipulation and analysis will enhance your
 comprehension and stimulate interest in the subject.
 
\end_layout

\begin_layout Itemize

\series bold
Engage with the material:
\series default
 I will strive to make the course engaging and less boring.
 However, if this course is not your primary interest, focus on the aspects
 of the material that intrigue you.
 Try to have a general impression of the major concepts even though you
 do not remember any detail.
\end_layout

\begin_layout Itemize

\series bold
Exams are important, but more important is to enjoy the course.
 
\end_layout

\begin_layout Standard
This content of this book is organized or follows.
 We start with probabilities based on counting, which should be familiar
 to high school graduates.
 Though rudimentary, they often yield surprising results, as rigorous calculatio
ns frequently challenge our intuitions about the likelihood of events.
 Special emphasis is placed on conditional probability, as conditional thinking
 is crucial both in academic studies as well as in daily life.
\end_layout

\begin_layout Standard
Next, we introduce the core concept of the random variable, which forms
 the foundation of all probability distributions and statistical theory.
 Random variables are essential tools that allow us to mathematically model
 uncertainty.
 We introduce two types of random variables: discrete and continuous.
 We begin with discrete random variables because they do not require calculus,
 offering a smoother learning curve for beginners.
 Key concepts such as expectations, variance, and covariance are introduced
 alongside well-known discrete distributions such as the Binomial, Geometric,
 and Poisson distributions.
 This arrangement ensures that students can grasp these important concepts
 without being overwhelmed by calculus.
 We also demonstrate how these fundamental distributions can be applied
 to solve real-world problems.
 
\end_layout

\begin_layout Standard
Following this, we move on to continuous distributions.
 We will see that the formulas from discrete distributions extend naturally
 to continuous distributions with the aid of calculus—essentially replacing
 summation with integration.
 We cover some of the most important continuous distributions, such as the
 Normal, Exponential, and Gamma distributions, and explore the interconnections
 between them.
 We also extend the concepts of expectations, variance, and joint distributions
 to their continuous forms.
\end_layout

\begin_layout Standard
The book concludes with a discussion on sampling and statistical inference.
 Since we cannot observe entire distribution, it becomes necessary to infer
 distribution properties from finite samples.
 We introduce two of the most important theorems in probability and statistical
 theory—the Law of Large Numbers and the Central Limit Theorem.
 The breadth and generality of these theorems are remarkable.
 But their most significant contribution to statistical applications is
 they allow us to gauge how close our sample estimates are to the true parameter
 values.
 The final chapter also includes a brief discussion on estimator accuracy,
 confidence intervals, and hypothesis testing.
 These topics are introduced briefly, as they serve primarily to prepare
 students for more advanced courses, such as econometrics.
\end_layout

\begin_layout Standard
The chapters are organized logically, with each chapter building on the
 knowledge presented in the previous ones.
 Therefore, it is recommended to follow the sequence of chapters rather
 than reading them independently.
 However, advanced readers who are already familiar with the topics may
 feel free to skip between chapters as needed.
 This manuscript is written tersely, serving as a skeleton to complement
 lecture materials.
 It is not intended as a substitute for lectures or comprehensive textbooks.
 Students who wish to learn the course material solely by reading are encouraged
 to consult a formal textbook.
\end_layout

\begin_layout Standard
This manuscript is a preliminary version, and while efforts have been made
 to ensure accuracy, errors may still be present.
 Your feedback on any mistakes or inaccuracies is greatly appreciated and
 will help improve the material.
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Probability Basics
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\align center

\emph on
Probability is the most important concept in modern science, especially
 as nobody has the slightest notion of what it means.
 ——Bertrand Russell 
\end_layout

\begin_layout Standard
What is probability? We all talk about probabilities in everyday life, but
 mostly in vague languages.
 This course is to introduce probability as a logical framework for quantifying
 uncertainty and randomness.
 
\end_layout

\begin_layout Standard

\bar under
Mathematics is the logic of certainty; probability is the logic of uncertainty.
 
\end_layout

\begin_layout Standard
The earliest development of probability is rooted in gambling.
 For instance, the renowned Monte Carlo method in statistics, invented by
 Stanislaw Ulam in the late 1940s, takes its name from the 
\emph on
Monte Carlo Casino
\emph default
 in Monaco, where Ulam's uncle would borrow money from relatives to gamble.
 Probability theories still apply today to analyze gambling odds, but their
 applications have expanded to nearly every field.
 It is the foundation of statistics, machine learning, and artificial intelligen
ce.
 It also plays a crucial role in everyday decision-making, from stock investment
s to effective strategies to combat an infectious disease.
\end_layout

\begin_layout Standard
Probability is a concept that is intuitive to understand but very hard to
 define formally.
 Perhaps, the first formal definition of probability is often attributed
 to Pierre-Simon Laplace in the 18th century.
 In his work "Théorie analytique des probabilités," published in 1812, 
\end_layout

\begin_layout Quotation
The probability of an event is the ratio of the number of cases favorable
 to it, to the number of all cases possible when nothing leads us to expect
 that any one of these cases should occur more than any other, which renders
 them, for us, equally possible.
\end_layout

\begin_layout Standard
This definition is outdated, as we will soon discover.
 But before we explore the modern definition of probability, let's first
 clarify some preliminary concepts (based on sets), which is the mathematical
 language we use to describe probabilistic events.
\end_layout

\begin_layout Section
Events and sample spaces
\end_layout

\begin_layout Standard
The mathematical framework for probability is built around sets (like the
 cases in other math subjects as well).
 
\end_layout

\begin_layout Definition
The 
\series bold
sample space
\series default
 
\begin_inset Formula $S$
\end_inset

 of an experiment is the set of all possible outcomes of the experiment.
 An 
\series bold
event
\series default
 
\begin_inset Formula $A$
\end_inset

 is a subset of the sample space 
\begin_inset Formula $S$
\end_inset

.
 We say 
\begin_inset Formula $A$
\end_inset

 occurred if the actual outcome is in 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Standard
An experiment can be understood loosely.
 Anything (a gamble, an exam, a financial year, ...) can be an experiment.
 The sample space can be finite, countably infinite, or uncountably infinite.
 It is convenient to visualize events in a 
\series bold
Venn diagram
\series default
.
 
\end_layout

\begin_layout Standard
Set theory provides a rich language for expressing and working with events.
 Set operations, especially unions, intersections, and complements, make
 it easy to build new events in terms of already-deﬁned events.
 For example, let 
\begin_inset Formula $S$
\end_inset

 be the sample space of an experiment and let 
\begin_inset Formula $A,B\subseteq S$
\end_inset

 be events.
 Then the union 
\begin_inset Formula $A\cup B$
\end_inset

 is the event that occurs if and only if at least one of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 occurs, the intersection 
\begin_inset Formula $A\cap B$
\end_inset

 is the event that occurs if and only if both 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 occur, and the complement 
\begin_inset Formula $A^{c}$
\end_inset

 is the event that occurs if and only if 
\begin_inset Formula $A$
\end_inset

 does not occur.
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Coin flips
\end_layout

\end_inset

A coin is flipped twice.
 We write 
\begin_inset Quotes eld
\end_inset

H
\begin_inset Quotes erd
\end_inset

 if a coin lands Head, and 
\begin_inset Quotes eld
\end_inset

T
\begin_inset Quotes erd
\end_inset

 if a coin lands Tail.
 The sample space is the set of all possible outcomes.
 Therefore, 
\begin_inset Formula $S=\left\{ HH,HT,TH,TT\right\} $
\end_inset

.
 Let's look at some events:
\end_layout

\begin_layout Enumerate
Let 
\begin_inset Formula $A_{1}$
\end_inset

 be the event that the first flip is Heads.
 Then 
\begin_inset Formula $A_{1}=\left\{ HH,HT\right\} $
\end_inset

.
 Let 
\begin_inset Formula $A_{2}$
\end_inset

 be the event that the second flip is Heads.
 Then 
\begin_inset Formula $A_{2}=\left\{ HH,TH\right\} $
\end_inset

.
\end_layout

\begin_layout Enumerate
Let 
\begin_inset Formula $B$
\end_inset

 be the event that at least one flip is Heads.
 Then 
\begin_inset Formula $B=A_{1}\cup A_{2}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Let 
\begin_inset Formula $C$
\end_inset

 be the event that all the flips are Heads.
 Then 
\begin_inset Formula $C=A_{1}\cap A_{2}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Let 
\begin_inset Formula $D$
\end_inset

 be the event that no flip is Heads.
 Then 
\begin_inset Formula $D=B^{c}$
\end_inset

.
\end_layout

\begin_layout Standard
Here is a list of events described in both English and set notations.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
English
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sets
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
sample space
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $S$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset

 is a possible outcome
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s\in S$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 is an event
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A\subseteq S$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 occurred
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s_{\textrm{actual}}\in A$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 or 
\begin_inset Formula $B$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A\cup B$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A\cap B$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
not 
\begin_inset Formula $A$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A^{c}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
at least one of 
\begin_inset Formula $A_{1},\dots,A_{n}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{1}\cup\cdots\cup A_{n}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
all of 
\begin_inset Formula $A_{1},\dots,A_{n}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{1}\cap\cdots\cap A_{n}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 implies 
\begin_inset Formula $B$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A\subseteq B$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are mutually exclusive (disjoint)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A\cap B=\phi$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{1},\dots,A_{n}$
\end_inset

are a partition of 
\begin_inset Formula $S$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{1}\cup\cdots\cup A_{n}=S$
\end_inset

 and 
\begin_inset Formula $A_{i}\cap A_{j}=\phi$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Classical probability
\end_layout

\begin_layout Definition
Classical (naive) definition of probability: 
\begin_inset Formula 
\[
P(A)=\frac{\left|A\right|}{\left|S\right|}=\dfrac{\textrm{number of outcomes favorable to A}}{\textrm{total number of outcomes in A}}
\]

\end_inset

assuming the outcomes are 
\emph on
finite
\emph default
 and 
\emph on
equally likely
\emph default
.
\end_layout

\begin_layout Example
Flip a coin twice.
 Find the probability of landing two heads.
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 There are four possible outcomes: {HH, HT, TH, TT}, each with equal probability.
 Therefore, 
\begin_inset Formula $P(\textrm{HH})=\frac{1}{4}$
\end_inset

.
\end_layout

\begin_layout Standard
The naive deﬁnition is very restrictive.
 It has often been misapplied by people who assume equally likely outcomes
 without justiﬁcation.
 Besides, it is easy to conceive examples of probabilities that do not fit
 into this formula, e.g.
 probability of rain.
 By saying it is 
\begin_inset Quotes eld
\end_inset

naive
\begin_inset Quotes erd
\end_inset

, it is definitely not the preferred definition in this course.
 
\end_layout

\begin_layout Standard
Nonetheless, we do some examples using the naive definition as a warm-up.
 Calculating the naive probability of an event 
\begin_inset Formula $A$
\end_inset

 often involves counting the number of outcomes in 
\begin_inset Formula $A$
\end_inset

 and the number of outcomes in the sample space 
\begin_inset Formula $S$
\end_inset

, which usually involve some counting methods.
 We now review some of the counting methods (multiplications, factorials,
 permutations, combinations) that was introduced in high schools.
 
\end_layout

\begin_layout Standard

\series bold
Multiplications.

\series default
 Consider a compound experiment consisting of two sub-experiments, Experiment
 A and Experiment B.
 Suppose that Experiment A has 
\begin_inset Formula $a$
\end_inset

 possible outcomes, and for each of those outcomes Experiment B has 
\begin_inset Formula $b$
\end_inset

 possible outcomes.
 Then the compound experiment has 
\begin_inset Formula $a\times b$
\end_inset

 possible outcomes.
\end_layout

\begin_layout Standard

\series bold
Exponentiations.

\series default
 Consider 
\begin_inset Formula $n$
\end_inset

 objects and making 
\begin_inset Formula $k$
\end_inset

 choices from them, one at a time 
\bar under
with replacement
\bar default
.
 Then there are 
\begin_inset Formula $n^{k}$
\end_inset

 possible outcomes.
\end_layout

\begin_layout Standard

\series bold
Factorials.

\series default
 Consider 
\begin_inset Formula $n$
\end_inset

 objects 
\begin_inset Formula $1,2,\dots,n$
\end_inset

.
 A permutation of 
\begin_inset Formula $1,2,\dots,n$
\end_inset

 is an arrangement of them in some order, e.g., 
\begin_inset Formula $3,5,1,2,4$
\end_inset

 is a permutation of 
\begin_inset Formula $1,2,3,4,5$
\end_inset

.
 The are 
\begin_inset Formula $n!$
\end_inset

 permutations of 
\begin_inset Formula $1,2,\dots,n$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Permutations
\series default
.
 Consider 
\begin_inset Formula $n$
\end_inset

 objects and making 
\begin_inset Formula $k$
\end_inset

 choices from them, one at a time 
\bar under
without replacement
\bar default
.
 Then there are 
\begin_inset Formula $P_{n}^{k}=n(n-1)\cdots(n-k+1)$
\end_inset

 possible outcomes, for 
\begin_inset Formula $k\leq n$
\end_inset

.
 (Ordering matters in this case, e.g.
 
\begin_inset Formula $1,2,3$
\end_inset

 is considered different from 
\begin_inset Formula $2,3,1$
\end_inset

)
\end_layout

\begin_layout Standard

\series bold
Combinations
\series default
.
 Consider 
\begin_inset Formula $n$
\end_inset

 objects and making 
\begin_inset Formula $k$
\end_inset

 choices from them, one at a time without replacement, without distinguishing
 between the different orders in which they could be chosen (e.g.
 
\begin_inset Formula $1,2,3$
\end_inset

 is considered no different from 
\begin_inset Formula $2,3,1$
\end_inset

).
 Then there are 
\begin_inset Formula $C_{n}^{k}=\frac{n(n-1)\cdots(n-k+1)}{k!}$
\end_inset

 possible outcomes.
 It literally counts the number of subsets of size 
\begin_inset Formula $k$
\end_inset

 for a set of size 
\begin_inset Formula $n$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $C_{n}^{k}$
\end_inset

 is known as the Binomial coefficient, also denoted as 
\begin_inset Formula $\binom{n}{k}$
\end_inset

, read as 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $n$
\end_inset

 choose 
\begin_inset Formula $k$
\end_inset


\begin_inset Quotes erd
\end_inset

.
 As it is related to the Binomial theorem, which states that 
\begin_inset Formula 
\[
(x+y)^{n}=\sum_{k=0}^{n}\binom{n}{k}x^{k}y^{n-k}.
\]

\end_inset


\end_layout

\begin_layout Standard
The following table summarizes the counting methods.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
order matters
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
order doesn't matter
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
with replacement
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n^{k}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $C_{n+k-1}^{k}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
non-replacement
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P_{n}^{k}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $C_{n}^{k}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
We don't explain the upper-right corner case 
\begin_inset Formula $C_{n+k-1}^{k}$
\end_inset

 as it is not relevant for our purpose here.
 Feel free to figure it out yourself if you are interested.
 
\end_layout

\begin_layout Example
Find the probability of a 
\begin_inset Quotes eld
\end_inset

full house
\begin_inset Quotes erd
\end_inset

 in a five-card hand.
\end_layout

\begin_layout Example

\emph on
Solution:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(\textrm{Full House})=\frac{13C_{4}^{3}\cdot12C_{4}^{2}}{C_{52}^{5}}=0.14\%.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Birthday problem
\end_layout

\end_inset

Suppose there are 
\begin_inset Formula $k$
\end_inset

 people.
 Find the probability that two of them have the same birthday.
 
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
Assuming there are 365 days in a year, ignoring leap years.
 If 
\begin_inset Formula $k>365$
\end_inset

, the probability is 
\begin_inset Formula $1$
\end_inset

.
 If 
\begin_inset Formula $k\leq365$
\end_inset

, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(\textrm{no match})=\frac{365\cdot365\cdots(365-k+1)}{365^{k}};
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(\textrm{match})=\begin{cases}
50.7\% & k=23\\
70.6\% & k=30\\
97\% & k=50\\
99.999\% & k=100
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Newton-Pepys problem
\end_layout

\end_inset

Isaac Newton was consulted about the following problem by Samuel Pepys,
 who wanted the information for gambling purposes.
 Which of the following events has the highest probability?
\end_layout

\begin_deeper
\begin_layout Standard
A: At least one 6 appears when 6 fair dice are rolled.
\end_layout

\begin_layout Standard
B: At least two 6’s appear when 12 fair dice are rolled.
\end_layout

\begin_layout Standard
C: At least three 6’s appear when 18 fair dice are rolled.
\end_layout

\end_deeper
\begin_layout Section
Axiomatic probability
\end_layout

\begin_layout Standard
We have now seen several methods for counting outcomes in a sample space,
 allowing us to calculate probabilities if the naive deﬁnition applies.
 But the naive deﬁnition can only take us so far, since it requires equally
 likely outcomes and can’t handle an inﬁnite sample space.
 To generalize the notion of probability, we’ll use the best part about
 math, which is that you get to 
\emph on
make up your own deﬁnitions
\emph default
.
 What this means is that we write down a short wish list of how we want
 probability to behave (in math, the items on the wish list are called axioms),
 and then we deﬁne a probability function to be something that satisﬁes
 the properties we want.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
A 
\series bold
probability space
\series default
 consists of 
\begin_inset Formula $S$
\end_inset

 and 
\begin_inset Formula $P$
\end_inset

, where 
\begin_inset Formula $S$
\end_inset

 is a sample space, and 
\begin_inset Formula $P$
\end_inset

 is a function which takes an event 
\begin_inset Formula $A\subseteq S$
\end_inset

 as input and returns 
\begin_inset Formula $P(A)\in[0,1]$
\end_inset

 such that 
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $P(\phi)=0$
\end_inset

,
\end_layout

\begin_layout Enumerate
\begin_inset Formula $P(S)=1$
\end_inset

,
\end_layout

\begin_layout Enumerate
\begin_inset Formula $P(\cup_{n=1}^{\infty}A_{n})=\sum_{n=1}^{\infty}P(A_{n})$
\end_inset

 if 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}$
\end_inset

 are disjoint.
 
\end_layout

\end_deeper
\begin_layout Standard
Note that this Definition does not imply any particular interpretation of
 probability.
 In fact, any function 
\begin_inset Formula $P$
\end_inset

 that satisfies the axioms are valid 
\begin_inset Quotes eld
\end_inset

probabilities
\begin_inset Quotes erd
\end_inset

.
 Thus, the theories of probability do not depend on any particular interpretatio
n.
 It is purely axiomatic.
 From the three axioms, we can derive any property of probabilities.
 The interpretation also matters, but it is more of a philosophical debate.
 Basically, there are two views in this regard.
 
\end_layout

\begin_layout Itemize
The 
\emph on
frequentist
\emph default
 view of probability is that it represents a long-run frequency over a large
 number of repetitions of an experiment: if we say a coin has probability
 1/2 of Heads, that means the coin would land Heads 50% of the time if we
 tossed it over and over and over.
\end_layout

\begin_layout Itemize
The 
\emph on
Bayesian
\emph default
 view of probability is that it represents a degree of belief about the
 event in question, so we can assign probabilities to hypotheses like “candidate
 A will win the election” or “the defendant is guilty” even if it isn’t
 possible to repeat the same election or the same crime over and over again.
\end_layout

\begin_layout Theorem
Probability has the following properties.
 For any events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, we have
\end_layout

\begin_layout Enumerate
\begin_inset Formula $P(A^{c})=1-P(A)$
\end_inset


\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $A\subseteq B$
\end_inset

, then 
\begin_inset Formula $P(A)\leq P(B).$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $P(A\cup B)=P(A)+P(B)-P(A\cap B)$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Proof
1.
 Since 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $A^{c}$
\end_inset

 are disjoint and their union is 
\begin_inset Formula $S$
\end_inset

, apply the third axiom: 
\begin_inset Formula 
\[
P(S)=P(A\cup A^{c})=P(A)+P(A^{c});
\]

\end_inset


\end_layout

\begin_layout Proof
By the second axiom, 
\begin_inset Formula $P(S)=1$
\end_inset

.
 So 
\begin_inset Formula $P(A)+P(A^{c})=1$
\end_inset

.
\end_layout

\begin_layout Proof
2.
 The key is to break up the set into disjoint sets.
 If 
\begin_inset Formula $A\subseteq B$
\end_inset

, then 
\begin_inset Formula $B=A\cup(B\cap A^{c})$
\end_inset

 where 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B\cap A^{c}$
\end_inset

 are disjoint (draw a Venn diagram for intuition).
 By the third axiom, we have 
\begin_inset Formula 
\[
P(B)=P(A\cup(B\cap A^{c}))=P(A)+P(B\cap A^{c})\geq P(A).
\]

\end_inset


\end_layout

\begin_layout Proof
3.
 We can write 
\begin_inset Formula $A\cup B$
\end_inset

 as the union of the disjoint set 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B\cap A^{c}$
\end_inset

.
 Then by the third axiom, 
\begin_inset Formula 
\[
P(A\cup B)=P(A\cup(B\cap A^{c}))=P(A)+P(B\cap A^{c}).
\]

\end_inset


\end_layout

\begin_layout Proof
It suffices to show that 
\begin_inset Formula $P(B\cap A^{c})=P(B)-P(A\cap B)$
\end_inset

.
 Since 
\begin_inset Formula $B\cap A$
\end_inset

 and 
\begin_inset Formula $B\cap A^{c}$
\end_inset

 are disjoint, we have
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
P(B)=P(B\cap A)+P(B\cap A^{c}).
\]

\end_inset


\end_layout

\begin_layout Proof
So 
\begin_inset Formula $P(B\cap A^{c})=P(B)-P(A\cap B)$
\end_inset

 as desired.
\end_layout

\begin_layout Standard
The last property is a very usueful formula for ﬁnding the probability of
 a union of events when the events are not necessarily disjoint.
 We have showed that for two events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 A natural question is to generalize it for three or more events.
 For three events,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(A\cup B\cup C)=P(A)+P(B)+P(C)-P(A\cap B)-P(A\cap C)-P(B\cap C)+P(A\cap B\cap C).
\]

\end_inset


\end_layout

\begin_layout Standard
We skip the proof.
 It can be easily justified by showing a Venn diagram.
 For the 
\begin_inset Formula $n$
\end_inset

-events case, we state it as the following theorem.
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Inclusion-exclusion
\end_layout

\end_inset

For any events 
\begin_inset Formula $A_{1},A_{2},\dots,A_{n}$
\end_inset

, it holds that
\begin_inset Formula 
\begin{align*}
P(A_{1}\cup A_{2}\cdots\cup A_{n}) & =\sum_{j=1}^{n}P(A_{j})-\sum_{i<j}P(A_{i}\cap A_{j})+\sum_{i<j<k}P(A_{i}\cap A_{j}\cap A_{k})-\cdots\\
 & \quad(-1)^{n+1}P(A_{1}\cap\cdots\cap A_{n}).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This formula can be proved by induction using the axioms.
 Below is a famous application (known as de Montmort's problem, named after
 French mathematician Pierre Remond de Montmort) of the inclulsion-exclusion
 theorem.
 
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Matching problem
\end_layout

\end_inset

 Given 
\begin_inset Formula $n$
\end_inset

 cards, labeled 
\begin_inset Formula $1,2,...,n.$
\end_inset

 Let 
\begin_inset Formula $A_{j}$
\end_inset

 be the event 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $j$
\end_inset

-th card matches
\begin_inset Quotes erd
\end_inset

(the 
\begin_inset Formula $j$
\end_inset

-th card is numbered as 
\begin_inset Formula $j$
\end_inset

).
 Find the probability of at least one match, i.e.
 
\begin_inset Formula $P(A_{1}\cup A_{2}\cup\cdots\cup A_{n})=?$
\end_inset


\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Since all position are equally likely, 
\begin_inset Formula $P(A_{j})=\frac{1}{n}$
\end_inset

.
 The probability of there being two matches is: 
\begin_inset Formula $P(A_{1}\cap A_{2})=\frac{(n-2)!}{n!}=\frac{1}{n(n-1)}$
\end_inset

.
 Similarly, the probability of there being 
\begin_inset Formula $k$
\end_inset

 matches is: 
\begin_inset Formula $P(A_{1}\cap\cdots\cap A_{k})=\frac{(n-k)!}{n!}=\frac{1}{n(n-1)\cdots(n-k+1)}$
\end_inset

.
 Using the property of the union of events, 
\begin_inset Formula 
\[
\begin{aligned}P(A_{1}\cup A_{2}\cup\cdots\cup A_{n})= & n\cdot\frac{1}{n}-\binom{n}{2}\frac{1}{n(n-1)}+\binom{n}{3}\frac{1}{n(n-1)(n-2)}-\cdots\\
= & 1-\text{\ensuremath{\frac{1}{2!}+\frac{1}{3!}-\frac{1}{4!}+\cdots+(-1)^{n+1}\frac{1}{n!}}\ensuremath{\approx1-\frac{1}{e}}.}
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Section
Conditional probability
\end_layout

\begin_layout Standard
Abraham Wald, the renowned statistician, was hired by the Statistical Research
 Group (SRG) at Columbia University to figure out how to minimize the damage
 to bomber aircraft.
 The data they had comprised aircraft returning from missions with bullet
 holes on their bodies.
 If asked which parts of the aircraft should be armored to enhance survivability
, the obvious answer seemed to be to armor the damaged parts.
 However, Wald suggested the exact opposite—to armor the parts that were
 not damaged.
 Why? Because the observed damage was conditioned on the aircraft returning.
 If an aircraft had been damaged on other parts, it likely would not have
 returned.
 Thinking conditionally completely changes the answer!
\begin_inset Foot
status open

\begin_layout Plain Layout
See an interesting talk by Professor Joseph Blitzstein: "The Soul of Statistics".
 Available on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.youtube.com/watch?v=dzFf3r1yph8
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The probability of A 
\series bold
conditioned on
\series default
 B is the updated probability of event A after we learn that event B has
 occurred.
 Since events contain information, the occurring of a certain event may
 change our believes on probabilities of other relevant events.
 The updated probability of event A after we learn that event B has occurred
 is the conditional probability of A given B.
 
\end_layout

\begin_layout Definition
If 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are events with 
\begin_inset Formula $P(B)>0$
\end_inset

, then the 
\series bold
conditional probability
\series default
 of 
\begin_inset Formula $A$
\end_inset

 given 
\begin_inset Formula $B$
\end_inset

 is deﬁned as
\begin_inset Formula 
\[
P(A|B)=\frac{P(A\cap B)}{P(B)}.
\]

\end_inset


\end_layout

\begin_layout Exercise
Prove that conditional probabilities are probabilities.
 (Hint: using the three axioms.)
\end_layout

\begin_layout Theorem
Properties of conditional probability:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $P(A\cap B)=P(B)P(A|B)=P(A)P(B|A)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $P(A_{1}\cap\cdots\cap A_{n})=P(A_{1})P(A_{2}|A_{1})P(A_{3}|A_{1},A_{2})\cdots P(A_{n}|A_{1}\ldots A_{n-1})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $P(A|B)=\dfrac{P(B|A)P(A)}{P(B)}$
\end_inset

 (Bayes' rule)
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
The last property, Bayes' rule, quantifies how to update probabilities based
 on new evidence.
 It is named after Thomas Bayes in the 18th century.
 It gained prominence posthumously through Richard Price’s publication of
 Bayes’ work in 1763.
 The rule calculates the probability of a hypothesis based on prior knowledge
 and new data, foundational for Bayesian statistics.
\end_layout

\begin_layout Standard
Historically, Bayes studied the problem in order to prove David Hume wrong.
 Hume argued that we cannot directly observe causation; instead, we infer
 it from patterns of events.
 Bayes' rule allows for a systematic way to update our beliefs about causal
 relationships as new evidence emerges, thereby bridging the gap between
 empirical observation and theoretical inference.
 This approach counters Hume's skepticism by providing a method for rationally
 assessing the likelihood of causes based on observed effects.
\begin_inset Foot
status open

\begin_layout Plain Layout
See 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://faculty.som.yale.edu/jameschoi/bayes-theorem-began-as-a-defense-of-christia
nity
\end_layout

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Law of total probability
\end_layout

\end_inset

Let 
\begin_inset Formula $A_{1},...,A_{n}$
\end_inset

 be a partition of the sample space 
\begin_inset Formula $S$
\end_inset

 (i.e., the 
\begin_inset Formula $A_{i}$
\end_inset

 are disjoint events and their union is 
\begin_inset Formula $S$
\end_inset

), with 
\begin_inset Formula $P(A_{i})>0$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 Then 
\begin_inset Formula 
\[
P(B)=\sum_{i=1}^{n}P(B|A_{i})P(A_{i}).
\]

\end_inset


\end_layout

\begin_layout Example
Get a random 2-card hand from a standard deck.
 Find the probability of getting another ace conditioned on (a) having one
 ace, or (b) having the ace of spade.
 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 The example shows the subtleness of conditional probabilities.
 The seemingly indifferent probabilities are in fact different:
\begin_inset Formula 
\[
\begin{aligned} & P(\textrm{another ace | one ace})=\frac{P(\textrm{both aces})}{P(\textrm{one ace})}=\frac{C_{4}^{2}/C_{52}^{2}}{1-C_{48}^{2}/C_{52}^{2}}=\frac{1}{33};\\
 & P(\textrm{another ace | ace of spade})=\frac{P(\textrm{ace of spade \& another ace})}{P(\textrm{ace of spade})}=\frac{C_{3}^{1}/C_{52}^{2}}{C_{51}^{1}/C_{52}^{2}}=\frac{1}{17}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Example
In the first case, the denominator is interpreted as 
\begin_inset Quotes eld
\end_inset

at least one ace
\begin_inset Quotes erd
\end_inset

; whereas in the second case, it is 
\begin_inset Quotes eld
\end_inset

ace of space + another card
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The pandemic afflicted roughly 1/3 of the world population.
 The PCR test is 98% accurate.
 (this means if you have been infected, the test reports positive 98% of
 the time.) Find the probability of being infected when a test is positive.
 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $D$
\end_inset

: actually infected, 
\begin_inset Formula $T$
\end_inset

: test positive.
 The test accuracy means: 
\begin_inset Formula $P(T|D)=98\%$
\end_inset

.
 It also means 
\begin_inset Formula $P(T|D^{C})=2\%$
\end_inset

.
 We also know that 
\begin_inset Formula $P(D)=1/3$
\end_inset

.
 We want to find 
\begin_inset Formula $P(D|T)$
\end_inset

.
 Apply the Bayes' rule:
\begin_inset Formula 
\[
\begin{aligned}P(D|T)= & \frac{P(T|D)P(D)}{P(T)}\\
= & \frac{P(T|D)P(D)}{P(T|D)P(D)+P(T|D^{C})P(D^{C})}\\
= & \frac{0.98\times1/3}{0.98\times1/3+0.02\times2/3}\approx96\%.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Note that how 
\begin_inset Formula $P(T|D)$
\end_inset

 is different from 
\begin_inset Formula $P(D|T)$
\end_inset

, though confusing the conditionality is quite common in daily life.
 The difference is even pronounced if the disease is rare.
 Suppose 
\begin_inset Formula $P(D)=10\%$
\end_inset

.
 Then 
\begin_inset Formula $P(D|T)=84\%$
\end_inset

.
 A large difference from the test accuracy rate 
\begin_inset Formula $98\%$
\end_inset

! 
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Monty Hall problem
\end_layout

\end_inset

Suppose you are on Monty Hall's TV show.
 There are three doors.
 One of them has a car behind it.
 The other two doors have goats.
 Monty knows which one has the car.
 Monty now asks you to pick one door.
 You will win whatever is behind the door.
 After you pick one door.
 Monty opens another door that shows a goat.
 Monty then asks you if you want to switch.
 Is it optimal to switch?
\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename img/hall.png
	scale 50

\end_inset


\end_layout

\end_deeper
\begin_layout Example
We present two solutions to the problem.
 The first one is using the law of total probability.
 Let 
\begin_inset Formula $S$
\end_inset

: succeed assuming switch; 
\begin_inset Formula $D_{j}$
\end_inset

: door 
\begin_inset Formula $j$
\end_inset

 has the car, 
\begin_inset Formula $j\in1,2,3$
\end_inset

.
 Without loss of generality, assume the initial pick is Door 1.
 Monty will always open the door with a goat.
 By the law of total probability,
\begin_inset Formula 
\[
\begin{aligned}P(S)= & \underbrace{P(S|D_{1})}_{\textrm{switch from initial pick}}P(D_{1})+\underbrace{P(S|D_{2})}_{\textrm{Monty opens door 3}}P(D_{2})+\underbrace{P(S|D_{3})}_{\textrm{Monty opens door 2}}P(D_{3})\\
= & 0+1\times\frac{1}{3}+1\times\frac{1}{3}=\frac{2}{3}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Example
The problem can also be solved using the Bayes' rule.
 Let 
\begin_inset Formula $D_{j}$
\end_inset

: door 
\begin_inset Formula $j$
\end_inset

 has the car; 
\begin_inset Formula $M_{j}$
\end_inset

: Monty opens door 
\begin_inset Formula $j$
\end_inset

, 
\begin_inset Formula $j\in1,2,3$
\end_inset

.
 Assume the initial pick is Door 1.
 If Monty opens door 3, the probability of winning the car assuming switching
 is
\begin_inset Formula 
\[
\begin{aligned}P(D_{2}|M_{3})= & \frac{P(M_{3}|D_{2})P(D_{2})}{P(M_{3})}\\
= & \frac{P(M_{3}|D_{2})P(D_{2})}{P(M_{3}|D_{1})P(D_{1})+P(M_{3}|D_{2})P(D_{2})+P(M_{3}|D_{3})P(D_{3})}\\
= & \frac{1\times\frac{1}{3}}{\frac{1}{2}\times\frac{1}{3}+1\times\frac{1}{3}+0}=\frac{2}{3}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Example
Note that, if door 1 has the car, Monty will open door 2 and 3 with equal
 probability, thus 
\begin_inset Formula $P(M_{3}|D_{1})=\frac{1}{2}$
\end_inset

.
 And Monty will never open the door with the car, therefore 
\begin_inset Formula $P(M_{3}|D_{3})=0$
\end_inset

.
 Similarly, if Monty opens door 2, we have 
\begin_inset Formula $P(D_{3}|M_{2})=\frac{2}{3}$
\end_inset

.
 Therefore, the optimal choice is always to switch.
 Intuitively, because Monty knows which door has the car, the fact that
 he always opens the door without the car gives additional information regarding
 the choice of the door.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Simpson's paradox
\end_layout

\end_inset

There are two doctors, Dr.
 Lee and Dr.
 Wong, performing two types of surgeries — heart surgery (hard) and band-aid
 removal (easy).
 Dr.
 Lee has higher overall surgery success rate.
 Is Dr.
 Lee necessarily a better doctor than Dr.
 Wong?
\end_layout

\begin_layout Standard

\emph on
Solution:
\emph default
 No.
 Consider the following example:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="8">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dr.
 Lee
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dr.
 Wong
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Heart
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Band-Aid
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Heart
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Band-Aid
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Success
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
81
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
83
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Failure
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Success rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
83%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
78%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
100%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The truth is Dr.
 Lee has overall higher success rate because he only does easy surgeries
 (band-aid removal).
 Dr.
 Wong does mostly hard surgeries and thus has a lower overall success rate.
 Yet, he is better at each single type of surgery.
 To formalize the argument, let 
\begin_inset Formula $S$
\end_inset

: successful surgery; 
\begin_inset Formula $D$
\end_inset

: treated by Dr.
 Lee, 
\begin_inset Formula $D^{c}$
\end_inset

: treated by Dr.
 Wong; 
\begin_inset Formula $E$
\end_inset

: heart surgery, 
\begin_inset Formula $E^{c}$
\end_inset

: band-aid removal.
 Dr.
 Wong is better at each type of surgery,
\begin_inset Formula 
\[
\begin{aligned}P(S|D,E) & <P(S|D^{c},E)\\
P(S|D,E^{c}) & <P(S|D^{c},E^{c});
\end{aligned}
\]

\end_inset

But, Dr.
 Lee has a higher overall successful rate,
\begin_inset Formula 
\[
P(S|D)>P(S|D^{c}).
\]

\end_inset

This is because there is a 
\begin_inset Quotes eld
\end_inset

confounder
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $E$
\end_inset

:
\begin_inset Formula 
\[
P(S|D)=\underbrace{P(S|D,E)}_{<P(S|D^{c},E)}\underbrace{P(E|D)}_{\textrm{weight}}+\underbrace{P(S|D,E^{c})}_{<P(S|D^{c},E^{c})}\underbrace{P(E^{c}|D)}_{\textrm{weight}}.
\]

\end_inset

A 
\series bold
confounder
\series default
 is a variable that influences with both explanatory variable and the outcome
 variable, which therefore 
\begin_inset Quotes eld
\end_inset

confounds
\begin_inset Quotes erd
\end_inset

 the correlation between the two.
 In our example, the type of surgery (
\begin_inset Formula $E$
\end_inset

) is associated with both the doctor and the outcome.
 Without the confounder being controlled, it is impossible to draw valid
 conclusions from the statistics.
 
\end_layout

\begin_layout Standard
In general terms, Simpson’s paradox refers to the paradox in which a trend
 that appears across different groups of aggregate data is the reverse of
 the trend that appears when the aggregate data is broken up into its components.
 It is one of the most common sources of statistical misuse.
 Here is another example.
\begin_inset Foot
status open

\begin_layout Plain Layout
See 
\begin_inset CommandInset href
LatexCommand href
name "https://setosa.io/simpsons"
target "https://setosa.io/simpsons"
literal "false"

\end_inset

 for a really good illustration of the Simpson's paradox.
 
\end_layout

\end_inset

 
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
UC Berkeley gender bias
\end_layout

\end_inset

One of the best-known examples of Simpson's paradox comes from a study of
 gender bias among graduate school admissions to University of California,
 Berkeley.
 The admission figures for the fall of 1973 showed that men applying were
 more likely than women to be admitted, and the difference was so large
 that it was unlikely to be due to chance.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="6">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Male
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Female
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Applicants
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Admitted
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Applicants
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Admitted
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8,442
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
44%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4,321
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
However, when taking into account the information about departments being
 applied to, the conclusion turns to the opposite: in most departments,
 the admission rate for women is higher than men.
 The lower overall admission rate is caused by the fact that women tended
 to apply to more competitive departments with lower rates of admission,
 whereas men tended to apply to less competitive departments with higher
 rates of admission.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Department
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Male
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Female
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Applicants
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Admitted
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Applicants
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Admitted
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
825
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
62%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
108
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
82%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
560
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
63%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
25
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
68%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
C
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
325
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
37%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
593
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
34%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
D
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
417
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
33%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
375
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
E
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
191
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
393
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
24%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
F
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
373
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
341
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2691
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
45%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1835
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Independence
\end_layout

\begin_layout Definition
If event 
\begin_inset Formula $B$
\end_inset

’s occurrence does not change the probability of 
\begin_inset Formula $A$
\end_inset

, then we say 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are independent.
 That is to say 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are 
\series bold
independent
\series default
 if
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(A|B)=P(A)\textrm{ when }P(B)>0.
\]

\end_inset


\end_layout

\begin_layout Standard
Or more generally, 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are 
\series bold
independent
\series default
 if 
\begin_inset Formula 
\[
P(A\cap B)=P(A)P(B).
\]

\end_inset

 (A definition including cases where 
\begin_inset Formula $A$
\end_inset

 or 
\begin_inset Formula $B$
\end_inset

 has zero probability.)
\end_layout

\begin_layout Theorem
If events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are independent, then
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B^{c}$
\end_inset

 are independent;
\end_layout

\begin_layout Itemize
\begin_inset Formula $A^{c}$
\end_inset

 and 
\begin_inset Formula $B^{c}$
\end_inset

 are independent.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are independent means they do not provide information to each other in
 the sense that conditional probability is not different from the unconditional
 probability.
 It is not an intuitive idea as it seems.
 It will become clearer when we discuss random variables in later chapters.
 Here we clarify some likely confusions.
 
\end_layout

\begin_layout Remark
Independence is not the same as disjointness.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are disjoint means if 
\begin_inset Formula $A$
\end_inset

 occurs, 
\begin_inset Formula $B$
\end_inset

 cannot occur.
 But independence means 
\begin_inset Formula $A$
\end_inset

 occurs has nothing to do with 
\begin_inset Formula $B$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
Pairwise independence does not imply independence.
\end_layout

\begin_layout Definition
Events 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 are said to be 
\series bold
(mutually) independent
\series default
 if all of the following equations hold:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\begin{aligned}P(A\cap B)= & P(A)P(B),\\
P(A\cap C)= & P(A)P(C),\\
P(B\cap C)= & P(B)P(C),\\
P(A\cap B\cap C)= & P(A)P(B)P(C).
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
If the ﬁrst three conditions hold, we say that 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 are 
\series bold
pairwise independent
\series default
.
 Pairwise independence does not imply independence.
 Convince yourself with the following example.
\end_layout

\begin_layout Example
Consider two fair, independent coin tosses, and let 
\begin_inset Formula $A$
\end_inset

 be the event that the ﬁrst is Heads, 
\begin_inset Formula $B$
\end_inset

 the event that the second is Heads, and 
\begin_inset Formula $C$
\end_inset

 the event that both tosses have the same result.
 Show that 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 are pairwise independent but not independent.
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 For each event, 
\begin_inset Formula $P(A)=\frac{1}{2}$
\end_inset

, 
\begin_inset Formula $P(B)=\frac{1}{2}$
\end_inset

.
 Consider the two events together, there are four possible outcomes: HH,
 HT, TH, TT.
 
\begin_inset Formula $P(C)=P(HH)+P(TT)=\frac{1}{2}$
\end_inset

.
 Thus,
\begin_inset Formula 
\begin{align*}
P(A\cap B) & =P(HH)=\frac{1}{4}=P(A)P(B)\\
P(A\cap C) & =P(HH)=\frac{1}{4}=P(A)P(C)\\
P(B\cap C) & =P(HH)=\frac{1}{4}=P(B)P(C)
\end{align*}

\end_inset

But 
\begin_inset Formula $A,B,C$
\end_inset

 are not independent, because
\begin_inset Formula 
\[
P(A\cap B\cap C)=P(HH)=\frac{1}{4}\neq P(A)P(B)P(C).
\]

\end_inset


\end_layout

\begin_layout Definition
For 
\begin_inset Formula $n$
\end_inset

 events 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}$
\end_inset

 to be 
\series bold
(mutually) independent
\series default
, we require any pair to satisfy 
\begin_inset Formula $P(A_{i}\cap A_{j})=P(A_{i})P(A_{j})$
\end_inset

 (for 
\begin_inset Formula $i\neq j$
\end_inset

), any triplet to satisfy 
\begin_inset Formula $P(A_{i}\cap A_{j}\cap A_{k})=P(A_{i})P(A_{j})P(A_{k})$
\end_inset

 (for 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $j$
\end_inset

, 
\begin_inset Formula $k$
\end_inset

 distinct), and similarly for all quadruplets, quintuplets, and so on.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
Events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are 
\series bold
conditional independent
\series default
 given 
\begin_inset Formula $C$
\end_inset

 if 
\begin_inset Formula 
\[
P(A\cap B|C)=P(A|C)P(B|C).
\]

\end_inset


\end_layout

\begin_layout Remark
Conditional independence does not apply independence.
 
\end_layout

\begin_layout Remark
Consider an example of playing chess games.
 Conditioned on the strength of your opponents, the outcome of each game
 is reasonably independent (ignoring the psychology and fatigues of the
 players).
 But the outcomes are not unconditionally independent, because stronger
 player has higher chances of winning each game.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
Independence does not apply conditional independence.
\end_layout

\begin_layout Remark
Consider an example of fire alarm.
 Suppose there are two potential causes to trigger the fire alarm: (1) there
 is fire; (2) someone smoking.
 Assume the two events are independent.
 But they are not conditional independent if conditioning on the alarm beeping.
 Because if the alarm is on, but no one smokes, we definitely know there
 is fire.
 So there they are not conditional independent.
 
\end_layout

\begin_layout Section
Review of calculus*
\end_layout

\begin_layout Standard
Calculus is a prerequisite to work with continuous distributions.
 The following chapters assume readers are proficient in calculus.
 We nonetheless review some basic concepts here as a warm-up.
 This review is not exhaustive, so please refer to a specific textbook if
 needed for a more comprehensive understanding.
\end_layout

\begin_layout Subsection
Differentiation
\end_layout

\begin_layout Standard
We define the derivative of a function 
\begin_inset Formula $f(x)$
\end_inset

 to be 
\begin_inset Formula 
\[
f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}
\]

\end_inset


\end_layout

\begin_layout Standard
Loosely speaking, a function is continuous if there is no jump in the graph,
 differentiable if the curve is smooth.
 Some commonly used derivatives:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned} & \frac{d}{dx}(x^{n}) & = & nx^{n-1}\\
 & \frac{d}{dx}(e^{x}) & = & e^{x}\\
 & \frac{d}{dx}(\ln(x)) & = & \frac{1}{x}\\
 & \frac{d}{dx}(\sin(x)) & = & \cos(x)\\
 & \frac{d}{dx}(\cos(x)) & = & -\sin(x)\\
 & (fg)' & = & f'g+fg'\\
 & \left(\frac{f}{g}\right)^{'} & = & \frac{f'g-fg'}{g^{2}}\\
 & [f(g(x))]' & = & f'(g(x))g'(x)
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
When dealing with limits of the form 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\frac{0}{0}$
\end_inset


\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\frac{\infty}{\infty}$
\end_inset


\begin_inset Quotes erd
\end_inset

, the L'Hospital rule is very handy.
 
\begin_inset Formula 
\[
\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}.
\]

\end_inset


\end_layout

\begin_layout Standard
One important application of derivatives is the Taylor's theorem, which
 gives the approximation of a function around a given point by polynomials.
 Assume function 
\begin_inset Formula $f$
\end_inset

 is at least 
\begin_inset Formula $k$
\end_inset

 times differentiable, then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(x)=f(a)+f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^{2}+\cdots+\frac{f^{(k)}(a)}{k!}(x-a)^{k}+\cdots
\]

\end_inset


\end_layout

\begin_layout Standard
which means we can approximate a function arbitrarily well by higher order
 polynomials.
 Some commonly used Taylor series (expanding around 
\begin_inset Formula $a=0$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned} & \frac{1}{1-x} & = & 1+x+x^{2}+x^{3}+\cdots\quad\textrm{for }|x|<1\\
 & e^{x} & = & 1+x+\frac{x^{2}}{2!}+\frac{x^{3}}{3!}+\cdots\\
 & \sin x & = & x-\frac{x^{3}}{3!}+\frac{x^{5}}{5!}-\frac{x^{7}}{7!}+\cdots\\
 & \cos x & = & 1-\frac{x^{2}}{2!}+\frac{x^{4}}{4!}-\frac{x^{6}}{6!}+\cdots\\
 & \ln(1+x) & = & x-\frac{x^{2}}{2}+\frac{x^{3}}{3}-\frac{x^{4}}{4}+\cdots\quad\textrm{for }|x|<1\\
 & \arctan(x) & = & x-\frac{x^{3}}{3}+\frac{x^{5}}{5}-\frac{x^{7}}{7}+\cdots\quad\textrm{for }|x|\leq1
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Taylor series are one of the most amazing results in calculus.
 For example, in the last formula, if we let 
\begin_inset Formula $x=1$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\pi}{4}=\arctan(1)=1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, we can approximate 
\begin_inset Formula $\pi$
\end_inset

 by summing up a sequence of fractions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi=4\left(1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Integration
\end_layout

\begin_layout Standard
Integration is the inverse operation of differentiation.
 Integral has the geometric interpretation as the area under the curve.
 Let 
\begin_inset Formula $A(x)$
\end_inset

 be the area under the curve of 
\begin_inset Formula $y=f(x)$
\end_inset

.
 Thus 
\begin_inset Formula $A(x)=\int_{0}^{x}f(t)dt$
\end_inset

.
 The change of the area resulted from a tiny little change of 
\begin_inset Formula $x$
\end_inset

 is approximated by 
\begin_inset Formula $A(x+h)-A(x)\approx f(x)h$
\end_inset

.
 That is 
\begin_inset Formula $\frac{A(x+h)-A(x)}{h}=f(x)$
\end_inset

.
 If the change is infinitesimal, 
\begin_inset Formula $h\to0$
\end_inset

, we have 
\begin_inset Formula $A'(x)=f(x)$
\end_inset

.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename img/integral.png
	width 60col%

\end_inset


\end_layout

\begin_layout Standard
The Fundamental Theorem of Calculus: if 
\begin_inset Formula $F$
\end_inset

 is the antiderivative of 
\begin_inset Formula $f$
\end_inset

, then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
F(x)=\int_{a}^{x}f(t)dt
\]

\end_inset


\begin_inset Formula 
\[
\int_{a}^{b}f(x)dx=F(b)-F(a)
\]

\end_inset


\end_layout

\begin_layout Standard
One interpretation of the integral is — the integral of a rate of change
 of a quantity gives the net change in that quantity.
 Think about speed and distance: 
\begin_inset Formula $\int_{a}^{b}v(t)dt=s(b)-s(a)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Because the integral is just a sum over infinitely many approximating rectangles
, 
\begin_inset Formula $\int_{a}^{b}f(x)dx=\lim_{n\to\infty}\sum_{i=1}^{n}f(x_{i})\Delta x$
\end_inset

.
 Integrals behave just like sums.
 For example, 
\begin_inset Formula $\frac{1}{b-a}\int_{a}^{b}f(x)dx$
\end_inset

 has the interpretation of the average of 
\begin_inset Formula $f(x)$
\end_inset

 from 
\begin_inset Formula $a$
\end_inset

 to 
\begin_inset Formula $b$
\end_inset

.
\end_layout

\begin_layout Standard
Indefinite integrals are the general antiderivatives without specifying
 the interval of the integration.
 It always comes with a constant 
\begin_inset Formula $C$
\end_inset

.
 Some commonly used integrals:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned} & \int dx & = & x+C\\
 & \int x^{n}dx & = & \frac{x^{n+1}}{n+1}+C\\
 & \int e^{x}dx & = & e^{x}+C\\
 & \int\frac{1}{x}dx & = & \ln|x|+C\\
 & \int\cos(x)dx & = & \sin(x)+C\\
 & \int\sin(x)dx & = & -\cos(x)+C\\
 & \int\frac{1}{1+x^{2}}dx & = & \arctan(x)+C
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Two common integration techniques are 
\emph on
substitution
\emph default
 and 
\emph on
integration by parts
\emph default
.
 Integration by substitution applies when substituting part of the integrand
 makes the integral more approachable.
\end_layout

\begin_layout Example
Find 
\begin_inset Formula $\int\sqrt{3x+2}dx$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $u=3x+2$
\end_inset

, then 
\begin_inset Formula $du=3dx$
\end_inset

.
 Then
\begin_inset Formula 
\[
\int\sqrt{3x+2}dx=\frac{1}{3}\int\sqrt{u}du=\frac{2}{9}u^{3/2}+C=\frac{2}{9}(3x+2)^{3/2}+C.
\]

\end_inset


\end_layout

\begin_layout Standard
Integration by parts follows the formula: 
\begin_inset Formula $\int f(x)g'(x)dx=f(x)g(x)-\int f'(x)g(x)dx$
\end_inset

.
\end_layout

\begin_layout Example
Find 
\begin_inset Formula $\int x\sin xdx$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $f(x)=x$
\end_inset

, 
\begin_inset Formula $g'(x)=\sin x$
\end_inset

.
 Then 
\begin_inset Formula $g(x)=-\cos x$
\end_inset

.
 Therefore, 
\begin_inset Formula 
\[
\int x\sin xdx=-x\cos x-\int(-\cos x)dx=-x\cos x+\sin x+C.
\]

\end_inset


\end_layout

\begin_layout Chapter
Random Variables
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
In the previous chapter, we have been working with 
\emph on
events
\emph default
, which is a conceptualization of real world outcomes occurred with probabilitie
s.
 In this chapter, we introduce a much more powerful conceptualization that
 deals with uncertain outcomes — random variables, which is the foundation
 of all probability and statistical studies.
 
\end_layout

\begin_layout Standard
In high school, all mathematical models come with certainty.
 For example, the falling time of any object from height 
\begin_inset Formula $h$
\end_inset

 down to the earth is: 
\begin_inset Formula $t=\sqrt{\frac{2h}{g}}$
\end_inset

, where 
\begin_inset Formula $g$
\end_inset

 is the gravity constant.
 The outcome is 
\emph on
deterministic
\emph default
.
 The variables that enter into the equation either have unknown values or
 known certain values.
 Errors are possible only due to frictions or measurement errors.
 
\end_layout

\begin_layout Standard
But many real world processes come naturally with uncertainty.
 Think about the temperature tomorrow, or the stock market returns.
 We can only make predictions with probabilities.
 Yes, you may argue this uncertainly is due to incomplete information.
 If we have all the knowledge regarding the climate, we can predict exactly
 the temperature.
 But given the imperfection of the human knowledge, the only feasible option
 is to build this uncertainly into our mathematical models.
 Random variable is core concept and the Swiss knife that we use to deal
 with uncertainties mathematically.
 
\end_layout

\begin_layout Standard
Informally, a random variable differs from a normal variable as it is 
\begin_inset Quotes eld
\end_inset

random
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\begin_layout Quotation
A random variable is a variable whose value is uncertain, but comes with
 probabilities.
\end_layout

\begin_layout Standard
A random variable, say 
\begin_inset Formula $X$
\end_inset

, is never associated with a certain value, such as 
\begin_inset Formula $X=1$
\end_inset

, or 
\begin_inset Formula $X=2$
\end_inset

.
 It could be any of these values, but with different probabilities, e.g.
 
\begin_inset Formula $P(X=1)=0.2$
\end_inset

, 
\begin_inset Formula $P(X=2)=0.4$
\end_inset

.
\end_layout

\begin_layout Definition
Given an experiment with sample space 
\begin_inset Formula $S$
\end_inset

, a 
\series bold
random variable
\series default
 is a function from the sample space 
\begin_inset Formula $S$
\end_inset

 to the real numbers 
\begin_inset Formula $\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Standard
As an example, flipping a coin twice, let 
\begin_inset Formula $X$
\end_inset

 be the number of heads.
 Then 
\begin_inset Formula $X(\cdot)$
\end_inset

 is a functions that maps events in 
\begin_inset Formula $\left\{ HH,HT,TH,TT\right\} $
\end_inset

 into real numbers.
 In our case, the mapping goes like
\begin_inset Formula 
\begin{align*}
X(HH) & =2,X(HT)=1,X(TH)=1,X(TT)=0.
\end{align*}

\end_inset


\begin_inset Formula $X$
\end_inset

 is therefore an 
\bar under
encoding
\bar default
 of events in the sample space into real numbers.
 We could, of course, have different encodings.
 Conder the random variable 
\begin_inset Formula $Y$
\end_inset

 as the number of tails.
 Then we have 
\begin_inset Formula $Y=2-X$
\end_inset

.
 
\begin_inset Formula 
\begin{align*}
Y(HH) & =0,Y(HT)=1,Y(TH)=2,Y(TT)=2.
\end{align*}

\end_inset

We could also define 
\begin_inset Formula $Z$
\end_inset

 as the number heads in the 1st toss only.
 The encoding goes like 
\begin_inset Formula 
\[
Z(HH)=1,Z(HT)=1,Z(TH)=0,Z(TT)=0.
\]

\end_inset

We have listed three ways of 
\begin_inset Quotes eld
\end_inset

encoding
\begin_inset Quotes erd
\end_inset

 the same experiment as random variables.
 All of them are valid random variables, but they map the outcomes into
 different numbers.
 We can say that, a random variable is a 
\bar under
numeric
\bar default
 
\begin_inset Quotes eld
\end_inset

summary
\begin_inset Quotes erd
\end_inset

 of an aspect of an experiment.
 
\end_layout

\begin_layout Remark*
We usually use capital letters, such as 
\begin_inset Formula $X,Y,Z$
\end_inset

, to denote random variables.
 We use small letters, such as 
\begin_inset Formula $x,y,z$
\end_inset

, to denote specific values.
 
\begin_inset Formula $P(X=x)$
\end_inset

 means the probability of 
\begin_inset Formula $X$
\end_inset

 taking the value 
\begin_inset Formula $x$
\end_inset

.
 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $X=x$
\end_inset


\begin_inset Quotes erd
\end_inset

 is an event.
 In the example above, 
\begin_inset Formula $X=2$
\end_inset

 corresponds to the event HH.
 Note that we don't write 
\begin_inset Formula $P(X)$
\end_inset

.
 It is meaningless if 
\begin_inset Formula $X$
\end_inset

 takes no value.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a random variable.
 The 
\series bold
distribution
\series default
 of 
\begin_inset Formula $X$
\end_inset

 is the collection of all probabilities of the form 
\begin_inset Formula $P(X\in C)$
\end_inset

 for all sets 
\begin_inset Formula $C$
\end_inset

 of real numbers such that 
\begin_inset Formula $\left\{ X\in C\right\} $
\end_inset

 is an event.
\end_layout

\begin_layout Standard
A 
\series bold
distribution
\series default
 specifies the probabilities associated with 
\bar under
all
\bar default
 values of a random variable.
 In the above example, the distribution of 
\begin_inset Formula $X$
\end_inset

 is given by 
\begin_inset Formula 
\[
P(X=0)=\frac{1}{4},P(X=1)=\frac{1}{2},P(X=2)=\frac{1}{4}.
\]

\end_inset

The distribution of 
\begin_inset Formula $Y$
\end_inset

 is given by 
\begin_inset Formula 
\[
P(Y=0)=\frac{1}{4},P(Y=1)=\frac{1}{2},P(Y=2)=\frac{1}{4}.
\]

\end_inset

The distribution of 
\begin_inset Formula $Z$
\end_inset

 is given by 
\begin_inset Formula 
\[
P(Z=0)=\frac{1}{2},P(Z=1)=\frac{1}{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
You may have noted that the probabilities in a distribution always sums
 up to 
\begin_inset Formula $1$
\end_inset

, as all possible events constitute the entire sample space.
\end_layout

\begin_layout Example
Roll two fair 6-sided dice.
 Let 
\begin_inset Formula $T=X+Y$
\end_inset

 be the total of the two rolls, where 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are the individual rolls.
 Find the distribution for 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Section
Discrete random variables
\end_layout

\begin_layout Definition
We say 
\begin_inset Formula $X$
\end_inset

 is a 
\series bold
discrete random variable
\series default
 if 
\begin_inset Formula $X$
\end_inset

 can take only a finite number 
\begin_inset Formula $k$
\end_inset

 of different values 
\begin_inset Formula $x_{1},\ldots,x_{k}$
\end_inset

 or, at most, an infinite sequence of countable different values 
\begin_inset Formula $x_{1},x_{2},\ldots$
\end_inset

.
 
\end_layout

\begin_layout Definition
The ﬁnite or countably inﬁnite set of values 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $P(X=x)>0$
\end_inset

 is called the 
\series bold
support
\series default
 of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
If a random variable 
\begin_inset Formula $X$
\end_inset

 has a discrete distribution, the 
\series bold
probability mass function
\series default
 (PMF, sometimes also known as 
\series bold
probability function
\series default
, or 
\series bold
frequency function
\series default
) of 
\begin_inset Formula $X$
\end_inset

 is defined as the function 
\begin_inset Formula $p$
\end_inset

 such that 
\begin_inset Formula 
\[
p(x)=P(X=x)
\]

\end_inset

where 
\begin_inset Formula $p(x)\geq0$
\end_inset

 for all possible values of 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $\sum_{\textrm{all }x}p(x)=1$
\end_inset

.
\end_layout

\begin_layout Remark*
\begin_inset Formula $p(x)$
\end_inset

 differs from the probability function 
\begin_inset Formula $P(\cdot)$
\end_inset

.
 
\begin_inset Formula $p(x)$
\end_inset

 is a real-valued function.
 We can manipulate it as normal real-valued functions.
 Some textbooks prefer to use 
\begin_inset Formula $f(x)$
\end_inset

.
 In this book, we use 
\begin_inset Formula $p(x)$
\end_inset

 to distinguish it from the probability density function for continuous
 random variables.
 Sometimes, it is convinient to add a subscript, 
\begin_inset Formula $p_{X}(x)$
\end_inset

, to specify this is the PMF for random variable 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark*
The PMF 
\begin_inset Formula $p(x)$
\end_inset

 of a random variable 
\begin_inset Formula $X$
\end_inset

 must satisfy the following criteria:
\end_layout

\begin_layout Itemize
Nonnegative: 
\begin_inset Formula $p(x)\geq0$
\end_inset

 for all possible values of 
\begin_inset Formula $x$
\end_inset

;
\end_layout

\begin_layout Itemize
Sums to 
\begin_inset Formula $1$
\end_inset

: 
\begin_inset Formula $\sum_{\textrm{all }x}p(x)=1$
\end_inset

.
\end_layout

\begin_layout Standard
There are different ways to represent a PMF.
 We can (1) list all the possible values and their associated probabilities;
 (2) write a formula for the PMF; or (3) visualize it in a graph.
 
\end_layout

\begin_layout Section
Continuous random variables
\end_layout

\begin_layout Definition
We say a random variable 
\begin_inset Formula $X$
\end_inset

 has a 
\series bold
continuous distribution
\series default
 if the possible values of 
\begin_inset Formula $X$
\end_inset

 takes the form of a continuum.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
For a continuous random variable 
\begin_inset Formula $X$
\end_inset

, the 
\series bold
probability density function
\series default
 (PDF) of 
\begin_inset Formula $X$
\end_inset

 is a real-valued function 
\begin_inset Formula $f$
\end_inset

 such that 
\begin_inset Formula 
\[
P(a\leq X\leq b)=\int_{a}^{b}f(x)dx
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $f(x)\geq0$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $\int_{-\infty}^{+\infty}f(x)dx=1$
\end_inset

.
\end_layout

\begin_layout Standard
Continuous random variables are usually measurements.
 Examples include height, weight, temperature, the amount of money and so
 on.
\end_layout

\begin_layout Remark*
PDF differs from the discrete PMF in important ways:
\end_layout

\begin_deeper
\begin_layout Itemize
For a continuous random variable, 
\begin_inset Formula $P(X=x)=0$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

;
\end_layout

\begin_layout Itemize
The quantity 
\begin_inset Formula $f(x)$
\end_inset

 is not a probability.
 To get the probability, we integrate the PDF (probability is the area under
 the PDF): 
\begin_inset Formula 
\[
P(a<X\leq b)=F(b)-F(a)=\int_{a}^{b}f(x)dx.
\]

\end_inset


\end_layout

\begin_layout Itemize
Since any single value has probability 0, including or excluding endpoints
 does not matter.
 
\begin_inset Formula 
\[
P(a<X<b)=P(a<X\leq b)=P(a\leq X<b)=P(a\leq X\leq b).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark*
The PDF 
\begin_inset Formula $f$
\end_inset

 of a continuous random variable must satisfy the following criteria: 
\end_layout

\begin_deeper
\begin_layout Itemize
Nonnegative: 
\begin_inset Formula $f(x)\geq0$
\end_inset

;
\end_layout

\begin_layout Itemize
Integrates to 1: 
\begin_inset Formula $\int_{-\infty}^{\infty}f(x)dx=1$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
More on continuous distributions will be discussed in later chapters.
\end_layout

\begin_layout Section
Cumulative distribution function
\end_layout

\begin_layout Definition
The 
\series bold
cumulative distribution function
\series default
 (CDF) of a random variable 
\begin_inset Formula $X$
\end_inset

 is the function 
\begin_inset Formula $F$
\end_inset

 given by 
\begin_inset Formula $F(x)=P(X\leq x)$
\end_inset

.
 
\end_layout

\begin_layout Definition
For discrete random variables, 
\begin_inset Formula $F(x)=\sum_{k\leq x}p(k)$
\end_inset

.
\end_layout

\begin_layout Definition
For continuous random variables, 
\begin_inset Formula $F(x)=\int_{-\infty}^{x}f(t)dt$
\end_inset

.
 We thus have 
\begin_inset Formula $\frac{dF(x)}{dx}=f(x)$
\end_inset

.
\end_layout

\begin_layout Standard
Unlike PMF or PDF, a cumulative distribution function can be defined for
 both discrete and continuous random variables.
 CDF gives the full distribution of a random variable.
 Given the CDF, we can figure out any probability distribution of the random
 variable.
 For example, 
\begin_inset Formula $P(x_{1}<x\leq x_{2})=F(x_{2})-F(x_{1})$
\end_inset

.
\end_layout

\begin_layout Theorem

\emph on
Any CDF has the following properties:
\end_layout

\begin_layout Itemize
\begin_inset Formula $P(X>x)=1-F(x)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $P(x_{1}<x\leq x_{2})=F(x_{2})-F(x_{1})$
\end_inset


\end_layout

\begin_layout Itemize
Increasing: if 
\begin_inset Formula $x_{1}\leq x_{2}$
\end_inset

, then 
\begin_inset Formula $F(x_{1})\leq F(x_{2})$
\end_inset

.
\end_layout

\begin_layout Itemize
Right-continuous: for any 
\begin_inset Formula $a$
\end_inset

, 
\begin_inset Formula $F(a)=\lim_{x\to a+}F(x)$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $F(x)\to0$
\end_inset

 as 
\begin_inset Formula $x\to-\infty$
\end_inset

; 
\begin_inset Formula $F(x)\to1$
\end_inset

 as 
\begin_inset Formula $x\to+\infty$
\end_inset

.
\end_layout

\begin_layout Section
Data and random variables
\end_layout

\begin_layout Standard
Imagine you’re standing in a bustling café, sipping your coffee while observing
 the scene around you.
 Customers come and go, some ordering their usual drinks, others trying
 something new.
 The number of people who walk in during an hour, the time each spends waiting
 in line, even the total sales for the day—these are all examples of things
 we can measure, and all are influenced by uncertainty.
 We understand these seemingly unpredictable happenings through random variables
 and their distributions.
 
\end_layout

\begin_layout Standard
A random variable is a mathematical abstraction that provides a bridge between
 theoretical probability and real-world data.
 Every dataset you encounter—whether it’s student grades, daily temperatures,
 or stock market prices—can be viewed as observations from random variables.
 
\end_layout

\begin_layout Standard
The fact is, we describe something as a random variable not because they
 are random in nature (like rolling a die), but it is the problem posed
 does not allow a definite answer (the question itself involves likelihood)
 or we do not have enough information to give an answer with certainty.
 In such cases, we would like to give the possible values with their chances
 of being (the idea of distribution).
 
\end_layout

\begin_layout Standard
Despite the outcome of any one event being uncertain, we can use patterns
 from past observations to predict the general behavior of these variables.
 By collecting data, we can figure out how often certain outcomes happen
 and connect them to theoretical models called 
\series bold
distributions
\series default
.
 
\end_layout

\begin_layout Standard
For instance, if you track the heights of 100 people, you might notice that
 most are close to the average, with fewer at the extremes.
 This “bell-shaped curve” is the hallmark of something called the 
\series bold
normal distribution
\series default
, one of the most common patterns in nature.
 Heights, test scores, and even measurement errors tend to follow this distribut
ion.
 
\end_layout

\begin_layout Standard
But not all data fits the same shape.
 If you’re counting the number of cars passing through an intersection in
 a given hour, you might find the 
\series bold
Poisson distribution
\series default
 is a better fit.
 This pattern shows up whenever you’re dealing with counts of events over
 time or space—like customer arrivals at a store or typos in a book.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccccccc}
\textrm{Question with} & \rightarrow & \textrm{Data Collection} & \rightarrow & \textrm{Patterns}\\
\textrm{uncertainty} &  & \downarrow &  & \downarrow\\
 &  & \textrm{Random Variables} & \rightarrow & \textrm{Distributions} & \rightarrow & \textrm{Predictions}
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
By linking real-world data to these theoretical models, random variables
 let us make predictions.
 How many customers will show up next week? What’s the chance of a traffic
 jam during rush hour? Random variables give us the tools to answer these
 questions with confidence.
 
\end_layout

\begin_layout Standard
Viewing the world through the lens of random variables has several benefits:
 (1) It helps us deal with uncertainty.
 Random variables give us a framework to understand situations where outcomes
 aren’t guaranteed.
 For example, a meteorologist uses random variables to estimate the chance
 of rain, so you know whether to carry an umbrella.
 (2) It connects theory to reality.
 By analyzing data, we can identify which theoretical models describe the
 randomness we observe.
 This helps businesses, scientists, and policymakers make better decisions.
 (3) It allows for better planning.
 
\end_layout

\begin_layout Standard
Suppose you’re running an online store.
 Knowing that the number of daily orders follows a certain distribution
 can help you manage inventory and staffing.
 Suppose you’re tracking the number of customers visiting your café each
 day.
 You notice the number fluctuates between 50 and 100, with an average of
 75.
 By treating this as a random variable, you can estimate the likelihood
 of having fewer than 60 customers tomorrow (useful for planning staff schedules
); or the probability of exceeding 90 customers on a holiday (important
 for stocking supplies).
 
\end_layout

\begin_layout Standard
In the grand scheme of things, random variables are more than just mathematical
 tools—they’re a way to make sense of life’s unpredictability.
 So, the next time you see data—whether it’s sports stats, sales figures,
 or even your social media likes—remember: Behind the numbers is a pattern
 of randomness waiting to be understood.
 And with random variables, you have the key to unlock it.
 
\end_layout

\begin_layout Section
Summary
\end_layout

\begin_layout Standard
1.
 A random variable serves as a numerical representation of a specific aspect
 of an experiment or a random phenomenon.
 It allows us to quantify outcomes in a meaningful way, enabling analysis
 and interpretation of the results.
 For example, in a coin toss, we might define a random variable to represent
 the number of heads observed in a series of flips.
\end_layout

\begin_layout Standard
2.
 We typically model situations as random variables because we often lack
 sufficient information to draw definitive conclusions.
 In these instances, probability provides a framework for making educated
 guesses about uncertain outcomes.
 It acts as a compromise, allowing us to express our uncertainty mathematically
 and make decisions based on incomplete information.
 This is particularly useful in fields like finance, economics, and social
 sciences, where uncertainties are inherent.
\end_layout

\begin_layout Standard
3.
 Generally, we do not have access to the true distribution of a random variable,
 which is why we rely on finite samples, often derived from historical records,
 to approximate this distribution.
 By analyzing past data, we can estimate the probabilities associated with
 different outcomes.
 However, it's important to note that these approximations are subject to
 sampling variability and may not capture the entire complexity of the underlyin
g phenomenon.
 Thus, understanding the limitations of our data and the potential for biases
 is crucial when making inferences based on random variables.
\end_layout

\begin_layout Chapter
Discrete Distributions
\end_layout

\begin_layout Section
Bernoulli distribution
\end_layout

\begin_layout Standard
We introduce some theoretical distributions from now on.
 These distributions are important because they provide standardized models
 for common 
\begin_inset Quotes eld
\end_inset

patterns
\begin_inset Quotes erd
\end_inset

 of random processes.
 We develop these distributions from idealized assumptions.
 In practice, we usually do not know what is the 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 distribution of the question of interest.
 Typically, we 
\begin_inset Quotes eld
\end_inset

fit
\begin_inset Quotes erd
\end_inset

 the question into a theoretical distribution according to their proximity
 to the assumptions.
\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $X$
\end_inset

 is said to have the 
\series bold
Bernoulli distribution
\series default
, denoted as 
\begin_inset Formula $X\text{\ensuremath{\sim\textrm{Bern}(p)}}$
\end_inset

, if 
\begin_inset Formula $X$
\end_inset

 has only two possible values, 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

, and 
\begin_inset Formula $P(X=1)=p$
\end_inset

, 
\begin_inset Formula $P(X=0)=1-p$
\end_inset

.
\end_layout

\begin_layout Standard
The PMF of a Bernoulli random variable 
\begin_inset Formula $X$
\end_inset

 is given by 
\begin_inset Formula 
\[
p_{X}(x)=\begin{cases}
p & \textrm{if }x=1,\\
1-p & \textrm{if }x=0.
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
This can also be expressed as 
\begin_inset Formula 
\[
p_{X}(x)=p^{x}(1-p)^{1-x}\textrm{ for }x\in\left\{ 0,1\right\} .
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The Bernoulli distribution is widely used because it provides a simple yet
 powerful framework for modeling binary outcomes, where events can be classified
 as 
\emph on
success
\emph default
 or 
\emph on
failure
\emph default
 (
\series bold
Bernoulli trial
\series default
).
 This versatility allows it to be applied across a wide range of fields
 and scenarios.
 
\end_layout

\begin_layout Example
One key reason for its popularity is that many real-world phenomena can
 be distilled into binary outcomes.
 For instance, in quality control, a product can either pass or fail inspection;
 in healthcare, a treatment may either be effective or ineffective; and
 in marketing, a consumer may either purchase a product or not.
 Because nearly any situation involving two possible outcomes can be framed
 in terms of success and failure, the Bernoulli distribution becomes a natural
 choice for analysis.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
An 
\series bold
indicator variable
\series default
 assigns a value of 
\begin_inset Formula $1$
\end_inset

 to represent the occurrence of a specific event (success) and a value of
 
\begin_inset Formula $0$
\end_inset

 to indicate that the event did not happen (failure).
 This binary representation allows us to convert any event into a random
 variable, 
\begin_inset Formula 
\[
I_{A}=\begin{cases}
1 & A\textrm{ happens with probability }p\\
0 & \textrm{otherwise, with probability }1-p
\end{cases}
\]

\end_inset

which can then be modeled as a Berboulli distribution 
\begin_inset Formula $I_{A}\sim Bern(p)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Bernoulli distribution serves as the foundation for more complex models,
 such as the binomial distribution, which deals with multiple independent
 trials.
 This hierarchical structure makes it easier to build upon and develop more
 sophisticated statistical methods.
 Its simplicity also facilitates calculations and interpretations, making
 it accessible for researchers and practitioners alike.
\end_layout

\begin_layout Section
Binomial distribution
\end_layout

\begin_layout Definition
Suppose 
\begin_inset Formula $X_{1},X_{2},\dots,X_{n}$
\end_inset

 are independent and identical 
\begin_inset Formula $\textrm{Bern}(p)$
\end_inset

 distributions.
 Let 
\begin_inset Formula $X$
\end_inset

 be the total number of successes of the 
\begin_inset Formula $n$
\end_inset

 independent trials.
 That is, 
\begin_inset Formula $X=X_{1}+X_{2}+\cdots+X_{n}$
\end_inset

.
 Then 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
Binomial distribution
\series default
, 
\begin_inset Formula $X\sim\textrm{Bin}(n,p)$
\end_inset

.
\end_layout

\begin_layout Standard
The probability mass function of 
\begin_inset Formula $X$
\end_inset

 directly follows from the combination theory:
\begin_inset Formula 
\[
p_{X}(k)=P(X=k)=\binom{n}{k}p^{k}(1-p)^{n-k}.
\]

\end_inset


\end_layout

\begin_layout Standard
This is a valid PMF because, by the Binomial theorem, we have
\begin_inset Formula 
\[
\sum_{k=0}^{n}p_{X}(k)=\sum_{k=0}^{n}\binom{n}{k}p^{k}(1-p)^{n-k}=(p+(1-p))^{n}=1.
\]

\end_inset


\end_layout

\begin_layout Example
In the previous example of tossing two coins, we compute the distribution
 of 
\begin_inset Formula $X$
\end_inset

 by counting the equally likely outcomes in an event.
 We can get the same result by realizing it is a Binomial distribution.
 
\begin_inset Formula $X\sim\textrm{Bin}(2,1/2)$
\end_inset

.
 Since each coin tossing is an independent Bernoulli trial.
 The probabilities come directly from the PMF.
 
\begin_inset Formula 
\begin{align*}
P(X=0) & =p_{X}(0)=\binom{2}{0}\left(\frac{1}{2}\right)^{0}\left(\frac{1}{2}\right)^{2}=\frac{1}{4};\\
P(X=1) & =p_{X}(1)=\binom{2}{1}\left(\frac{1}{2}\right)^{1}\left(\frac{1}{2}\right)^{1}=\frac{1}{2};\\
P(X=2) & =p_{X}(2)=\binom{2}{2}\left(\frac{1}{2}\right)^{2}\left(\frac{1}{2}\right)^{0}=\frac{1}{4}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Utilizing the Binomial distribution also allows us to generalize the problem.
 Suppose we are tossing 
\begin_inset Formula $n$
\end_inset

 coins, we want to find the probability of getting 
\begin_inset Formula $k$
\end_inset

 heads.
 It is almost impossible to count all the possible outcomes, but the answer
 immediately follows from the Binomial PMF.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The Binomial distribution is often used to model the probability that a
 certain number of “successes” occur during a certain number of trials.
 Here is an example.
 Suppose it is known that 5% of adults who take a certain medication experience
 negative side effects.
 We want to find the probability that a certain number of patients in a
 random sample of 100 will experience negative side effects.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number patients that experience negative side effects, it follows
 that 
\begin_inset Formula $X\sim\textrm{Bin}(100,0.05)$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim Bin(n,p)$
\end_inset

 and 
\begin_inset Formula $Y\sim Bin(m,p)$
\end_inset

 be two independent Binomail random variables.
 Show that 
\begin_inset Formula $X+Y\sim Bin(n+m,p)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Proof
\emph default
.
 By the definition of the Binomial distribution, 
\begin_inset Formula $X$
\end_inset

 is the number of successes in 
\begin_inset Formula $n$
\end_inset

 independent trials, and 
\begin_inset Formula $Y$
\end_inset

 is the number of successes in 
\begin_inset Formula $m$
\end_inset

 independent trials.
 Therefore, 
\begin_inset Formula $X+Y$
\end_inset

 is the number of successes in 
\begin_inset Formula $n+m$
\end_inset

 independent trials, which is exactly 
\begin_inset Formula $Bin(n+m,p)$
\end_inset

.
 
\end_layout

\begin_layout Example
We can also prove it using indicator variables.
 
\begin_inset Formula $X=\sum_{i=1}^{n}X_{i}$
\end_inset

 where 
\begin_inset Formula $X_{i}\sim Bern(p)$
\end_inset

; 
\begin_inset Formula $Y=\sum_{j=1}^{m}Y_{j}$
\end_inset

 where 
\begin_inset Formula $Y_{j}\sim Bern(p)$
\end_inset

.
 Therefore, 
\begin_inset Formula $X+Y=\sum_{i=1}^{n}X_{i}+\sum_{j=1}^{m}Y_{j}=\sum_{k=1}^{n+m}Z_{k}$
\end_inset

.
 Since 
\begin_inset Formula $X_{i}$
\end_inset

 and 
\begin_inset Formula $Y_{j}$
\end_inset

 are identical Bernoulli random variables, 
\begin_inset Formula $Z_{k}=X_{k}$
\end_inset

 for 
\begin_inset Formula $k=1,\dots,n$
\end_inset

; 
\begin_inset Formula $Z_{k}=Y_{k-n}$
\end_inset

 for 
\begin_inset Formula $k=n+1,\dots,n+m$
\end_inset

.
\end_layout

\begin_layout Example
Another way is to leverage the PMF: 
\begin_inset Formula 
\begin{align*}
P(X+Y=k) & =\sum_{i+j=k}P(X=i)P(Y=j)\\
 & =\sum_{i+j=k}\binom{n}{i}p^{i}(1-p)^{n-i}\binom{m}{j}p^{j}(1-p)^{m-j}\\
 & =\sum_{i+j=k}\binom{n}{i}\binom{m}{j}p^{i+j}(1-p)^{m+n-i-j}\\
 & =p^{k}(1-p)^{m+n-k}\sum_{i=0}^{k}\binom{n}{i}\binom{m}{k-i}\\
 & =p^{k}(1-p)^{m+n-k}\binom{n+m}{k}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The last step: 
\begin_inset Formula $\binom{n+m}{k}=\sum_{i=0}^{k}\binom{n}{i}\binom{m}{k-i}$
\end_inset

 is known as the Vandermonde's identity.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let’s explore an example that appears to be Binomial but is, in fact, not
 a Binomial distribution.
 Given a 5-card hand.
 Find the distribution of the number of aces.
 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of aces.
 It is tempting to say 
\begin_inset Formula $X\sim Bin(5,p)$
\end_inset

.
 But this not correct.
 Because having one ace is NOT independent from having another ace.
 We need to use the classical approach: 
\begin_inset Formula 
\[
P(X=k)=\frac{C_{4}^{k}C_{48}^{5-k}}{C_{52}^{5}}.
\]

\end_inset


\end_layout

\begin_layout Example
This example leads to a named distribution that is closed related to Binomial
 — Hypergeometric distribution.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Hypergeometric distribution
\end_layout

\begin_layout Standard
Suppose we have a box ﬁlled with 
\begin_inset Formula $w$
\end_inset

 white and 
\begin_inset Formula $b$
\end_inset

 black balls.
 We draw 
\begin_inset Formula $n$
\end_inset

 balls out of the box 
\bar under
with replacement
\bar default
.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of white balls.
 Then 
\begin_inset Formula $X\sim Bin(n,w/(w+b))$
\end_inset

.
 Since the draws are independent Bernoulli trials, each with probability
 
\begin_inset Formula $w/(w+b)$
\end_inset

 of success.
 If we instead sample 
\bar under
without replacement
\bar default
, then the number of white balls follows a 
\series bold
Hypergeometric distribution
\series default
.
 We denote this by 
\begin_inset Formula $X\sim\textrm{HGeom}(w,b,n)$
\end_inset

.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X\sim\textrm{HGeom}(w,b,n)$
\end_inset

, then the PMF of 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula 
\[
p_{X}(k)=\frac{\binom{w}{k}\binom{b}{n-k}}{\binom{w+b}{n}},
\]

\end_inset

for integers 
\begin_inset Formula $k$
\end_inset

 satisfying 
\begin_inset Formula $0\leq k\leq w$
\end_inset

 and 
\begin_inset Formula $0\leq n-k\leq b$
\end_inset

, and 
\begin_inset Formula $p_{X}(k)=0$
\end_inset

 otherwise.
\end_layout

\begin_layout Example
Let's redo the ace-card exercise with Hypergeometric distribution.
 In a 5-card hand, the number of aces in the hand has the 
\begin_inset Formula $\textrm{HGeom}(4,48,5)$
\end_inset

 distribution, which can be seen by thinking of the aces as white balls
 and the non-aces as black balls.
 The probability of having exactly three aces is 
\begin_inset Formula $\frac{\binom{4}{4}\binom{48}{2}}{\binom{52}{5}}=0.0017\%$
\end_inset

.
\end_layout

\begin_layout Standard
The Binomial and Hypergeometric distributions are often confused.
 Both are discrete distributions taking on integer values between 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 for some 
\begin_inset Formula $n$
\end_inset

, and both can be interpreted as the number of successes in 
\begin_inset Formula $n$
\end_inset

 Bernoulli trials.
 However, a crucial part of the Binomial story is that the Bernoulli trials
 involved are 
\bar under
independent
\bar default
.
 The Bernoulli trials in the Hypergeometric story are 
\bar under
dependent
\bar default
, since the sampling is done without replacement.
\end_layout

\begin_layout Section
Geometric and Negative Binomial
\end_layout

\begin_layout Definition
Consider a sequence of independent Bernoulli trials, each with the same
 success probability 
\begin_inset Formula $p$
\end_inset

.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of failures before the first successful trial.
 Then 
\begin_inset Formula $X$
\end_inset

 has a 
\series bold
Geometric distribution
\series default
, 
\begin_inset Formula $X\sim\textrm{Geom}(p)$
\end_inset

.
\end_layout

\begin_layout Standard
Let's derive the PMF for the Geometric distribution.
 By definition,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(X=k)=q^{k}p
\]

\end_inset

where 
\begin_inset Formula $q=1-p$
\end_inset

.
 This is a valid PMF because 
\begin_inset Formula 
\[
\sum_{k=0}^{\infty}q^{k}p=p\sum_{k=0}^{\infty}q^{k}=\frac{p}{1-q}=1.
\]

\end_inset

The expectation of 
\begin_inset Formula $X$
\end_inset

 is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(X)=\sum_{k=0}^{\infty}k\cdot q^{k}p=p\sum_{k=0}^{\infty}kq^{k}=p\frac{q}{p^{2}}=\frac{q}{p}.
\]

\end_inset

To see why this holds, taking derivative with respect to 
\begin_inset Formula $q$
\end_inset

 on both sides of 
\begin_inset Formula $\sum_{k=0}^{\infty}q^{k}=\frac{1}{1-q}$
\end_inset

 yields
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{k=1}^{\infty}kq^{k-1}=\frac{1}{(1-q)^{2}};
\]

\end_inset

Then multiply both sides by 
\begin_inset Formula $q$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{k=1}^{\infty}kq^{k}=\frac{q}{(1-q)^{2}}=\frac{q}{p^{2}}.
\]

\end_inset


\end_layout

\begin_layout Standard
A generalization of the Geometric distribution is the Negative Binomial
 distribution.
 
\end_layout

\begin_layout Definition
In a sequence of independent Bernoulli trials with success probability 
\begin_inset Formula $p$
\end_inset

, if 
\begin_inset Formula $X$
\end_inset

 is the number of failures before the 
\begin_inset Formula $r$
\end_inset

-th success, then 
\begin_inset Formula $X$
\end_inset

 is said to have a 
\series bold
Negative Binomial distribution
\series default
, denoted 
\begin_inset Formula $X\sim\textrm{NBin}(r,p)$
\end_inset

.
\end_layout

\begin_layout Standard
The PMF for Negative Binomial distribution, by definition, is given by 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(X=k)=\binom{k+r-1}{r-1}q^{k}p^{r}.
\]

\end_inset


\end_layout

\begin_layout Standard
To compute the expectation, let 
\begin_inset Formula $X=X_{1}+\cdots+X_{r}$
\end_inset

 where 
\begin_inset Formula $X_{i}$
\end_inset

 is the number of failures between the 
\begin_inset Formula $(i-1)$
\end_inset

-th success and the 
\begin_inset Formula $i$
\end_inset

-th success, 
\begin_inset Formula $1\leq i\leq r$
\end_inset

.
 Then 
\begin_inset Formula $X_{i}\sim\textrm{Geom}(p)$
\end_inset

.
 By linearity of expectations,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(X)=E(X_{1})+\cdots+E(X_{r})=r\frac{1-p}{p}.
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Toy collector
\end_layout

\end_inset

 There are 
\begin_inset Formula $n$
\end_inset

 types of toys.
 Assume each time you buy a toy, it is equally likely to be any of the 
\begin_inset Formula $n$
\end_inset

 types.
 What is the expected number of toys you need to buy until you have a complete
 set? 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Define the following random variables:
\begin_inset Formula 
\[
\begin{aligned}T= & T_{1}+T_{2}+\cdots+T_{n}\\
T_{1}= & \textrm{number of toys until 1st new type}\\
T_{2}= & \textrm{additional number of toys until 2nd new type}\\
T_{3}= & \textrm{additional number of toys until 3rd new type}\\
\vdots
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Example
We know, 
\begin_inset Formula $T_{1}=1$
\end_inset

, 
\begin_inset Formula $T_{2}-1\sim\textrm{Geom}\left(\frac{n-1}{n}\right)$
\end_inset

,..., 
\begin_inset Formula $T_{j}-1\sim\textrm{Geom}\left(\frac{n-(j-1)}{n}\right)$
\end_inset

.
 Thus,
\begin_inset Formula 
\[
\begin{aligned}E(T)= & E(T_{1})+E(T_{2})+\cdots+E(T_{n})\\
= & 1+\frac{n}{n-1}+\frac{n}{n-2}+\cdots+\frac{1}{n}\\
= & n(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n})\\
\to & n(\log n+0.577).
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Example
If 
\begin_inset Formula $n=5$
\end_inset

, 
\begin_inset Formula $E(T)\approx11$
\end_inset

; if 
\begin_inset Formula $n=10$
\end_inset

, 
\begin_inset Formula $E(T)\approx29$
\end_inset

.
\end_layout

\begin_layout Section
Discrete uniform distribution
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $a\leq b$
\end_inset

 be integers.
 Suppose that the value of a random variable 
\begin_inset Formula $X$
\end_inset

 is equally likely to be each of the integers 
\begin_inset Formula $a,\dots,b$
\end_inset

.
 Then we say that 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
discrete uniform distribution
\series default
 on the integers 
\begin_inset Formula $a,\dots,b$
\end_inset

.
 We denote it as 
\begin_inset Formula $X\sim DUnif(a,\dots,b)$
\end_inset

.
 
\end_layout

\begin_layout Definition
The PMF of 
\begin_inset Formula $X\sim DUnif(a,\dots,b)$
\end_inset

 is given by 
\begin_inset Formula 
\[
p(x)=\begin{cases}
\frac{1}{b-a+1} & \textrm{for }x=a,\dots,b\\
0 & \textrm{otherwise}
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X$
\end_inset

 be a random number from 1,2,...,100.
 Then 
\begin_inset Formula $X\sim DUnif(1,...,100)$
\end_inset

.
 And 
\begin_inset Formula $P(X=k)=1/100$
\end_inset

 for any 
\begin_inset Formula $k=1,...,100$
\end_inset

.
\end_layout

\begin_layout Example
The uniform distribution can be defined in discrete cases, but its continuous
 form is more well-known.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 be two real numbers such that 
\begin_inset Formula $a<b$
\end_inset

.
 Let 
\begin_inset Formula $X$
\end_inset

 be a random variable such that 
\begin_inset Formula $a\leq X\leq b$
\end_inset

 and, for every subinterval interval of 
\begin_inset Formula $[a,b]$
\end_inset

, the probability that 
\begin_inset Formula $X$
\end_inset

 belongs to that subinterval is proportional to the length of that subinterval.
 Then we say 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
uniform distribution
\series default
 on the interval 
\begin_inset Formula $[a,b]$
\end_inset

.
 We denote it as 
\begin_inset Formula $X\sim Unif(a,b)$
\end_inset

.
\end_layout

\begin_layout Definition
The PDF of 
\begin_inset Formula $X\sim Unif(a,b)$
\end_inset

 is given by 
\begin_inset Formula 
\[
f(x)=\begin{cases}
\frac{1}{b-a} & \textrm{for }a\leq x\leq b\\
0 & \textrm{otherwise}
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Definition
We verify this is a valid PDF because 
\begin_inset Formula 
\[
\int_{a}^{b}f(x)dx=\int_{a}^{b}\frac{1}{b-a}dx=\frac{1}{b-a}\int_{a}^{b}dx=1;
\]

\end_inset


\end_layout

\begin_layout Definition
or the area of the rectangle surrounded by 
\begin_inset Formula $x=a,x=b$
\end_inset

 and 
\begin_inset Formula $f(x)=\frac{1}{b-a}$
\end_inset

 is 1.
 
\end_layout

\begin_layout Section
Functions of random variables
\end_layout

\begin_layout Standard
Functions of random variables are also random variables.
 If 
\begin_inset Formula $X$
\end_inset

 is a random variable, then 
\begin_inset Formula $X^{2}$
\end_inset

, 
\begin_inset Formula $e^{X}$
\end_inset

 and 
\begin_inset Formula $\sin(X)$
\end_inset

 are also random variables.
 
\end_layout

\begin_layout Definition
For an experiment with sample space 
\begin_inset Formula $S$
\end_inset

, a random variable 
\begin_inset Formula $X$
\end_inset

, and a function 
\begin_inset Formula $g:\mathbb{R}\to\mathbb{R}$
\end_inset

.
 
\begin_inset Formula $g(X)$
\end_inset

 is the random variable that maps 
\begin_inset Formula $s$
\end_inset

 to 
\begin_inset Formula $g(X(s))$
\end_inset

 for all 
\begin_inset Formula $s\in S$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 be a discrete random variable and 
\begin_inset Formula $g:\mathbb{R}\to\mathbb{R}$
\end_inset

.
 If 
\begin_inset Formula $g(X)$
\end_inset

 is a one-to-one function.
 Then the support of 
\begin_inset Formula $g(X)$
\end_inset

 is the set of all 
\begin_inset Formula $y$
\end_inset

 such that 
\begin_inset Formula $x=g^{-1}(y)$
\end_inset

 is in the support of 
\begin_inset Formula $X$
\end_inset

.
 The PMF of 
\begin_inset Formula $g(X)$
\end_inset

 is 
\begin_inset Formula 
\[
P(g(X)=y)=P(g(X)=g(x))=P(X=x).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 be a discrete random variable and 
\begin_inset Formula $g:\mathbb{R}\to\mathbb{R}$
\end_inset

.
 Then the support of 
\begin_inset Formula $g(X)$
\end_inset

 is the set of all 
\begin_inset Formula $y$
\end_inset

 such that 
\begin_inset Formula $g(x)=y$
\end_inset

 for at least one 
\begin_inset Formula $x$
\end_inset

 in the support of 
\begin_inset Formula $X$
\end_inset

.
 The PMF of 
\begin_inset Formula $g(X)$
\end_inset

 is 
\begin_inset Formula 
\[
P(g(X)=y)=\sum_{x:g(x)=y}P(X=x).
\]

\end_inset


\end_layout

\begin_layout Definition
Give an experiment with sample space 
\begin_inset Formula $S$
\end_inset

, if 
\begin_inset Formula $X,Y$
\end_inset

 are random variables that map 
\begin_inset Formula $s\in S$
\end_inset

 to 
\begin_inset Formula $X(s)$
\end_inset

 and 
\begin_inset Formula $Y(s)$
\end_inset

, then 
\begin_inset Formula $g(X,Y)$
\end_inset

 is the random variable that maps 
\begin_inset Formula $s$
\end_inset

 to 
\begin_inset Formula $g(X(s),Y(s))$
\end_inset

 for all 
\begin_inset Formula $s\in S$
\end_inset

.
\end_layout

\begin_layout Example
We roll two fair 6-sided dice.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number on the first die, and 
\begin_inset Formula $Y$
\end_inset

 be the number on the second die.
 Find the distribution of 
\begin_inset Formula $\max(X,Y)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
We just show how to compute one case in the distribution, other cases are
 similar.
\begin_inset Formula 
\begin{align*}
P(\max(X,Y)=5) & =P(X=5,Y\leq4)+P(X\leq4,Y=5)+P(X=5,Y=5)\\
 & =2P(X=5,Y\leq4)+1/36\\
 & =2(4/36)+1/36=9/36.
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Independence of random variables
\end_layout

\begin_layout Definition
Random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
independent
\series default
 if 
\begin_inset Formula 
\[
P(X\leq x,Y\leq y)=P(X\leq x)P(Y\leq y)
\]

\end_inset

for all 
\begin_inset Formula $x,y\in\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Definition
In the discrete case, this is equivalent to the condition 
\begin_inset Formula 
\[
P(X=x,Y=y)=P(X=x)P(Y=y)
\]

\end_inset

for all possible values of 
\begin_inset Formula $x,y$
\end_inset

.
\end_layout

\begin_layout Definition
In the continuous case, this is equivalent to the condition 
\begin_inset Formula 
\[
f(x,y)=f_{X}(x)f_{Y}(y)
\]

\end_inset

for all 
\begin_inset Formula $x,y$
\end_inset

, where 
\begin_inset Formula $f,f_{X},f_{Y}$
\end_inset

 are density functions.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent, then any function of 
\begin_inset Formula $X$
\end_inset

 is independent of any function of 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Definition
If a given number of random variables are independent and have the same
 distribution, we call them 
\series bold
independent and identically distributed
\series default
, or 
\series bold
i.i.d
\series default
 for short.
\end_layout

\begin_layout Itemize
Independent and identically distributed (
\begin_inset Formula $X,Y$
\end_inset

 independent die rolls)
\end_layout

\begin_layout Itemize
Independent and not identically distributed (
\begin_inset Formula $X$
\end_inset

: die roll; 
\begin_inset Formula $Y$
\end_inset

: coin flip)
\end_layout

\begin_layout Itemize
Dependent and identically distributed (
\begin_inset Formula $X$
\end_inset

: number of Heads; 
\begin_inset Formula $Y$
\end_inset

: number of Tails)
\end_layout

\begin_layout Itemize
Dependent and not identically distributed (
\begin_inset Formula $X$
\end_inset

: economic growth; 
\begin_inset Formula $Y$
\end_inset

: presidential election)
\end_layout

\begin_layout Definition
Random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
conditionally independent
\series default
 given 
\begin_inset Formula $Z$
\end_inset

 if 
\begin_inset Formula 
\[
P(X\leq x,Y\leq y|Z=z)=P(X\leq x|Z=z)P(Y\leq y|Z=z)
\]

\end_inset

for all 
\begin_inset Formula $x,y\in\mathbb{R}$
\end_inset

 and all 
\begin_inset Formula $z$
\end_inset

 in the support of 
\begin_inset Formula $Z$
\end_inset

.
 
\end_layout

\begin_layout Definition
For discrete random variables, the equivalent definition is to require 
\begin_inset Formula 
\[
P(X=x,Y=y|Z=z)=P(X=x|Z=z)P(Y=y|Z=z).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Application: seller ratings*
\end_layout

\begin_layout Standard
This example involves multiple types of discrete distributions.
 The technique used to solve this problem aligns with Bayesian inference,
 which is beyond the scope of this course.
 However, it remains an interesting case.
 The procedure illustrates the process of statistical modeling: we begin
 with an assumption and a proposed statistical model, then update it with
 new data.
 Finally, we draw inferences based on the model, typically addressing the
 question we aim to answer.
 You are not required to understand everything in this example.
 Nonetheless, it helps to develop a mindset of statistical inference early
 in the study.
\end_layout

\begin_layout Standard
Suppose you are shopping a product online.
 There are three sellers with the following ratings: 
\end_layout

\begin_layout Itemize
Seller 1: 100% positive out of 10 reviews
\end_layout

\begin_layout Itemize
Seller 2: 96% positive out of 50 reviews 
\end_layout

\begin_layout Itemize
Seller 3: 93% positive out of 200 reviews 
\end_layout

\begin_layout Standard
Which seller is likely to give the best service?
\end_layout

\begin_layout Standard
The problem is intriguing because it is obvious that higher ratings do not
 necessarily means higher satisfaction.
 We have to weight in the number of reviews.
 The more reviews, the more trustworthy the ratings are.
 Let 
\begin_inset Formula $X_{j}^{(i)}$
\end_inset

 be a random variable that means consumer 
\begin_inset Formula $j$
\end_inset

 is satisfied with seller 
\begin_inset Formula $i$
\end_inset

, where 
\begin_inset Formula $i\in\left\{ 1,2,3\right\} $
\end_inset

.
 Assume 
\begin_inset Formula $X_{j}^{(i)}$
\end_inset

 follows a Bernoulli distribution:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{j}^{(i)}=\begin{cases}
1 & \textrm{satisfaction with probability \ensuremath{\theta_{i}}}\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\theta_{i}$
\end_inset

 is an unknown parameter of seller 
\begin_inset Formula $i$
\end_inset

 that captures their 
\begin_inset Quotes eld
\end_inset

genuine
\begin_inset Quotes erd
\end_inset

 satisfaction rate.
 We assume the consumers independently write their ratings.
 The overall positive rate of seller 
\begin_inset Formula $i$
\end_inset

 is therefore 
\begin_inset Formula $R_{i}=\frac{1}{n_{i}}\sum_{j}X_{j}^{(i)}$
\end_inset

 where 
\begin_inset Formula $n_{i}$
\end_inset

 is the total number of reviews.
 We want to infer the value of 
\begin_inset Formula $\theta_{i}$
\end_inset

 from their observed positive rate 
\begin_inset Formula $R_{i}$
\end_inset

.
 From now on we drop the seller index 
\begin_inset Formula $i$
\end_inset

 to simply the notation since it is symmetric for all sellers.
 
\end_layout

\begin_layout Standard
Because we have no prior knowledge about 
\begin_inset Formula $\theta$
\end_inset

.
 We assume that 
\begin_inset Formula $\theta$
\end_inset

 takes any value from 
\begin_inset Formula $[0,1]$
\end_inset

 equally likely, i.e.
 
\begin_inset Formula $\theta\sim\textrm{Unif}(0,1)$
\end_inset

.
 Assuming each 
\begin_inset Formula $X_{j}$
\end_inset

 is independent and identical, then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S=X_{1}+X_{2}+\dots+X_{n}
\]

\end_inset


\end_layout

\begin_layout Standard
follows the Binomial distribution with PMF:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(k|\theta)=\binom{n}{k}\theta^{k}(1-\theta)^{n-k}
\]

\end_inset


\end_layout

\begin_layout Standard
Our goal is to find: 
\begin_inset Formula $p(\theta|k)$
\end_inset

.
 Recall that the Bayes' rule allows us to invert the conditional probability:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned}p(\theta|k) & =\frac{p(k|\theta)p(\theta)}{p(k)}=\frac{p(k|\theta)p(\theta)}{\int_{-\infty}^{\infty}p(k|\theta)p(\theta)d\theta}\\[1em]\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\theta\sim\textrm{Unif}(0,1)$
\end_inset

, we have
\begin_inset Formula 
\[
p(\theta)=\begin{cases}
1 & \textrm{if }\theta\in[0,1]\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
We now focus on 
\begin_inset Formula $\theta\in[0,1]$
\end_inset

, since the probability is 
\begin_inset Formula $0$
\end_inset

 otherwise.
 Substitute in the PMF of the Binomial distribution, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\theta|k)=\frac{\binom{n}{k}\theta^{k}(1-\theta)^{n-k}}{\int_{0}^{1}\binom{n}{k}\theta^{k}(1-\theta)^{n-k}d\theta}
\]

\end_inset


\end_layout

\begin_layout Standard
The hard part is to evaluate the integral.
 We state without proof (this is known as the Beta function, which we will
 prove in later chapters):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{0}^{1}\theta^{k}(1-\theta)^{n-k}=\frac{k!(n-k)!}{(n+1)!}
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\theta|k)=\frac{(n+1)!}{k!(n-k)!}\theta^{k}(1-\theta)^{n-k}
\]

\end_inset


\end_layout

\begin_layout Standard
Now suppose you are the next customer.
 The probability that you would be satisfied is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned}P(X_{n+1}=1|S=k)= & \int_{0}^{1}P(x_{n+1}=1|\theta)p(\theta|k)d\theta\\
= & \int_{0}^{1}\theta\times\frac{(n+1)!}{k!(n-k)!}\theta^{k}(1-\theta)^{n-k}d\theta\\
= & \frac{(n+1)!}{k!(n-k)!}\int_{0}^{1}\theta^{k+1}(1-\theta)^{(n+1)-(k+1)}d\theta\\
= & \frac{(n+1)!}{k!(n-k)!}\times\frac{(k+1)!(n-k)!}{(n+2)!}\\
= & \frac{k+1}{n+2}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Now we substitute the ratings for the three sellers:
\end_layout

\begin_layout Itemize
Seller 1: 
\begin_inset Formula $n=10,k=10$
\end_inset


\end_layout

\begin_layout Itemize
Seller 2: 
\begin_inset Formula $n=50,k=48$
\end_inset


\end_layout

\begin_layout Itemize
Seller 3: 
\begin_inset Formula $n=200,k=186$
\end_inset


\end_layout

\begin_layout Standard
The probabilities that you would be satisfied with each seller are: 92%,
 94%, 93%.
 The result is known as the 
\series bold
Laplace's rule of succession
\series default
.
 The rule of thumb is, pretending we have too more reviews: one is positive,
 the other is negative.
 Compute the satisfaction rate as 
\begin_inset Formula $\frac{k+1}{n+2}$
\end_inset

.
\end_layout

\begin_layout Section
Further comments
\end_layout

\begin_layout Subsection*
How to choose a distribution?
\end_layout

\begin_layout Standard
The fact is, we never know the 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 distribution of a real-world problem.
 When building a probability model, the distribution is typically 
\emph on
assumed
\emph default
 based on the nature of the data and the problem at hand.
 This assumption is crucial because the probability distribution determines
 how the random variable behaves, including its likelihood of taking specific
 values.
 Typically, this process involves:
\end_layout

\begin_layout Enumerate
Choosing the distribution: Based on the characteristics of the real-world
 situation or data, you assume an appropriate probability distribution.
 For example, if you're modeling the number of successes in a fixed number
 of independent trials, you might assume a Binomial distribution.
\end_layout

\begin_layout Enumerate
Assumptions behind the distribution: Every distribution has underlying assumptio
ns.
 For example, a Binomial distribution assumes independent trials with two
 possible outcomes (success/failure) and a constant probability of success.
 
\end_layout

\begin_layout Enumerate
Fitting the model: Once you assume a distribution, you use data to estimate
 parameters of the distribution (e.g., mean, variance, or rate parameters),
 which allows you to make probabilistic predictions and inferences.
\end_layout

\begin_layout Standard
It is important to stress that the data we have collected from real events
 does not directly reveal the 
\series bold
Data Generating Process (DGP)
\series default
, which is the true underlying process that produces the data.
 Instead, when we assume a distribution, we are essentially making a hypothesis
 about what that DGP might be.
 The actual relationship between the assumed distribution and the data is
 one of approximation and testing, rather than perfect correspondence.
\end_layout

\begin_layout Standard
The assumed distribution is a 
\emph on
theoretical model
\emph default
 that we believe could explain the underlying patterns in the data.
 The data is a finite set of observations, which is only a sample from the
 potential infinite population or DGP.
 The data is influenced by noise, randomness, and sample size, so it doesn't
 always clearly show the true DGP.
 When we assume a distribution, we're making an educated guess about the
 DGP based on the nature of the problem, properties of the data, and sometimes
 prior knowledge or experience.
 
\end_layout

\begin_layout Standard
Data alone, especially from a finite sample, does not directly tell us what
 the DGP is.
 Instead, we infer the DGP by fitting models to the data and assessing how
 well they describe it.
 Since data is inherently noisy and finite, different models may fit the
 data well, meaning that multiple distributions could seem plausible based
 on the data alone.
 That’s why we use goodness-of-fit tests, residual analysis, and model compariso
n to narrow down our choices.
 
\end_layout

\begin_layout Standard
If the data pattern conflicts with the assumed distribution, it might suggest
 that the assumption be wrong, and we should revisit our model.
 However, some degree of mismatch can be due to sample noise, outliers,
 or oversimplification, and may not always mean the assumption is entirely
 incorrect.
 
\end_layout

\begin_layout Subsection*
The workflow of probability modeling
\end_layout

\begin_layout Standard
The example of sellers' ratings is a good illustration of how we do probability
 modeling.
 Here we summarize it into several key steps.
\end_layout

\begin_layout Enumerate
Understanding of the problem and data exploration: The typical workflow
 of probability modeling begins with a clear understanding of the problem
 we are trying to solve.
 This involves identifying the objective of the model, determining which
 quantities or events need to be modeled as random variables.
 This also involves gathering relevant data, if available, or understanding
 the kind of data we will be working with.
 
\end_layout

\begin_layout Enumerate
Assumption of probability distribution: Based on the nature of the data
 and the problem at hand, choose a candidate distribution.
 For discrete data, this could be distributions like Bernoulli or Binomial.
 For continuous data, it might be Normal or Uniform distributions.
 
\end_layout

\begin_layout Enumerate
Parameter estimation: The candidate distribution usually involves unknown
 parameters.
 In most of the applications, we are interested in estimating these parameters.
 In our example, we update the parameter with the Bayes' rule.
 But there are other estimation methods available, such as Maximum Likelihood
 Estimation (MLE).
 Estimation quantifies the model and provides specific estimates based on
 the data.
\end_layout

\begin_layout Enumerate
Model fit and evaluation: We skip this step in our example.
 But normally, we need to evaluate how well the assumed distribution fits
 the data.
 This involves performing goodness-of-fit tests or graphical diagnostics.
 If the assumed distribution doesn't fit the data well, the model might
 need to be refined.
 
\end_layout

\begin_layout Enumerate
Simulation or inference: After refining the model, we can run simulations
 or make inferences.
 If the model is meant to simulate real-world processes, we can now generate
 new data based on the probability distribution and its parameters.
 We may also use the model to predict future outcomes or estimate probabilities
 of specific events.
 
\end_layout

\begin_layout Chapter
Expectation
\end_layout

\begin_layout Section
Expectation
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a discrete random variable.
 The 
\series bold
expectation
\series default
 of 
\begin_inset Formula $X$
\end_inset

, denoted by 
\begin_inset Formula $E(X)$
\end_inset

, is defined as: 
\begin_inset Formula 
\[
E(X)=\sum_{\textrm{all }x}xP(X=x).
\]

\end_inset

The expectation of 
\begin_inset Formula $X$
\end_inset

 is also referred to as the 
\series bold
mean
\series default
 of X or the 
\series bold
expected value
\series default
 of 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard
In other words, the expected value of 
\begin_inset Formula $X$
\end_inset

 is a 
\emph on
weighted average
\emph default
 of the possible values that 
\begin_inset Formula $X$
\end_inset

 can take on, weighted by their probabilities.
 If the values are of equal probability, expectation is the simple average
 of all 
\begin_inset Formula $x$
\end_inset

: 
\begin_inset Formula $E(X)=\frac{1}{n}\sum x$
\end_inset

.
\end_layout

\begin_layout Standard
The expected value of 
\begin_inset Formula $X$
\end_inset

 is a 
\emph on
number
\emph default
 (if it exists), 
\begin_inset Formula $E(X)\in\mathbb{R}$
\end_inset

.
 It is not a random variable such as a function of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
Sometimes, we would like to omit the parentheses for simplicity and write
 
\begin_inset Formula $EX\equiv E(X)$
\end_inset

.
 We also like to denote expectation by the greek letter 
\begin_inset Formula $\mu\equiv E(X)$
\end_inset

.
 
\end_layout

\begin_layout Example
The expectation of a Bernoulli random variable 
\begin_inset Formula $X\sim\textrm{Bern}(p)$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
E(X)=1\times P(X=1)+0\times P(X=0)=p.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The expectation of a Binomial random variable 
\begin_inset Formula $X\sim\textrm{Bin}(n,p)$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\begin{aligned}E(X)= & \sum_{k=0}^{n}kp(k)\\
= & \sum_{k=0}^{n}k\cdot\binom{n}{k}p^{k}q^{n-k}\\
= & \sum_{k=1}^{n}n\cdot\binom{n-1}{k-1}p^{k}q^{n-k}\\
= & np\sum_{k=1}^{n}\binom{n-1}{k-1}p^{k-1}q^{n-k}\\
= & np\underbrace{\sum_{j=0}^{n-1}\binom{n-1}{j}p^{j}q^{n-1-j}}_{\textrm{another Binomial PMF}}\\
= & np.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Life expectancy is the average number of years a person is expected to live.
 It is a crucial indicator of the quality of living and one of the three
 components of the Human Development Index (HDI) (the other two components
 are education and per capita GDP).
 Here is a toy example to compute life expectancy with hypothetical data.
\begin_inset Foot
status open

\begin_layout Plain Layout
This is an overly simplified example that only serves to clarify the definition
 of expectation.
 See 
\begin_inset CommandInset href
LatexCommand href
name "this tutorial from MEASURE Evaluation"
target "https://www.measureevaluation.org/resources/training/online-courses-and-resources/non-certificate-courses-and-mini-tutorials/multiple-decrement-life-tables/lesson-3.html"
literal "false"

\end_inset

 for the actual computation of life expectancy.
\end_layout

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="right" valignment="top" width="1.3cm">
<column alignment="right" valignment="top" width="1.3cm">
<column alignment="right" valignment="top" width="1.3cm">
<column alignment="right" valignment="top" width="1.3cm">
<column alignment="left" valignment="top" width="1.4cm">
<column alignment="right" valignment="top" width="1.3cm">
<column alignment="right" valignment="top" width="1.3cm">
<row>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(1)
\end_layout

\begin_layout Plain Layout

\size scriptsize
Age
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(2)
\end_layout

\begin_layout Plain Layout

\size scriptsize
Population
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(3)
\end_layout

\begin_layout Plain Layout

\size scriptsize
Mortality rates
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(4)
\end_layout

\begin_layout Plain Layout

\size scriptsize
# Survive
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(5)
\end_layout

\begin_layout Plain Layout

\size scriptsize
# Died at age
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
(6)
\end_layout

\begin_layout Plain Layout

\size scriptsize
P(Age)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1%
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1000
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2%
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
990
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
=1000(1-1%)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
40
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
250
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10%
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
970
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
=990(1-2%)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
97
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
150
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20%
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
873
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
=970(1-10%)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
175
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
100
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
100%
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
699
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
=873(1-20%)
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
699
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1000
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Hypothetical mortality rates and life table
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Example
To simplify our analysis, we will assume there are only five possible ages:
 0, 20, 40, 60, and 80.
 A baby is born at age 0, and can either die at that age or survive to age
 20.
 We intentionally exclude intermediate ages such as 5 and 10 for the sake
 of computational simplicity.
\end_layout

\begin_layout Example
It’s important to note that life expectancy is 
\bar under
not
\bar default
 the same as the average age of the population.
 For instance, based on the hypothetical data presented, the average age
 can be calculated as:
\begin_inset Formula 
\[
\overline{\textrm{Age}}=(0\times200+20\times300+40\times250+60\times150+80\times100)/1000=33.
\]

\end_inset


\end_layout

\begin_layout Example
However, the expected age, denoted as 
\begin_inset Formula $E(\textrm{Age})$
\end_inset

, is defined as:
\begin_inset Formula 
\[
E(\textrm{Age})=\sum\textrm{Age}\times P(\textrm{Age}).
\]

\end_inset


\end_layout

\begin_layout Example
To compute this expected value, we need to determine 
\begin_inset Formula $P(\textrm{Age})$
\end_inset

, the probability of living to a specific age or dying at that age.
 This requires consideration of the mortality rate at each age, which is
 given in Column 3.
\end_layout

\begin_layout Example
Assuming 1000 babies are born at age 0, with a mortality rate of 1% at that
 age, we find that 99% of the babies survive to age 20.
 Thus, the number of babies that survive to age 20 is: 
\begin_inset Formula $1000×(1−1\%)=990$
\end_inset

.
 We can apply similar calculations to determine the number of survivors
 at each subsequent age.
 
\end_layout

\begin_layout Example
The number of individuals who die at a specific age (Column 5) is the difference
 between the number of survivors at that age and the next (Column 4).
 To find the probability of living to a specific age, we compute: 
\begin_inset Formula $P(\textrm{Age})=\textrm{Column 4}/1000$
\end_inset

.
 
\end_layout

\begin_layout Example
Finally, we compute the expected value of age (or life expectancy) as follows:
\begin_inset Formula 
\[
E(Age)=0\times1\%+20\times2\%+40\times10\%+60\times17\%+80\times70\%=70.6.
\]

\end_inset

This figure differs from the average age.
 Since the mortality rate is low at younger ages, the probabilities 
\begin_inset Formula $P(\textrm{Age})$
\end_inset

 for these ages are also low, while they are higher for older ages.
 This example illustrates the distinction between average and expected values.
 In everyday conversation, we may use these terms interchangeably, but in
 certain contexts, expected values can significantly differ from averages.
\end_layout

\begin_layout Section
Linearity of expectation
\end_layout

\begin_layout Theorem
For any random variables 
\begin_inset Formula $X,Y$
\end_inset

 and any constant 
\begin_inset Formula $c$
\end_inset

, 
\begin_inset Formula 
\begin{align*}
E(X+Y) & =E(X)+E(Y),\\
E(cX) & =cE(X).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\bar under
This property holds regardless of the dependencies between the random variables.
\end_layout

\begin_layout Proof
The proof is not as straightforward as it seems.
 It is hard to combine the two random variables:
\begin_inset Formula 
\[
E(X)+E(Y)=\sum_{x}xP(X=x)+\sum_{y}yP(Y=y)\overset{?}{=}\sum(x+y)P(X+Y=x+y).
\]

\end_inset


\end_layout

\begin_layout Proof
The problem becomes easier if the number of possible values of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are the same and all values are equally likely, 
\begin_inset Formula 
\[
E(X)+E(Y)=\frac{1}{n}\sum x+\frac{1}{n}\sum y=\frac{1}{n}\sum(x+y)=E(X+Y).
\]

\end_inset


\end_layout

\begin_layout Proof
The original problem is equivalent to the simple case if realizing that
 the weighted average is jut a simple average with repetitive values.
 For example, 
\begin_inset Formula 
\[
1\times\frac{1}{4}+2\times\frac{2}{4}+3\times\frac{1}{4}=\frac{1}{4}(1+2+2+3).
\]

\end_inset


\end_layout

\begin_layout Proof
Imagine the sample space as being composed of 
\begin_inset Quotes eld
\end_inset

atom
\begin_inset Quotes erd
\end_inset

 outcomes 
\begin_inset Formula $\{\omega\}$
\end_inset

, each with equal probability 
\begin_inset Formula $P(\omega)$
\end_inset

.
 All random variable are function of these atoms, 
\begin_inset Formula $X(\omega)$
\end_inset

, and 
\begin_inset Formula $Y(\omega)$
\end_inset

.
 Therefore, the expectation formula can be rewritten as 
\begin_inset Formula 
\[
E(X)+E(Y)=\sum_{\omega}X(\omega)P(\omega)+\sum_{\omega}Y(\omega)P(\omega)=\sum_{\omega}(X+Y)(\omega)P(\omega)=E(X+Y).
\]

\end_inset


\end_layout

\begin_layout Proof
Here is another way to prove linearity for discrete random variables: 
\begin_inset Formula 
\begin{align*}
E(X+Y) & =\sum_{z=x+y}zP(X+Y=z)\\
E(X+Y) & =\sum_{x}\sum_{y}(x+y)P(X=x,Y=y)\\
 & =\sum_{x}\sum_{y}xP(X=x,Y=y)+\sum_{x}\sum_{y}yP(X=x,Y=y)\\
 & =\sum_{x}x\sum_{y}P(X=x,Y=y)+\sum_{y}y\sum_{x}P(X=x,Y=y)\\
 & =\sum_{x}xP((X=x)\cap\bigcup_{\textrm{all }y}(Y=y))+\sum_{y}yP(\bigcup_{\textrm{all }x}(X=x)\cap(Y=y))\\
 & =\sum_{x}xP(X=x)+\sum_{y}yP(Y=y)\\
 & =E(X)+E(Y).
\end{align*}

\end_inset


\end_layout

\begin_layout Corollary
Further properties on the linearity of expectations:
\end_layout

\begin_deeper
\begin_layout Itemize

\shape up
If 
\begin_inset Formula $Y=aX+b$
\end_inset

, then 
\begin_inset Formula $E(Y)=aE(X)+b$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $E(X_{1}+\cdots+X_{n})=E(X_{1})+\cdots+E(X_{n})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $E(a_{1}X_{1}+\cdots+a_{n}X_{n}+b)=a_{1}E(X_{1})+\cdots+a_{n}E(X_{n})+b$
\end_inset


\end_layout

\end_deeper
\begin_layout Example
Redo the expectation of 
\begin_inset Formula $X\sim\textrm{Bin}(n,p)$
\end_inset

 with properties of expectation: 
\begin_inset Formula 
\[
E(X)=E(X_{1}+\cdots+X_{n})=nE(X_{i})=np
\]

\end_inset

where 
\begin_inset Formula $X_{i}\sim\textrm{Bern}(p)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\textrm{HGeom}(w,b,n)$
\end_inset

.
 Find 
\begin_inset Formula $E(X)$
\end_inset

 the expected number of white balls.
 Similarly, we can decompose 
\begin_inset Formula $X$
\end_inset

: 
\begin_inset Formula 
\[
X=I_{1}+\cdots+I_{n}
\]

\end_inset

where 
\begin_inset Formula $I_{j}$
\end_inset

 equals 
\begin_inset Formula $1$
\end_inset

 if the 
\begin_inset Formula $j$
\end_inset

th ball is white and 
\begin_inset Formula $0$
\end_inset

 otherwise.
 We have said that 
\begin_inset Formula $\{I_{j}\}$
\end_inset

 are not independent, but the property of linearity still holds: 
\begin_inset Formula 
\[
E(X)=E(I_{1}+\cdots+I_{n})=E(I_{1})+\cdots+E(I_{n}).
\]

\end_inset

Meanwhile we have 
\begin_inset Formula 
\[
E(I_{j})=P(j\textrm{-th ball is white})=\frac{w}{w+b}
\]

\end_inset

since unconditionally the 
\begin_inset Formula $j$
\end_inset

th ball is equally likely to be any of the balls.
 Thus, 
\begin_inset Formula $E(X)=\frac{nw}{w+b}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
In a group of 
\begin_inset Formula $n$
\end_inset

 people, what is the expected number of distinct birthdays among the 
\begin_inset Formula $n$
\end_inset

 people (the expected number of days on which at least one of the people
 was born)? What is the expected number of people sharing a birthday (any
 day)? 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Let 
\begin_inset Formula $X$
\end_inset

 be the number of distinct birthdays, and write 
\begin_inset Formula $X=I_{1}+\cdots+I_{365}$
\end_inset

, where 
\begin_inset Formula 
\[
I_{j}=\begin{cases}
1 & \textrm{if someone was born on day }j\\
0 & \textrm{otherwise}
\end{cases}.
\]

\end_inset

Then 
\begin_inset Formula 
\begin{align*}
E(I_{j}) & =P(\textrm{someone was born on day }j)\\
 & =1-P(\textrm{no one was born on day }j)\\
 & =1-\left(\frac{364}{365}\right)^{n}.
\end{align*}

\end_inset

Then by linearity, 
\begin_inset Formula 
\[
E(X)=365\left(1-\left(\frac{364}{365}\right)^{n}\right).
\]

\end_inset

Let 
\begin_inset Formula $Y$
\end_inset

 be the number of people sharing a birthday, and 
\begin_inset Formula $Y=J_{1}+\cdots+J_{n}$
\end_inset

 where 
\begin_inset Formula $J_{k}$
\end_inset

 is an indicator that the 
\begin_inset Formula $j$
\end_inset

-th person shares his birthday with somebody else.
 
\begin_inset Formula 
\begin{align*}
E(J_{k}) & =P(\textrm{someone shares birthday with }k)\\
 & =1-P(\textrm{no one shares birthday with }k)\\
 & =1-\left(\frac{364}{365}\right)^{n-1}.
\end{align*}

\end_inset

Therefore, 
\begin_inset Formula 
\[
E(Y)=\sum_{k=1}^{n}E(J_{k})=n\left(1-\left(\frac{364}{365}\right)^{n-1}\right).
\]

\end_inset


\end_layout

\begin_layout Example
For some numeric values, 
\begin_inset Formula $E(Y)=2.3$
\end_inset

 if 
\begin_inset Formula $n=30$
\end_inset

; 
\begin_inset Formula $E(Y)=6.3$
\end_inset

 if 
\begin_inset Formula $n=50$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Suppose that there are 
\begin_inset Formula $𝑛$
\end_inset

 people sitting in a classroom with exactly 
\begin_inset Formula $n$
\end_inset

 seats.
 At some point, everyone got up, ran around the room, and sat back down
 randomly (i.e., all seating arrangements are equally likely).
 What is the expected value of the number of people sitting in their original
 seat? 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Number the people from 1 to 𝑛.
 Let 
\begin_inset Formula $𝑋_{i}$
\end_inset

 be the Bernoulli random variable with value 
\begin_inset Formula $1$
\end_inset

 if person 
\begin_inset Formula $𝑖$
\end_inset

 returns to their original seat and value 
\begin_inset Formula $0$
\end_inset

 otherwise.
 Since person 
\begin_inset Formula $𝑖$
\end_inset

 is equally likely to sit back down in any of the 
\begin_inset Formula $n$
\end_inset

 seats, the probability that person 
\begin_inset Formula $𝑖$
\end_inset

 returns to their original seat is 
\begin_inset Formula $1/𝑛$
\end_inset

.
 Therefore 
\begin_inset Formula $𝐸[𝑋_{i}]=1/𝑛$
\end_inset

.
 Now, let 
\begin_inset Formula $𝑋$
\end_inset

 be the number of people sitting in their original seat following the rearrangem
ent.
 Then 
\begin_inset Formula $𝑋=𝑋_{1}+𝑋_{2}+⋯+𝑋_{n}$
\end_inset

.
 By linearity of expected values, we have 
\begin_inset Formula $𝐸[𝑋]=\sum E[𝑋_{i}]=∑1/𝑛=1.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $\Pi$
\end_inset

 be a permutation over 
\begin_inset Formula $\{1,2,\dots,n\}$
\end_inset

.
 That is a reordering of the numbers.
 A fixed point of a permutation are the points not moved by the permutation.
 For example, in the permutation below 
\begin_inset Formula 
\[
\begin{array}{ccccc}
 & 1 & 2 & 3 & 4\\
\Pi & 2 & 4 & 3 & 1
\end{array}
\]

\end_inset


\end_layout

\begin_layout Example
The fixed point is 3.
 Find the expected number of fixed points of a random permutation.
 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Let 
\begin_inset Formula $𝑋$
\end_inset

 be the number of fixed points of a random permutation.
 Then 
\begin_inset Formula $X=\sum_{k=1}^{n}\boldsymbol{1}_{\Pi(k)=k}$
\end_inset

 where 
\begin_inset Formula $\boldsymbol{1}_{\Pi(k)=k}$
\end_inset

 indicates the 
\begin_inset Formula $k$
\end_inset

-th number stays the same after the permutation.
 By linearity, 
\begin_inset Formula 
\[
E(X)=E\left(\sum_{k=1}^{n}\boldsymbol{1}_{\Pi(k)=k}\right)=\sum_{k=1}^{n}E\left(\boldsymbol{1}_{\Pi(k)=k}\right)=\sum_{k=1}^{n}\frac{1}{n}=1.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Buffon's needle
\end_layout

\end_inset

Rule a surface with parallel lines a distance 
\begin_inset Formula $d$
\end_inset

 apart.
 What is the probability that a randomly dropped needle of length 
\begin_inset Formula $l\leq d$
\end_inset

 crosses a line?
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Consider dropping any (continuous) curve of length 
\begin_inset Formula $l$
\end_inset

 onto the surface.
 Imagine dividing up the curve into 
\begin_inset Formula $𝑁$
\end_inset

 straight line segments, each of length 
\begin_inset Formula $\frac{l}{N}$
\end_inset

.
 Let 
\begin_inset Formula $X_{i}$
\end_inset

 be the indicator for the 
\begin_inset Formula $𝑖$
\end_inset

-th segment crossing a line.
 Let 
\begin_inset Formula $𝑋$
\end_inset

 be the total number of times the curve crosses a line.
 Then,
\begin_inset Formula 
\[
E(X)=E(\sum X_{i})=\sum E(X_{i})=N\cdot E(X_{i}).
\]

\end_inset

There could be infinitely many segments.
 It is hard to compute this expectation directly.
 But here we arrive an important Lemma: the expected number of crossings
 is proportional to the length of the curve, regardless of the shape of
 the curve.
 If we can compute 
\begin_inset Formula $E(X)$
\end_inset

 for some curve, the we can compute 
\begin_inset Formula $E(X)$
\end_inset

 for any length by scaling the value proportional to the length.
\end_layout

\begin_layout Example
Consider a circle of diameter 
\begin_inset Formula $d$
\end_inset

.
 The circle always crosses the lines twice for sure.
 That is, 
\begin_inset Formula $E(X_{\textrm{circle}})=2$
\end_inset

.
 The length of the circle is 
\begin_inset Formula $\pi d$
\end_inset

.
 Therefore, the value of 
\begin_inset Formula $E(X)$
\end_inset

 for any curve of length 
\begin_inset Formula $l$
\end_inset

 is given by 
\begin_inset Formula 
\[
E(X)=\frac{2l}{\pi d}.
\]

\end_inset


\end_layout

\begin_layout Example
Now a needle can cross a line either 
\begin_inset Formula $1$
\end_inset

 or 
\begin_inset Formula $0$
\end_inset

 times.
 Thus, 
\begin_inset Formula $E(X)=1\cdot P(X=1)+0\cdot P(X=0)$
\end_inset

 is exactly the probability of a needle crossing a line.
\end_layout

\begin_layout Remark*
This amazing example can be used to approximate the value of 
\begin_inset Formula $\pi$
\end_inset

.
 Let 
\begin_inset Formula $q$
\end_inset

 be the probability of a needle crossing a line.
 
\begin_inset Formula $q$
\end_inset

 can be approximated by large number of simulations.
 Then 
\begin_inset Formula $\pi\approx\frac{2l}{qd}$
\end_inset

.
\end_layout

\begin_layout Section
Multiplication and LOTUS
\end_layout

\begin_layout Theorem

\shape up
If 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent, we have 
\begin_inset Formula 
\[
E(XY)=E(X)E(Y).
\]

\end_inset

In general, if 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 are independent, we have 
\begin_inset Formula 
\[
E(X_{1}X_{2}\cdots X_{n})=E(X_{1})E(X_{2})\cdots E(X_{n}).
\]

\end_inset


\end_layout

\begin_layout Remark*

\shape up
\bar under
The multiplication rule will not hold without independence
\bar default
.
 
\end_layout

\begin_layout Proof
For discrete and independent 
\begin_inset Formula $X,Y$
\end_inset

, 
\begin_inset Formula 
\begin{align*}
E(XY) & =\sum_{x}\sum_{y}xyP(X=x,Y=y)\\
 & =\sum_{x}\sum_{y}xyP(X=x)P(Y=y)\quad\textrm{if independent}\\
 & =\sum_{x}xP(X=x)\sum_{y}yP(Y=y)\\
 & =E(X)E(Y).
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*

\shape up
This is a sufficient but not necessary condition.
 
\begin_inset Formula $E(XY)=E(X)E(Y)$
\end_inset

 does not imply independence.
 Consider a counter-example, 
\begin_inset Formula 
\[
X=\begin{cases}
1 & \textrm{with prob. }1/2\\
0 & \textrm{with prob. }1/2
\end{cases},\quad Z=\begin{cases}
1 & \textrm{with prob. }1/2\\
-1 & \textrm{with prob. }1/2
\end{cases};
\]

\end_inset

Then 
\begin_inset Formula 
\[
Y=XZ=\begin{cases}
-1 & \textrm{with prob. }1/4\\
0 & \textrm{with prob. }1/2\\
1 & \textrm{with prob. }1/4
\end{cases}.
\]

\end_inset

We have 
\begin_inset Formula $E(X)=1/2$
\end_inset

, 
\begin_inset Formula $E(Y)=0$
\end_inset

, 
\begin_inset Formula $E(XY)=0$
\end_inset

.
 So 
\begin_inset Formula $E(XY)=E(X)E(Y)$
\end_inset

.
 But clearly 
\begin_inset Formula $X,Y$
\end_inset

 are not independent.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\shape up
Law of the unconscious statistician (LOTUS)
\end_layout

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 be a random variable, and 
\begin_inset Formula $g$
\end_inset

 be a real-valued function of a real variable.
 If 
\begin_inset Formula $X$
\end_inset

 has a discrete distribution, then
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
E[g(X)]=\sum_{\textrm{all }x}g(x)P(X=x).
\]

\end_inset


\end_layout

\begin_layout Standard
LOTUS says we can compute the expectation of 
\begin_inset Formula $g(X)$
\end_inset

 without knowing the PMF of 
\begin_inset Formula $g(X)$
\end_inset

.
 
\end_layout

\begin_layout Example
Compute 
\begin_inset Formula $E(X)$
\end_inset

 and 
\begin_inset Formula $E(X^{2})$
\end_inset

 given the following distribution.
 
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example

\emph on
Solution:
\emph default
 According to the distribution table, we compute the expectations as
\begin_inset Formula 
\begin{align*}
E(X) & =0\times1/4+1\times1/2+2\times1/4=1;\\
E(X^{2}) & =0\times1/4+1\times1/2+4\times1/4=3/2.
\end{align*}

\end_inset

Note that 
\begin_inset Formula $E(X^{2})\neq[E(X)]^{2}$
\end_inset

.
\end_layout

\begin_layout Remark*
In general, 
\begin_inset Formula $E[g(X)]\neq g(E(X))$
\end_inset

.
 Linearity implies that if 
\begin_inset Formula $g$
\end_inset

 is a linear function of 
\begin_inset Formula $X$
\end_inset

, then 
\begin_inset Formula $E[g(X)]=g(E(X))$
\end_inset

.
 For a nonlinear function 
\begin_inset Formula $g$
\end_inset

, the relationship between 
\begin_inset Formula $E[g(X)]$
\end_inset

 and 
\begin_inset Formula $g(E(X))$
\end_inset

 is determined case by case.
 We will get back to this point when we learn Jensen's inequality.
 
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
St.
 Petersburg Paradox
\end_layout

\end_inset

Flip a fair coin over and over again until the head lands the first time.
 You will win 
\begin_inset Formula $2^{k}$
\end_inset

 dollars if the head lands in the 
\begin_inset Formula $k$
\end_inset

-th trial (including the successful trial).
 What is the expected payoff of this game?
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $X=2^{k}$
\end_inset

.
 We want to find 
\begin_inset Formula $E(X)$
\end_inset

.
 The probability of the first head showing up in the 
\begin_inset Formula $k$
\end_inset

-th trial is 
\begin_inset Formula $\frac{1}{2^{k}}$
\end_inset

.
 Therefore,
\begin_inset Formula 
\[
E(X)=\sum_{k=1}^{\infty}2^{k}\cdot\frac{1}{2^{k}}=\sum_{k=1}^{\infty}1=\infty
\]

\end_inset


\end_layout

\begin_layout Example
The expected payoff is infinitely high! This is against most people's intuition.
 This is because we intuitively think that 
\begin_inset Formula $E(X)=E(2^{k})=2^{E(k)}$
\end_inset

, which is a finite number.
 
\end_layout

\begin_layout Section
Median and mode
\end_layout

\begin_layout Standard
The mean is called a measure of 
\emph on
central tendency
\emph default
 because it tells us something about the center of a distribution, speciﬁcally
 its center of mass.
 Other measures of central tendency that are commonly used in statistics
 are the median and the mode, which we now deﬁne.
\end_layout

\begin_layout Definition
We say that 
\begin_inset Formula $c$
\end_inset

 is a 
\series bold
median
\series default
 of a random variable 
\begin_inset Formula $X$
\end_inset

 if 
\begin_inset Formula $P(X\leq c)\geq1/2\text{\textrm{ and }\ensuremath{P(X\geq c)\geq1/2}.}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
For a discrete random variable 
\begin_inset Formula $X$
\end_inset

, we say that 
\begin_inset Formula $c$
\end_inset

 is a 
\series bold
mode
\series default
 of 
\begin_inset Formula $X$
\end_inset

 if it maximizes the PMF: 
\begin_inset Formula $P(X=c)\geq P(X=x)$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
 For a continuous random variable 
\begin_inset Formula $X$
\end_inset

 with PDF 
\begin_inset Formula $f$
\end_inset

, we say that 
\begin_inset Formula $c$
\end_inset

 is a 
\series bold
mode
\series default
 if it maximizes the PDF: 
\begin_inset Formula $f(c)\geq f(x)$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
Intuitively, the median is a value 
\begin_inset Formula $c$
\end_inset

 such that half the mass of the distribution falls on either side of 
\begin_inset Formula $c$
\end_inset

 (or as close to half as possible, for discrete random variables), and the
 mode is a value that has the greatest mass or density out of all values
 in the support of 
\begin_inset Formula $X$
\end_inset

.
 If the CDF 
\begin_inset Formula $F$
\end_inset

 is a continuous, strictly increasing function, then 
\begin_inset Formula $F^{-1}(1/2)$
\end_inset

 is the median (and is unique).
\end_layout

\begin_layout Remark*

\bar under
A distribution can have multiple medians and multiple modes
\bar default
.
 Medians have to occur side by side; modes can occur all over the distribution.
 
\end_layout

\begin_layout Example
The main reason why the median is sometimes preferred over the mean is that
 the median is more robust to extreme values.
 Think about an income distribution.
 Higher incomes are rare, but their absolute values are high.
 Thus, the mean income tends be higher than what the mass of the population
 would earn.
 But the median is more robust to extreme values and is closer to the earnings
 of an 
\begin_inset Quotes eld
\end_inset

average
\begin_inset Quotes erd
\end_inset

 person.
 For example, the mean of China's income is 
\begin_inset Formula $\yen2,561$
\end_inset

 monthly in 2019; the median is only 
\begin_inset Formula $\yen2,210$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Income (monthly, yuan)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
<1k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1-2k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2-5k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5-10k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10-20k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
>20k
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Population (million)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
550
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
420
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
360
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
63
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7.8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.7
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
China monthly income per capita.
 Source: NBS 2019.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 be an random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 , and let 
\begin_inset Formula $m$
\end_inset

 be a median of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
The value of 
\begin_inset Formula $c$
\end_inset

 that minimizes the mean squared error 
\begin_inset Formula $E\left(X−c\right)^{2}$
\end_inset

 is 
\begin_inset Formula $c=\mu$
\end_inset

.
\end_layout

\begin_layout Itemize
A value of 
\begin_inset Formula $c$
\end_inset

 that minimizes the mean absolute error 
\begin_inset Formula $E\left|X-c\right|$
\end_inset

 is 
\begin_inset Formula $c=m$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Section
Variance and standard deviation
\end_layout

\begin_layout Standard
Expectation is the most commonly used summary of a distribution, as it indicates
 where values are likely centered.
 However, it provides limited insight into the distribution’s overall shape.
 For example, two random variables might have the same mean, yet one could
 have values spread far from the mean while the other has values tightly
 clustered around it.
 Variance, on the other hand, describes how far values in a distribution
 typically deviate from the mean, offering a measure of the distribution’s
 dispersion.
\end_layout

\begin_layout Definition
The 
\series bold
variance
\series default
 of a random variable 
\begin_inset Formula $X$
\end_inset

 is defined as 
\begin_inset Formula 
\[
Var(X)=E\left(X-EX\right)^{2}.
\]

\end_inset


\end_layout

\begin_layout Definition
The 
\series bold
standard deviation
\series default
 of 
\begin_inset Formula $X$
\end_inset

 is defined as 
\begin_inset Formula 
\[
SD(X)=\sqrt{Var(X)}.
\]

\end_inset


\end_layout

\begin_layout Standard
We often denote standard deviation by the greek letter 
\begin_inset Formula $\sigma\equiv SD(X)$
\end_inset

, and variance by 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Variance measures how far 
\begin_inset Formula $X$
\end_inset

 typically deviates from its mean, but instead of averaging the differences,
 we average the squared differences to ensure both positive and negative
 deviations contribute.
 The expected deviation, 
\begin_inset Formula $E(X-E(X))$
\end_inset

, is always zero, so squaring avoids this cancellation.
 Since variance is in squared units, we take the square root to get the
 standard deviation, restoring the original units.
\end_layout

\begin_layout Standard
Why take squares? Sometimes we also use 
\begin_inset Formula $E(|X-E(X)|)$
\end_inset

 instead.
 But it is less common because the absolute value function isn’t differentiable.
 Besides, squaring connects to geometric concepts like the distance formula
 and Pythagorean theorem, which have useful statistical meanings.
\end_layout

\begin_layout Theorem
For any random variable 
\begin_inset Formula $X$
\end_inset

, 
\begin_inset Formula 
\[
Var(X)=E(X^{2})-(EX)^{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mu=E(X)$
\end_inset

.
 By definition, 
\begin_inset Formula 
\begin{align*}
Var(X) & =E(X-\mu)^{2}=E(X^{2}-2\mu X+\mu^{2})\\
 & =E(X^{2})-2\mu E(X)+\mu^{2}=E(X^{2})-\mu^{2}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Find the variance for 
\begin_inset Formula $X\sim\textrm{Bern}(p).$
\end_inset


\begin_inset Formula 
\[
Var(X)=E(X^{2})-E^{2}(X)=p-p^{2}=p(1-p).
\]

\end_inset


\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
Variance has the following properties:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $Var(X)\geq0$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Var(X+c)=Var(X)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Var(cX)=c^{2}Var(X)$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $X,Y$
\end_inset

 are independent, 
\begin_inset Formula $Var(X+Y)=Var(X)+Var(Y)$
\end_inset

.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $X_{1},X_{2},\dots,X_{n}$
\end_inset

 are independent, 
\begin_inset Formula ${\displaystyle Var(\sum_{i=1}^{n}X_{i})=\sum_{i=1}^{n}Var(X_{i})}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Find the variance for 
\begin_inset Formula $X\sim\textrm{Bin}(n,p).$
\end_inset

 
\begin_inset Formula $X=X_{1}+\cdots+X_{n}$
\end_inset

 where 
\begin_inset Formula $X_{i}$
\end_inset

 are 
\emph on

\begin_inset Formula $i.i.d$
\end_inset


\emph default
 Bernoulli distributions 
\begin_inset Formula 
\[
Var(X)\overset{iid}{=}\sum_{i=1}^{n}Var(X_{i})=np(1-p).
\]

\end_inset


\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Covariance and correlation
\end_layout

\begin_layout Standard
For more than one random variable, it is also of interest to know the relationsh
ip between them.
 Are they dependent? How strong is the dependence? Covariance and correlation
 are intended to measure that dependence.
 But they only capture a particular type of dependence, namely linear dependence.
 
\end_layout

\begin_layout Definition
The 
\series bold
covariance
\series default
 between random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 is defined as 
\begin_inset Formula 
\[
Cov(X,Y)=E[(X-EX)(Y-EY)].
\]

\end_inset


\end_layout

\begin_layout Standard
The covariance between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 reflects how much 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 simultaneously deviate from their respective means.
 If 
\begin_inset Formula $X>EX$
\end_inset

, 
\begin_inset Formula $Y>EY$
\end_inset

 or 
\begin_inset Formula $X<EX$
\end_inset

, 
\begin_inset Formula $Y<EY$
\end_inset

 simultaneously, then 
\begin_inset Formula $Cov(X,Y)$
\end_inset

 tends be positive.
 Conversely, if 
\begin_inset Formula $X>EX$
\end_inset

 is pair with 
\begin_inset Formula $Y<EY$
\end_inset

 (or 
\begin_inset Formula $X<EX$
\end_inset

 paired with 
\begin_inset Formula $Y>EY$
\end_inset

), then 
\begin_inset Formula $Cov(X,Y)$
\end_inset

 tends to be negative.
 
\end_layout

\begin_layout Theorem
For any random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, 
\begin_inset Formula 
\[
Cov(X,Y)=E(XY)-E(X)E(Y).
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mu_{X}=E(X)$
\end_inset

 and 
\begin_inset Formula $\mu_{Y}=E(Y)$
\end_inset

.
 By definition, 
\begin_inset Formula 
\begin{align*}
Cov(X,Y) & =E(XY-\mu_{X}Y-\mu_{Y}X+\mu_{X}\mu_{Y})\\
 & =E(XY)-\mu_{X}E(Y)-\mu_{Y}E(X)+\mu_{X}\mu_{Y}\\
 & =E(XY)-E(X)E(Y).
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X,Y$
\end_inset

 are independent, they are uncorrelated.
 But the converse is false.
 
\end_layout

\begin_layout Proof
\begin_inset Formula $Cov(X,Y)=E(XY)-E(X)E(Y)$
\end_inset

.
 Independence implies 
\begin_inset Formula $E(XY)=E(X)E(Y)$
\end_inset

.
 Thus, 
\begin_inset Formula $Cov(X,Y)=0$
\end_inset

.
 But 
\begin_inset Formula $Cov(X,Y)=0$
\end_inset

 does not necessarily imply independence.
 Consider the following counter example.
 Let 
\begin_inset Formula $X$
\end_inset

 be a random variable that takes three values -1, 0, 1 with equal probability.
 And 
\begin_inset Formula $Y=X^{2}$
\end_inset

.
 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are clearly dependent.
 But they their correlation is 0.
 Since 
\begin_inset Formula $E(X)=0$
\end_inset

, 
\begin_inset Formula $E(Y)=2/3$
\end_inset

, 
\begin_inset Formula $E(XY)=E(X^{3})=0$
\end_inset

, 
\begin_inset Formula $Cov(X,Y)=0$
\end_inset

.
\end_layout

\begin_layout Remark*
Covariances and correlations provide measures of the extend to which two
 random variables are 
\bar under
linearly related
\bar default
.
 If we plot the values of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 in the 
\begin_inset Formula $xy$
\end_inset

-plane, if the points form a straight line, that would signal a strong positive
 (if positive slope) or negative (if negative slope) correlation.
 It is possible that the correlation is 
\begin_inset Formula $0$
\end_inset

 if 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are dependent but the relationship is nonlinear.
\end_layout

\begin_layout Theorem
Covariance has the following properties:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $Cov(X,X)=Var(X)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Cov(X,Y)=Cov(Y,X)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Cov(cX,Y)=Cov(X,cY)=c\left[Cov(X,Y)\right]$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula ${\displaystyle Var\left(\sum_{i=1}^{n}X_{i}\right)=\sum_{i=1}^{n}Var(X_{i})+2\sum_{i<j}Cov(X_{i},X_{j})}$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We only prove the variance-covariance property: 
\begin_inset Formula 
\begin{align*}
Var(X+Y) & =E[(X+Y-\mu_{X}-\mu_{Y})^{2}]\\
 & =E[(X-\mu_{X})^{2}+(Y-\mu_{Y})^{2}+2(X-\mu_{X})(Y-\mu_{Y})]\\
 & =Var(X)+Var(Y)+2Cov(X,Y).
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Find 
\begin_inset Formula $Cov(X+Y,Z+W)$
\end_inset

 and 
\begin_inset Formula $Var(X-Y)$
\end_inset

.
\end_layout

\begin_layout Standard
While 
\begin_inset Formula $\text{Cov}(X,Y)$
\end_inset

 quantifies how 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 vary together, its magnitude also depends on the absolute scales of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 (multiply 
\begin_inset Formula $X$
\end_inset

 by a constant 
\begin_inset Formula $c$
\end_inset

, the covariance will be different).
 To establish a measure of association between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 that is unaffected by arbitrary changes in the scales of either variable,
 we introduce a 
\begin_inset Quotes eld
\end_inset

standardized covariance
\begin_inset Quotes erd
\end_inset

 called correlation.
\end_layout

\begin_layout Definition
The 
\series bold
correlation
\series default
 between random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 is defined as 
\begin_inset Formula 
\[
Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}.
\]

\end_inset


\end_layout

\begin_layout Standard
We also denote correlation by 
\begin_inset Formula $\rho\equiv Corr(X,Y)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Unlike covariance, scaling 
\begin_inset Formula $X$
\end_inset

 or 
\begin_inset Formula $Y$
\end_inset

 has no effect on the correlation.
 We can verify this: 
\begin_inset Formula 
\[
Corr(cX,Y)=\frac{Cov(cX,Y)}{\sqrt{Var(cX)Var(Y)}}=\frac{cCov(X,Y)}{c\sqrt{Var(X)Var(Y)}}=Corr(X,Y).
\]

\end_inset


\end_layout

\begin_layout Theorem
For any random variable 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, 
\begin_inset Formula 
\[
-1\leq Corr(X,Y)\leq1.
\]

\end_inset


\end_layout

\begin_layout Proof
Without loss of generality, assume 
\begin_inset Formula $X,Y$
\end_inset

 both have variance 1, since scaling does not change the correlation.
 Let 
\begin_inset Formula $\rho=Corr(X,Y)=Cov(X,Y)$
\end_inset

.
 Then 
\begin_inset Formula 
\begin{align*}
Var(X+Y) & =Var(X)+Var(Y)+2Cov(X,Y)=2+2\rho\geq0,\\
Var(X-Y) & =Var(X)+Var(Y)-2Cov(X,Y)=2-2\rho\ge0.
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus 
\begin_inset Formula $-1\leq\rho\leq1$
\end_inset

.
\end_layout

\begin_layout Standard
It is said that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
positively correlated
\series default
 if 
\begin_inset Formula $Corr(X,Y)>0$
\end_inset

, that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
negatively correlated
\series default
 if 
\begin_inset Formula $Corr(X,Y)<0$
\end_inset

, and that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
uncorrelated
\series default
 if 
\begin_inset Formula $Corr(X,Y)=0$
\end_inset

.
\end_layout

\begin_layout Theorem
Suppose that 
\begin_inset Formula $X$
\end_inset

 is a random variable and 
\begin_inset Formula $Y=aX+b$
\end_inset

 for some constants 
\begin_inset Formula $a,b$
\end_inset

, where 
\begin_inset Formula $a\neq0$
\end_inset

.
 If 
\begin_inset Formula $a>0$
\end_inset

, then 
\begin_inset Formula $\rho_{XY}=1$
\end_inset

.
 If 
\begin_inset Formula $a<0$
\end_inset

, then 
\begin_inset Formula $\rho_{XY}=-1$
\end_inset

.
\end_layout

\begin_layout Proof
If 
\begin_inset Formula $Y=aX+b$
\end_inset

, then 
\begin_inset Formula $E(Y)=aE(X)+b$
\end_inset

.
 Thus, 
\begin_inset Formula $Y-E(Y)=a(X-E(X))$
\end_inset

.
 Therefore, 
\begin_inset Formula 
\[
Cov(X,Y)=aE[(X-EX)^{2}]=aVar(X).
\]

\end_inset

Since 
\begin_inset Formula $Var(Y)=a^{2}Var(X)$
\end_inset

, 
\begin_inset Formula $\rho_{XY}=\frac{a}{|a|}$
\end_inset

.
 The theorem thus follows.
 
\end_layout

\begin_layout Example
Toss two coins.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of Heads, and 
\begin_inset Formula $Y$
\end_inset

 be the number of Tails.
 Find the covariance and correlation between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Note that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are counterparts to each other, 
\begin_inset Formula $Y=2-X$
\end_inset

.
 So we expect the correlation be negative.
 The expectation of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are the same: 
\begin_inset Formula $EX=EY=1$
\end_inset

.
 So we have 
\begin_inset Formula $X-EX=-1,0,1$
\end_inset

 and 
\begin_inset Formula $Y-EY=1,0,-1$
\end_inset

.
 The corresponding probabilities are 1/4,1/2,1/4 respectively.
 Therefore,
\begin_inset Formula 
\[
Cov(X,Y)=(-1)\times1\times1/4+1\times(-1)\times1/4=-1/2.
\]

\end_inset


\end_layout

\begin_layout Example
Since 
\begin_inset Formula $Var(X)=Var(Y)=1/2$
\end_inset

, the correlation is 
\begin_inset Formula 
\[
Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}=\frac{-1/2}{\sqrt{1/2\times1/2}}=-1.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim HGeom(w,b,n)$
\end_inset

.
 Find 
\begin_inset Formula $Var(X)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Interpret 
\begin_inset Formula $X$
\end_inset

 as the number of white balls in a sample of size 
\begin_inset Formula $n$
\end_inset

 from an box with 
\begin_inset Formula $w$
\end_inset

 white and 
\begin_inset Formula $b$
\end_inset

 black balls.
 We can represent 
\begin_inset Formula $X$
\end_inset

 as the sum of indicator variables, 
\begin_inset Formula $X=I_{1}+\cdots+I_{n}$
\end_inset

 , where 
\begin_inset Formula $I_{j}$
\end_inset

 is the indicator of the 
\begin_inset Formula $j$
\end_inset

-th ball in the sample being white.
 Each 
\begin_inset Formula $I_{j}$
\end_inset

 has mean 
\begin_inset Formula $p=w/(w+b)$
\end_inset

 and variance 
\begin_inset Formula $p(1−p)$
\end_inset

, but because the 
\begin_inset Formula $I_{j}$
\end_inset

 are dependent, we cannot simply add their variances.
 Instead, 
\begin_inset Formula 
\begin{align*}
Var(X) & =Var\left(\sum_{j=1}^{n}I_{j}\right)\\
 & =Var(I_{1})+\cdots+Var(I_{n})+2\sum_{i<j}Cov(I_{i},I_{j})\\
 & =np(1-p)+2\binom{n}{2}Cov(I_{i},I_{j})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In the last step, because of symmetry, for every pair 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, 
\begin_inset Formula $Cov(I_{i},I_{j})$
\end_inset

 are the same.
 
\begin_inset Formula 
\begin{align*}
Cov(I_{i},I_{j}) & =E(I_{i}I_{j})-E(I_{i})E(I_{j})\\
 & =P(i\textrm{ and }j\textrm{ both white})-P(i\textrm{ is white})P(j\textrm{ is white})\\
 & =\frac{w}{w+b}\cdot\frac{w-1}{w+b-1}-p^{2}\\
 & =p\frac{Np-1}{N-1}-p^{2}\\
 & =\frac{p(p-1)}{N-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $N=w+b$
\end_inset

.
 Plugging this into the above formula and simplifying, we eventually obtain
 
\begin_inset Formula 
\[
Var(X)=np(1-p)+n(n-1)\frac{p(p-1)}{N-1}=\frac{N-n}{N-1}np(1-p).
\]

\end_inset

This differs from the Binomial variance of 
\begin_inset Formula $np(1-p)$
\end_inset

 by a factor of 
\begin_inset Formula $\frac{N-n}{N-1}$
\end_inset

.
 This discrepancy arises because the Hypergeometric story involves sampling
 without replacement.
 As 
\begin_inset Formula $N\to\infty$
\end_inset

, it becomes extremely unlikely that we would draw the same ball more than
 once, so sampling with or without replacement essentially become the same.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
PG exam
\end_layout

\end_inset

Put 
\begin_inset Formula $k$
\end_inset

 balls into 
\begin_inset Formula $n$
\end_inset

 boxes.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of empty boxes.
 Find 
\begin_inset Formula $E(X)$
\end_inset

 and 
\begin_inset Formula $Var(X)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Define an indicator variable 
\begin_inset Formula 
\[
I_{j}=\begin{cases}
1 & j\textrm{-th box is empty}\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Example
Then 
\begin_inset Formula $X=\sum_{j=1}^{n}I_{j}$
\end_inset

.
 Unconditionally, the probability of one box being empty is 
\begin_inset Formula $\left(\frac{n-1}{n}\right)^{k}$
\end_inset

.
 Therefore, 
\begin_inset Formula 
\[
E(I_{j})=P(j\textrm{-th box is empty})=\left(\frac{n-1}{n}\right)^{k}
\]

\end_inset

for 
\begin_inset Formula $j=1,2,\dots,n$
\end_inset

.
 It follows that 
\begin_inset Formula 
\[
E(X)=\sum_{j=1}^{n}I_{j}=nE(I_{j})=n\left(\frac{n-1}{n}\right)^{k}.
\]

\end_inset


\end_layout

\begin_layout Example
To compute the variance, 
\begin_inset Formula 
\begin{align*}
Var(X) & =Var(I_{1}+\cdots+I_{n})=\sum_{j=1}^{n}Var(I_{j})+2\sum_{i<j}Cov(I_{i},I_{j})\\
 & =nVar(I_{j})+2\binom{n}{2}Cov(I_{i},I_{j}),
\end{align*}

\end_inset


\end_layout

\begin_layout Example
since by symmetry, 
\begin_inset Formula $Var(I_{j})$
\end_inset

 is the same for all 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $Cov(I_{i},I_{j})$
\end_inset

 is the same for all 
\begin_inset Formula $i\neq j$
\end_inset

.
 It suffices to compute 
\begin_inset Formula $Var(I_{j})$
\end_inset

 and 
\begin_inset Formula $Cov(I_{i},I_{j})$
\end_inset

 for any 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $i\neq j$
\end_inset

.
 Since 
\begin_inset Formula $I_{j}$
\end_inset

 only takes number 0 and 1, 
\begin_inset Formula 
\[
E(I_{j}^{2})=\left(\frac{n-1}{n}\right)^{k},
\]

\end_inset


\begin_inset Formula 
\begin{align*}
Var(I_{j})=E(I_{j}^{2})-(E(I_{j}))^{2} & =\left(\frac{n-1}{n}\right)^{k}-\left(\frac{n-1}{n}\right)^{2k}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
For the covariance term, 
\begin_inset Formula 
\[
E(I_{i}I_{j})=P(\textrm{\ensuremath{i,j} are both empty})=\left(\frac{n-2}{n}\right)^{k},
\]

\end_inset


\begin_inset Formula 
\[
Cov(I_{i},I_{j})=E(I_{i}I_{j})-E(I_{i})E(I_{j})=\left(\frac{n-2}{n}\right)^{k}-\left(\frac{n-1}{n}\right)^{2k}.
\]

\end_inset


\end_layout

\begin_layout Example
Therefore, 
\begin_inset Formula 
\[
Var(X)=n\left[\left(\frac{n-1}{n}\right)^{k}-\left(\frac{n-1}{n}\right)^{2k}\right]+2\binom{n}{2}\left[\left(\frac{n-2}{n}\right)^{k}-\left(\frac{n-1}{n}\right)^{2k}\right].
\]

\end_inset


\end_layout

\begin_layout Section
Moments and MGF
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 .
 For any positive integer 
\begin_inset Formula $n$
\end_inset

, the 
\begin_inset Formula $n$
\end_inset

-th 
\series bold
moment
\series default
 of 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula $E(X^{n})$
\end_inset

, the 
\begin_inset Formula $n$
\end_inset

-th 
\series bold
central moment
\series default
 is 
\begin_inset Formula $E(X−\mu)^{n}$
\end_inset

, and the 
\begin_inset Formula $n$
\end_inset

-th 
\series bold
standardized moment
\series default
 is 
\begin_inset Formula $E\left(\frac{X-\mu}{\sigma}\right)^{n}$
\end_inset

.
\end_layout

\begin_layout Standard
In accordance with this terminology, 
\begin_inset Formula $E(X)$
\end_inset

 is the first moment of 
\begin_inset Formula $X$
\end_inset

, 
\begin_inset Formula $Var(X)$
\end_inset

 is the second central moment of 
\begin_inset Formula $X$
\end_inset

.
 It is natural to ask if there are higher order moments.
 The answer is yes.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a random variable with mean 
\begin_inset Formula $\mu$
\end_inset

, standard deviation 
\begin_inset Formula $\sigma$
\end_inset

, and finite third moment.
 The 
\series bold
skewness
\series default
 of 
\begin_inset Formula $X$
\end_inset

 is defined as 
\begin_inset Formula 
\[
\textrm{Skew}(X)=E\left[\left(\frac{X-\mu}{\sigma}\right)^{3}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The 
\series bold
Kurtosis
\series default
 of 
\begin_inset Formula $X$
\end_inset

 is defined as 
\begin_inset Formula 
\[
\textrm{Kurt}(X)=\left[\left(\frac{X-\mu}{\sigma}\right)^{4}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Skewness is the measure of the lopsidedness of the distribution; any symmetric
 distribution will have a third central moment, if defined, of zero.
 A distribution that is skewed to the left (the tail of the distribution
 is longer on the left) will have a negative skewness.
 A distribution that is skewed to the right (the tail of the distribution
 is longer on the right), will have a positive skewness.
\end_layout

\begin_layout Standard
Kurtosis is a measure of the heaviness of the tail of the distribution.
 If a distribution has heavy tails, the kurtosis will be high; conversely,
 light-tailed distributions have low kurtosis.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename img/moments.png
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Moments and the shape of a distribution
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
We see that moments give information about the shape of a distribution.
 Different orders of moments captures different aspects of the distribution.
 In fact, if we know all the moments (moments of infinitely high order),
 we can exactly pin down the distribution.
 
\end_layout

\begin_layout Theorem
For a distribution of mass or probability on a bounded interval, the collection
 of all the moments (of all orders, from 
\begin_inset Formula $0$
\end_inset

 to 
\begin_inset Formula $\infty$
\end_inset

) uniquely determines the distribution.
\end_layout

\begin_layout Standard
So there are two ways of fully characterize a distribution:
\end_layout

\begin_layout Enumerate
Listing all the possible values along with their associated probabilities;
\end_layout

\begin_layout Enumerate
Giving all the moments of the distribution.
\end_layout

\begin_layout Standard
It is somewhat like the analogous Taylor theorem in the probability theory.
 We can represent any distribution by a sequence of higher order 
\begin_inset Quotes eld
\end_inset

polynomials
\begin_inset Quotes erd
\end_inset

: 
\begin_inset Formula $E(X),E(X^{2}),E(X^{3}),\ldots$
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a random variable.
 For each real number 
\begin_inset Formula $t$
\end_inset

, define the 
\series bold
moment generating function
\series default
 (MGF) as 
\begin_inset Formula 
\[
M_{X}(t)=E\left(e^{tX}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
To see why it is 
\begin_inset Quotes eld
\end_inset

generating
\begin_inset Quotes erd
\end_inset

 moments, take the Taylor expansion of the exponential function: 
\begin_inset Formula 
\[
e^{tX}=1+tX+\frac{t^{2}X^{2}}{2!}+\frac{t^{3}X^{3}}{3!}+\cdots
\]

\end_inset

Hence, 
\begin_inset Formula 
\[
M_{X}(t)=E\left(e^{tX}\right)=1+E(X)t+E(X^{2})\frac{t^{2}}{2!}+\cdots
\]

\end_inset


\end_layout

\begin_layout Standard
A natural question at this point is: What is the interpretation of 
\begin_inset Formula $t$
\end_inset

? The answer is that 
\begin_inset Formula $t$
\end_inset

 has no interpretation in particular; it’s just a bookkeeping device that
 we introduce in order to 
\emph on
encode
\emph default
 the sequence of moments in a differentiable function.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $M_{X}(t)$
\end_inset

 be the MGF of 
\begin_inset Formula $X$
\end_inset

.
 Then the 
\begin_inset Formula $n$
\end_inset

-th moment of 
\begin_inset Formula $X$
\end_inset

 is given by 
\begin_inset Formula $E(X^{n})=M_{X}^{(n)}(0)$
\end_inset

, where 
\begin_inset Formula $M_{X}^{(n)}$
\end_inset

 denotes the 
\begin_inset Formula $n$
\end_inset

-th derivative of the MGF.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
The MGF of a random variable determines its distribution: if two random
 variables have the same MGF, they must have the same distribution.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent, then the MGF of 
\begin_inset Formula $X+Y$
\end_inset

 is the product of the individual MGFs:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{X+Y}(t)=M_{X}(t)M_{Y}(t).
\]

\end_inset


\end_layout

\begin_layout Example
For 
\begin_inset Formula $X\sim Bern(p)$
\end_inset

, 
\begin_inset Formula $e^{tX}$
\end_inset

 takes on the value 
\begin_inset Formula $e^{t}$
\end_inset

 with probability 
\begin_inset Formula $p$
\end_inset

 and the value 
\begin_inset Formula $1$
\end_inset

 with probability 
\begin_inset Formula $q$
\end_inset

, so 
\begin_inset Formula $M(t)=E\left(e^{tX}\right)=pe^{t}+q$
\end_inset

.
 Since this is ﬁnite for all values of 
\begin_inset Formula $t$
\end_inset

, the MGF is deﬁned on the entire real line.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The MGF of a 
\begin_inset Formula $Bin(n,p)$
\end_inset

 random variable is 
\begin_inset Formula $M(t)=(pe^{t}+q)^{n}$
\end_inset

, since it is the product of 
\begin_inset Formula $n$
\end_inset

 independent Bernoulli MGFs.
\end_layout

\begin_layout Section
Poisson distribution
\end_layout

\begin_layout Standard
Now we introduce arguably the most popular discrete distribution—Poisson
 distribution.
 Poisson distribution is used to model independent events occurring at a
 constant mean rate.
 It is like the Binomial distribution in the sense that they both model
 the number of occurrence of events, but it is parametrized on the 
\begin_inset Quotes eld
\end_inset

rate
\begin_inset Quotes erd
\end_inset

 of the event (how many times an event occurs in a unit of time on average)
 rather than the total number of events and the probability of each event.
 It is therefore more practical in real-world modeling since we mostly observe
 the rate rather than the totality.
 We introduce the Poisson distribution by showing that it is a limiting
 case of the Binomial distribution.
 
\end_layout

\begin_layout Problem
Suppose we are studying the distribution of the number of visitors to a
 certain website.
 Every day, a million people independently decide whether to visit the site,
 with probability 
\begin_inset Formula $p=2\times10^{-6}$
\end_inset

 of visiting.
 What is the probability of getting 
\begin_inset Formula $k$
\end_inset

 visitors on a particular day? 
\end_layout

\begin_layout Problem
We can model the problem with a Binomial distribution.
 Let 
\begin_inset Formula $X\sim Bin(n,p)$
\end_inset

 be the number of visitors, where 
\begin_inset Formula $n=10^{6}$
\end_inset

 and 
\begin_inset Formula $p=2\times10^{-6}$
\end_inset

.
 But it is easy to run into computational difficulties with such a large
 
\begin_inset Formula $n$
\end_inset

 and small 
\begin_inset Formula $p$
\end_inset

.
 This is not uncommon, if we want to model the number of emails one receives
 per day, or the number of phone calls in a service center.
 In such cases, we could reasonably assume 
\begin_inset Formula $n\to\infty$
\end_inset

 and 
\begin_inset Formula $p\to0$
\end_inset

 while 
\begin_inset Formula $np=\lambda$
\end_inset

 is a constant.
 We may call 
\begin_inset Formula $\lambda$
\end_inset

 — the 
\begin_inset Quotes eld
\end_inset

rate
\begin_inset Quotes erd
\end_inset

, as it can be interpreted as the average visitors per day.
 
\end_layout

\begin_layout Problem
Take limit of the Binomial distribution:
\begin_inset Formula 
\[
\begin{aligned}P(X=k)= & \lim_{n\to\infty}\binom{n}{k}p^{k}(1-p)^{n-k}\\
= & \lim_{n\to\infty}\binom{n}{k}\left(\frac{\lambda}{n}\right)^{k}\left(1-\frac{\lambda}{n}\right)^{n-k}\\
= & \lim_{n\to\infty}\text{\ensuremath{\frac{n!}{(n-k)!k!}}}\frac{\lambda^{k}}{n^{k}}\underbrace{\left(1-\frac{\lambda}{n}\right)^{n}}_{\to e^{-\lambda}}\underbrace{\left(1-\frac{\lambda}{n}\right)^{-k}}_{\to1}\\
= & \lim_{n\to\infty}\underbrace{\frac{n!}{n^{k}(n-k)!}}_{\to1}\frac{\lambda^{k}}{k!}e^{-\lambda}\\
= & \frac{\lambda^{k}}{k!}e^{-\lambda}.
\end{aligned}
\]

\end_inset

This is the PMF of the Poisson distribution.
\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
Poisson distribution
\series default
 with parameter 
\begin_inset Formula $\lambda$
\end_inset

 if the PMF of 
\begin_inset Formula $X$
\end_inset

 is 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X=k)=\frac{e^{-\lambda}\lambda^{k}}{k!},\quad k=0,1,2,\ldots
\]

\end_inset


\end_layout

\begin_layout Definition
We denote this as 
\begin_inset Formula $X\sim\textrm{Pois}(\lambda)$
\end_inset

.
 We can easily verify this is a valid PMF because 
\begin_inset Formula $\sum_{k=0}^{\infty}\frac{\lambda^{k}}{k!}=e^{\lambda}$
\end_inset

.
 
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X\sim Bin(n,p)$
\end_inset

 and we let 
\begin_inset Formula $n\to\infty$
\end_inset

 and 
\begin_inset Formula $p\to0$
\end_inset

 such that 
\begin_inset Formula $\lambda=np$
\end_inset

 remains fixed, then the PMF of 
\begin_inset Formula $X$
\end_inset

 converges to the PMF of 
\begin_inset Formula $Pois(\lambda)$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "thm:Pois"

\end_inset


\end_layout

\begin_layout Standard
The expectation of the Poisson distribution is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned}E(X)= & \sum_{k=0}^{\infty}k\cdot\frac{e^{-\lambda}\lambda^{k}}{k!}\\
= & e^{-\lambda}\sum_{k=1}^{\infty}\frac{\lambda^{k}}{(k-1)!}\\
= & \lambda e^{-\lambda}\sum_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!}\\
= & \lambda e^{-\lambda}e^{\lambda}=\lambda.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
To get the variance, we first compute 
\begin_inset Formula $E(X^{2})$
\end_inset

.
 By LOTUS,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned}E(X^{2})= & \sum_{k=0}^{\infty}k^{2}\cdot\frac{e^{-\lambda}\lambda^{k}}{k!}=e^{-\lambda}\sum_{k=1}^{\infty}k^{2}\frac{\lambda^{k}}{k!}\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
Differentiate 
\begin_inset Formula $\sum_{k=0}^{\infty}\frac{\lambda^{k}}{k!}=e^{\lambda}$
\end_inset

 on both sides with respect to 
\begin_inset Formula $\lambda$
\end_inset

 and multiply (replenish) again by 
\begin_inset Formula $\lambda$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{k-1}^{\infty}k\frac{\lambda^{k}}{k!}=\lambda e^{\lambda}
\]

\end_inset


\end_layout

\begin_layout Standard
Repeat:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{k-1}^{\infty}k^{2}\frac{\lambda^{k}}{k!}=\lambda(e^{\lambda}+\lambda e^{\lambda})
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, we have 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(X^{2})=e^{-\lambda}(\lambda+\lambda^{2})e^{\lambda}=\lambda+\lambda^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Finally, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var(X)=E(X^{2})-(E(X))^{2}=\lambda+\lambda^{2}-\lambda^{2}=\lambda.
\]

\end_inset


\end_layout

\begin_layout Example
Continued with the website visiting example, there are one million people
 visiting the site every day, each with probability 
\begin_inset Formula $p=2\times10^{-6}$
\end_inset

.
 Give an approximation for the probability of getting at least three visitors
 on a particular day.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X$
\end_inset

 be the number of visitors.
 Since 
\begin_inset Formula $n$
\end_inset

 is large, 
\begin_inset Formula $p$
\end_inset

 is small, 
\begin_inset Formula $np=2$
\end_inset

 is fixed, 
\begin_inset Formula $X$
\end_inset

 is well approximated by 
\begin_inset Formula $Pois(2)$
\end_inset

.
 Therefore, 
\begin_inset Formula 
\begin{align*}
P(X\geq3)=1-P(X<3) & =1-P(X=0)-P(X=1)-P(X=2)\\
 & =1-e^{-2}-2e^{-2}-\frac{2^{2}}{2!}e^{-2}\\
 & =1-5e^{-2}\approx0.32.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
What is the probability of an earthquakes in a year in Sichuan? 
\end_layout

\begin_layout Example
Historical records
\begin_inset Foot
status open

\begin_layout Plain Layout
See 
\begin_inset CommandInset href
LatexCommand href
name "this article"
target "https://www.scdzj.gov.cn/dzpd/dzkp/202201/t20220125_51277.html"
literal "false"

\end_inset

 from the Sichuan Earthquake Administration.
\end_layout

\end_inset

 show that, from 26 BCE to 2021 CE, there were 309 earthquakes with magnitude
 of 5.0 or greater.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of earthquakes with magnitude 5.0 or greater.
 The annual rate 
\begin_inset Formula $\lambda$
\end_inset

 of earthquakes is therefore 
\begin_inset Formula $\frac{309}{2048}=0.15$
\end_inset

.
 Assume earthquakes are independent events (not always the case).
 Then 
\begin_inset Formula $X\sim\textrm{Pois}(0.15)$
\end_inset

.
 By the distribution of the Poisson distribution, 
\begin_inset Formula 
\[
P(X=k)=\begin{cases}
0.86 & k=0\\
0.13 & k=1\\
0.01 & k=2
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
The Poisson distribution is often used in situations where we are counting
 the number of successes in a particular region or interval of time, where
 there are a large number of trials, each with a small probability of success.
 The Poisson paradigm says in situations like this, we can approximate the
 number of successes by a Poisson distribution.
 It is more general than Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:Pois"
plural "false"
caps "false"
noprefix "false"

\end_inset

, as we relax the assumption of independence and identical events.
 
\end_layout

\begin_layout Proposition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Poisson paradigm
\end_layout

\end_inset

Let 
\begin_inset Formula $A_{1},\dots,A_{n}$
\end_inset

 be events with 
\begin_inset Formula $p_{j}=P(A_{j})$
\end_inset

, where 
\begin_inset Formula $n$
\end_inset

 is large, the 
\begin_inset Formula $p_{j}$
\end_inset

 are small, and the 
\begin_inset Formula $A_{j}$
\end_inset

 are independent or weakly dependent.
 Then 
\begin_inset Formula $X=\sum_{j=1}^{n}I(A_{j})$
\end_inset

, that is how many of the 
\begin_inset Formula $A_{j}$
\end_inset

 occur, is approximately distributed as 
\begin_inset Formula $Pois(\lambda)$
\end_inset

 with 
\begin_inset Formula $\lambda=\sum_{j=1}^{n}p_{j}$
\end_inset

.
\end_layout

\begin_layout Standard
The Poisson paradigm is also called the 
\emph on
law of rare events
\emph default
.
 The interpretation of “rare” is that the 
\begin_inset Formula $p_{j}$
\end_inset

 are small, but 
\begin_inset Formula $\lambda$
\end_inset

 is relatively stable.
 The number of events that occur may not be exactly Poisson, but the Poisson
 distribution often gives good approximations.
 Note that the conditions for the Poisson paradigm to hold are fairly ﬂexible:
 the 
\begin_inset Formula $n$
\end_inset

 trials can have different success probabilities, and the trials don’t have
 to be independent, though they should not be very dependent.
 So there are a wide variety of situations that can be cast in terms of
 the Poisson paradigm.
 This makes the Poisson a very popular model.
\end_layout

\begin_layout Example
If we have 
\begin_inset Formula $m$
\end_inset

 people and 
\begin_inset Formula $\binom{m}{2}$
\end_inset

 pairs.
 Each pair of people has probability 
\begin_inset Formula $p=1/365$
\end_inset

 of having the same birthday.
 Find the probability of at least one match.
 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: The probability of match is small, and the number of pairs is large.
 We consider using the Poisson paradigm to approximate the number 
\begin_inset Formula $X$
\end_inset

 of birthday matches.
 
\begin_inset Formula $X\approx Pois(\lambda)$
\end_inset

 where 
\begin_inset Formula $\lambda=\binom{m}{2}\frac{1}{365}$
\end_inset

.
 Then the probability of at least one match is 
\begin_inset Formula 
\[
P(X\geq1)=1-P(X=0)\approx1-e^{-\lambda}.
\]

\end_inset

For 
\begin_inset Formula $m=23$
\end_inset

, 
\begin_inset Formula $\lambda=253/365$
\end_inset

 and 
\begin_inset Formula $1-e^{-\lambda}\approx0.5$
\end_inset

, which agrees with our previous finding that we need 23 people to have
 50% chance of a birthday match.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Continued with the assumption above.
 What's the probability of two people who were born not only on the same
 day, but also at the same hour and the same minute? 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: This is the birthday problem with 
\begin_inset Formula $c=365\cdot24\cdot60=525600$
\end_inset

 categories rather than 
\begin_inset Formula $365$
\end_inset

 categories.
 By Poisson approximation, the probability of at least one match is approximatel
y 
\begin_inset Formula $1-e^{-\lambda_{1}}$
\end_inset

 where 
\begin_inset Formula $\lambda_{1}=\binom{m}{2}\frac{1}{525600}$
\end_inset

.
 This would require 
\begin_inset Formula $m=854$
\end_inset

 to reach the break even point, 50% chance of getting a match.
 
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X\sim Pois(\lambda_{1})$
\end_inset

, 
\begin_inset Formula $Y\sim Pois(\lambda_{2})$
\end_inset

, and 
\begin_inset Formula $X,Y$
\end_inset

 are independent, then 
\begin_inset Formula $X+Y\sim Pois(\lambda_{1}+\lambda_{2})$
\end_inset

.
 
\end_layout

\begin_layout Proof
To get the PMF of 
\begin_inset Formula $X+Y$
\end_inset

, condition on 
\begin_inset Formula $X$
\end_inset

 and use the law of total probability: 
\begin_inset Formula 
\begin{align*}
P(X+Y=k) & =\sum_{j=0}^{k}P(X+Y=k|X=j)P(X=j)\\
 & =\sum_{j=0}^{k}P(Y=k-j)P(X=j)\\
 & =\sum_{j=0}^{k}\frac{e^{-\lambda_{2}}\lambda_{2}^{k-j}}{(k-j)!}\cdot\frac{e^{-\lambda_{1}}\lambda_{1}^{j}}{j!}\\
 & =\frac{e^{-(\lambda_{1}+\lambda_{2})}}{k!}\sum_{j=0}^{k}\binom{k}{j}\lambda_{1}^{j}\lambda_{2}^{k-j}\\
 & =\frac{e^{-(\lambda_{1}+\lambda_{2})}}{k!}(\lambda_{1}+\lambda_{2})^{k}.
\end{align*}

\end_inset

We thus arrive at the PMF for 
\begin_inset Formula $Pois(\lambda_{1}+\lambda_{2})$
\end_inset

.
 The intuition is, if there are two different types of events occurring
 at rates 
\begin_inset Formula $\lambda_{1}$
\end_inset

 and 
\begin_inset Formula $\lambda_{2}$
\end_inset

, independently, then the overall event rate is 
\begin_inset Formula $\lambda_{1}+\lambda_{2}$
\end_inset

.
\end_layout

\begin_layout Section
Inequalities*
\end_layout

\begin_layout Standard
This section introduces some of the most popular inequality in statistics
 and general mathematics.
 Interestingly, our probability theories can shed light on these inequalities
 that are otherwise hard to explain.
 We don't show formal proofs here, but just point out how these inequalities
 can be useful in statistics.
 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Cauchy-Schwarz inequality
\end_layout

\end_inset


\begin_inset Formula 
\[
\left|\sum x_{i}y_{i}\right|\leq\sqrt{\sum x_{i}^{2}}\sqrt{\sum y_{i}^{2}}
\]

\end_inset


\end_layout

\begin_layout Proof
If 
\begin_inset Formula $X,Y$
\end_inset

 have zero means, their correlation can be written as
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\rho_{XY}=\frac{E(XY)}{\sqrt{E(X^{2})E(Y^{2})}}
\]

\end_inset

Since 
\begin_inset Formula $|\rho_{XY}|\leq1$
\end_inset

, we always have 
\begin_inset Formula 
\[
|E(XY)|\leq\sqrt{E(X^{2})E(Y^{2})}.
\]

\end_inset


\end_layout

\begin_layout Proof
Consider 
\begin_inset Formula $\{x_{i}\}$
\end_inset

 and 
\begin_inset Formula $\{y_{i}\}$
\end_inset

 as realizations of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 with equal probabilities, such that 
\begin_inset Formula $E(X)=\frac{1}{n}\sum x_{i}$
\end_inset

.
 The original inequality is thus proved.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Jensen's inequality
\end_layout

\end_inset

 For a convex function 
\begin_inset Formula $f$
\end_inset

, we have
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
\frac{1}{n}\sum f(x_{i})\geq f\left(\frac{1}{n}\sum x_{i}\right);
\]

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $f$
\end_inset

 is concave, then
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
\frac{1}{n}\sum f(x_{i})\leq f\left(\frac{1}{n}\sum x_{i}\right).
\]

\end_inset


\end_layout

\begin_layout Proof
This is not a proof, but a special case that helps to understand Jensen's
 inequality.
 Since 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
Var(X)=E(X^{2})-(E(X))^{2}\geq0
\]

\end_inset


\end_layout

\begin_layout Proof
We have
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
E(X^{2})\geq(E(X))^{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula $f(X)=X^{2}$
\end_inset

 is a convex function, and 
\begin_inset Formula $E(*)=\frac{1}{n}\sum*$
\end_inset

, we have shown the first inequality.
 The concave case is the opposite.
 
\end_layout

\begin_layout Proof
In general, if 
\begin_inset Formula $g$
\end_inset

 is a convex function, then 
\begin_inset Formula $E(g(X))\geq g(E(X))$
\end_inset

.
 If 
\begin_inset Formula $g$
\end_inset

 is a concave function, then 
\begin_inset Formula $E(g(X))\leq g(E(X))$
\end_inset

.
 In both cases, the only way that equality can hold is if there are constants
 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 such that 
\begin_inset Formula $g(X)=a+bX$
\end_inset

 with probability 1.
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Markov inequality
\end_layout

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 be a random variable, then
\begin_inset Formula 
\[
P(|X|\geq a)\leq\frac{E|X|}{a}
\]

\end_inset

That is, the probability of 
\begin_inset Formula $|X|$
\end_inset

 deviating from its mean by a multiple of 
\begin_inset Formula $a$
\end_inset

 must be less than 
\begin_inset Formula $1/a$
\end_inset

.
\end_layout

\begin_layout Proof
Define a random variable 
\begin_inset Formula 
\[
I_{|X|\geq a}=\begin{cases}
1 & \textrm{if }|X|\geq a\\
0 & \textrm{if }|X|<a
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula $P(|X|\geq a)=E(I_{|X|\geq a})$
\end_inset

.
 It always holds that 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
a\cdot I_{|X|\geq a}\leq|X|
\]

\end_inset


\end_layout

\begin_layout Proof
Therefore, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
E\left[a\cdot I_{|X|\geq a}\right]\leq E|X|
\]

\end_inset


\end_layout

\begin_layout Proof
Hence,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
P(|X|\geq a)\leq\frac{E|X|}{a}.
\]

\end_inset


\end_layout

\begin_layout Standard
For an intuitive interpretation, let 
\begin_inset Formula $X$
\end_inset

 be the income of a randomly selected individual from a population.
 Taking 
\begin_inset Formula $a=2E(X)$
\end_inset

, Markov’s inequality says that 
\begin_inset Formula $P(X\geq2E(X))\leq1/2$
\end_inset

, i.e., it is impossible for more than half the population to make at least
 twice the average income.
 This is clearly true, since if over half the population were earning at
 least twice the average income, the average income would be higher.
 Similarly, 
\begin_inset Formula $P(X\geq3E(X))\leq1/3$
\end_inset

: you can’t have more than 
\begin_inset Formula $1/3$
\end_inset

 of the population making at least three times the average income, since
 those people would already drive the average above what it is.
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Chebyshev inequality
\end_layout

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 be a random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 and standard deviation 
\begin_inset Formula $\sigma$
\end_inset

, then
\begin_inset Formula 
\[
P\left(\left|X-\mu\right|>c\sigma\right)\leq\frac{1}{c^{2}}
\]

\end_inset

That is, the probability of 
\begin_inset Formula $X$
\end_inset

 deviating from its mean by 
\begin_inset Formula $a$
\end_inset

 times the standard deviation must be less than 
\begin_inset Formula $1/a^{2}$
\end_inset

.
\end_layout

\begin_layout Proof
We first show 
\begin_inset Formula 
\[
P(|X-\mu|>a)\leq\frac{\sigma^{2}}{a^{2}}
\]

\end_inset

This is true by taking squares and applying the Markov inequality,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
P(|X-\mu|>a)=P((X-\mu)^{2}>a^{2})\leq\frac{E(X-\mu)^{2}}{a^{2}}=\frac{\sigma^{2}}{a^{2}}.
\]

\end_inset


\end_layout

\begin_layout Proof
Substitute 
\begin_inset Formula $c\sigma$
\end_inset

 for 
\begin_inset Formula $a$
\end_inset

, we have the original inequality.
\end_layout

\begin_layout Standard
This gives us an upper bound on the probability of a random variable being
 more than 
\begin_inset Formula $c$
\end_inset

 standard deviations away from its mean, e.g., there can’t be more than a
 25% chance of being 2 or more standard deviations from the mean.
 Given the mean and standard deviation of a random variable 
\begin_inset Formula $X$
\end_inset

, we know that 
\begin_inset Formula $\mu\pm2\sigma$
\end_inset

 captures 75% of its possible values; 
\begin_inset Formula $\mu\pm3\sigma$
\end_inset

 captures 90% of the possible values.
\end_layout

\begin_layout Chapter
Continuous Distributions
\end_layout

\begin_layout Section
Continuous random variables
\end_layout

\begin_layout Standard
Continuous random variables, in many ways, are more versatile and useful
 than discrete distributions.
 One key reason is that many quantities in the physical world, such as temperatu
re, height, weight, and time, are inherently continuous in nature.
 These variables can take on any value within a range, providing a more
 accurate representation of real-world phenomena compared to discrete variables,
 which are limited to distinct values.
 Additionally, the probability density functions (PDFs) of continuous distributi
ons are often defined by smooth, differentiable functions.
 This mathematical structure allows us to apply calculus for analysis, enabling
 precise calculations of probabilities, expected values, and other statistical
 measures.
 The ability to integrate and differentiate these functions not only simplifies
 manipulation but also makes continuous distributions a powerful tool for
 solving complex problems in physics, engineering, and data analysis.
\end_layout

\begin_layout Definition
A random variable has a continuous distribution if its CDF is 
\emph on
differentiable
\emph default
.
 A continuous random variable is a random variable with a continuous distributio
n.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
For a continuous random variable 
\begin_inset Formula $X$
\end_inset

 with CDF 
\begin_inset Formula $F$
\end_inset

, the 
\series bold
probability density function
\series default
 (PDF) of 
\begin_inset Formula $X$
\end_inset

 is the derivative of the CDF, given by 
\begin_inset Formula $f(x)=F'(x)$
\end_inset

.
 The support of 
\begin_inset Formula $X$
\end_inset

 is the set of all 
\begin_inset Formula $x$
\end_inset

 where 
\begin_inset Formula $f(x)>0$
\end_inset

.
\end_layout

\begin_layout Remark*
By the fundamental theorem of calculus, we integrate a PDF to get the CDF:
 
\begin_inset Formula 
\[
F(x)=\int_{-\infty}^{x}f(t)dt.
\]

\end_inset

PDF differs from the discrete PMF in important ways:
\end_layout

\begin_deeper
\begin_layout Itemize
For a continuous random variable, 
\begin_inset Formula $P(X=x)=0$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

;
\end_layout

\begin_layout Itemize
The quantity 
\begin_inset Formula $f(x)$
\end_inset

 is not a probability.
 To get the probability, we integrate the PDF (probability is the area under
 the PDF): 
\begin_inset Formula 
\[
P(a<X\leq b)=F(b)-F(a)=\int_{a}^{b}f(x)dx.
\]

\end_inset


\end_layout

\begin_layout Itemize
Since any single value has probability 0, including or excluding endpoints
 does not matter.
 
\begin_inset Formula 
\[
P(a<X<b)=P(a<X\leq b)=P(a\leq X<b)=P(a\leq X\leq b).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Theorem
The PDF 
\begin_inset Formula $f$
\end_inset

 of a continuous random variable must satisfy the following criteria: 
\end_layout

\begin_deeper
\begin_layout Itemize
Nonnegative: 
\begin_inset Formula $f(x)\geq0$
\end_inset

;
\end_layout

\begin_layout Itemize
Integrates to 1: 
\begin_inset Formula $\int_{-\infty}^{\infty}f(x)dx=1$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Definition
The 
\series bold
expectation
\series default
 of a continuous random variable 
\begin_inset Formula $X$
\end_inset

 with PDF 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula 
\[
E(X)=\int_{-\infty}^{\infty}xf(x)dx.
\]

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X$
\end_inset

 is a continuous random variable with PDF 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g:\mathbb{R}\to\mathbb{R}$
\end_inset

.
 The LOTUS applies 
\begin_inset Formula 
\[
E[g(X)]=\int_{-\infty}^{\infty}g(x)f(x)dx.
\]

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Discrete
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Continuous
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PMF/PDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x)=p(x)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(a\leq X\leq b)=\int_{a}^{b}f(x)dx$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F(x)=P(X\leq x)=\sum_{k\leq x}p(k)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F(x)=P(X\leq x)=\int_{-\infty}^{x}f(t)dt$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Expectation
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E(x)=\sum_{x}xP(X=x)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E(X)=\int_{-\infty}^{+\infty}xf(x)dx$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LOTUS
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E[g(x)]=\sum_{x}g(x)P(X=x)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E[g(x)]=\int_{-\infty}^{+\infty}g(x)f(x)dx$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Special integrals
\end_layout

\begin_layout Standard
There are many reasons to learn integrals.
 But the most compelling reason is that math is no longer the same with
 integrals.
 We can have many amazing results with integrals that were otherwise not
 imaginable.
 This section is not directly related to our main theme.
 But let's take a detour just to appreciate the beauty of integrals.
 
\end_layout

\begin_layout Example
Show that 
\begin_inset Formula $\int_{-\infty}^{+\infty}e^{-x^{2}}dx=\sqrt{\pi}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "eg:GaussInt"

\end_inset


\end_layout

\begin_layout Proof
This is known as Gaussian integral, which is the kernel of the PDF of the
 normal distribution.
 It also amazingly relates two of the most famous constants in mathematics.
 It is not integrable by normal integration techniques.
 But it can be solved by switching to the polar coordinate.
 
\begin_inset Formula 
\[
\begin{aligned}\left(\int_{-\infty}^{+\infty}e^{-x^{2}}dx\right)^{2}= & \int_{-\infty}^{+\infty}e^{-x^{2}}dx\int_{-\infty}^{+\infty}e^{-y^{2}}dy\\
= & \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{-(x^{2}+y^{2})}dxdy\\
= & \int_{0}^{2\pi}\int_{0}^{\infty}e^{-r^{2}}rdrd\theta & dA=dxdy=rdrd\theta\\
= & \int_{0}^{2\pi}\int_{0}^{\infty}\frac{1}{2}e^{-u}dud\theta & \textrm{let }u=r^{2}\\
= & \frac{1}{2}\int_{0}^{2\pi}d\theta=\pi.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Show that 
\begin_inset Formula $\int_{0}^{\infty}t^{n}e^{-t}dt=n!$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\Gamma(z)=\int_{0}^{\infty}t^{z-1}e^{-t}dt$
\end_inset

 is known as the Gamma function, which is definitely one of the most interesting
 functions in mathematics.
 It is the extension of factorials to real numbers or even complex numbers.
 It also has many interesting properties, such as 
\begin_inset Formula $\Gamma(n)=(n-1)!$
\end_inset

, 
\begin_inset Formula $\Gamma(1/2)=\sqrt{\pi}$
\end_inset

, 
\begin_inset Formula $\Gamma(3/2)=\sqrt{\pi}/2$
\end_inset

, 
\begin_inset Formula $\Gamma'(1)=-\gamma$
\end_inset

 and so on.
 The 
\begin_inset Formula $(n-1)$
\end_inset

 in the Gamma function is due to historical reasons and does not matter
 in our case.
 We will prove the integral with 
\begin_inset Formula $n$
\end_inset

 instead of 
\begin_inset Formula $(n-1)$
\end_inset

.
 
\end_layout

\begin_layout Proof
There are many ways to prove this.
 One is to discover the recursive relationship 
\begin_inset Formula $\Gamma(n+1)=n\Gamma(n)$
\end_inset

.
 But it does not give a clue why we need this integral to approximate the
 factorial.
 We start with an elementary integral
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\int_{0}^{\infty}e^{at}dt=-\frac{1}{a}
\]

\end_inset

where 
\begin_inset Formula $a<0$
\end_inset

.
 Differentiate both sides 
\begin_inset Formula $n$
\end_inset

 times with respect to 
\begin_inset Formula $a$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\begin{aligned}\int_{0}^{\infty}e^{at}tdt & = & -(-1)a^{-2}\\
\int_{0}^{\infty}e^{at}t^{2}dt & = & -(-1)(-2)a^{-3}\\
\int_{0}^{\infty}e^{at}t^{3}dt & = & -(-1)(-2)(-3)a^{-4}\\
 & \vdots\\
\int_{0}^{\infty}e^{at}t^{n}dt & = & (-1)^{n+1}n!a^{-(n+1)}
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $a=-1$
\end_inset

, we have 
\begin_inset Formula 
\[
\int_{0}^{\infty}e^{t}t^{n}=n!
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Uniform distribution
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 be two given real numbers such that 
\begin_inset Formula $a<b$
\end_inset

.
 Let 
\begin_inset Formula $X$
\end_inset

 be a random variable such that it is known that 
\begin_inset Formula $a\leq X\leq b$
\end_inset

 and, for every subinterval of 
\begin_inset Formula $[a,b]$
\end_inset

, the probability that 
\begin_inset Formula $X$
\end_inset

 will belong to that subinterval is proportional to the length of that subinterv
al.
 We then say that the random variable 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
Uniform distribution
\series default
 on the interval 
\begin_inset Formula $[a,b]$
\end_inset

.
 The PDF of 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula 
\[
f(x)=\begin{cases}
\frac{1}{b-a} & \textrm{for }a\leq x\leq b\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
This is a valid PDF since 
\begin_inset Formula 
\[
\int_{-\infty}^{+\infty}f(x)dx=\int_{a}^{b}\frac{1}{b-a}dx=\frac{1}{b-a}\int_{a}^{b}dx=1.
\]

\end_inset


\end_layout

\begin_layout Standard
The CDF of 
\begin_inset Formula $X$
\end_inset

 is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
F(x)=\int_{-\infty}^{x}f(t)dt=\int_{a}^{x}f(t)dt=\begin{cases}
0 & x<a\\
\frac{x-a}{b-a} & a\leq x\leq b\\
1 & x>b
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
The expectation of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(X)=\int_{a}^{b}x\frac{1}{b-a}dx=\frac{1}{b-a}\left[\frac{x^{2}}{2}\right]_{a}^{b}=\frac{a+b}{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
To figure out the variance, first compute
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(X^{2})=\int_{a}^{b}x^{2}\frac{1}{b-a}dx=\frac{1}{b-a}\left[\frac{x^{3}}{3}\right]_{a}^{b}=\frac{a^{2}+ab+b^{2}}{3}
\]

\end_inset


\end_layout

\begin_layout Standard
Thus,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var(X)=E(X^{2})-E^{2}(X)=\frac{a^{2}+ab+b^{2}}{3}-\frac{(a+b)^{2}}{4}=\frac{(b-a)^{2}}{12}.
\]

\end_inset


\end_layout

\begin_layout Exercise
A stick of unit length is broken at a random point X.
 What is the expected length of the longer piece?
\end_layout

\begin_layout Exercise

\emph on
Solution
\emph default
: The lengths of the two pieces are 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $1-X$
\end_inset

, with 
\begin_inset Formula $X\sim Unif(0,1)$
\end_inset

.
 The longer piece is 
\begin_inset Formula $\max(X,1-X)$
\end_inset

.
 For 
\begin_inset Formula $X<0.5$
\end_inset

, the longer piece is 
\begin_inset Formula $1-X$
\end_inset

, and for 
\begin_inset Formula $X\geq0.5$
\end_inset

, it is 
\begin_inset Formula $X$
\end_inset

.
 The expected value is:
\begin_inset Formula 
\[
E[\max(X,1-X)]=\int_{0}^{0.5}(1-X)\,dx+\int_{0.5}^{1}X\,dx=\frac{3}{4}.
\]

\end_inset


\end_layout

\begin_layout Section
Normal distribution
\end_layout

\begin_layout Standard
The most widely used model for random variables with continuous distributions
 is the family of normal distributions.
 One reason is that many real world samples appears to be normally distributed
 (the mass centered around the mean).
 The other reason is because of the Central Limit Theorem (will be discussed
 in later chapters), which essentially says the sum (or mean) or any random
 samples are approximately normal.
\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $Z$
\end_inset

 has the 
\series bold
standard Normal distribution
\series default
 with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1$
\end_inset

, denoted as 
\begin_inset Formula $Z\sim N(0,1)$
\end_inset

, if 
\begin_inset Formula $Z$
\end_inset

 has a PDF that follows 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
f(z)=\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}.
\]

\end_inset


\end_layout

\begin_layout Standard
This is a valid PDF because 
\begin_inset Formula $\int_{-\infty}^{\infty}f(z)dz=1$
\end_inset

, which directly follows from Example 
\begin_inset CommandInset ref
LatexCommand ref
reference "eg:GaussInt"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We further verify its mean and variance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(Z)=\int_{-\infty}^{+\infty}z\cdot\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}dz=0\quad\textrm{by symmetry.}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Var(Z) & =E(Z^{2})-(EZ)^{2}=E(Z^{2})\\
 & =\int_{-\infty}^{+\infty}z^{2}\cdot\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}dz\\
 & =\frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}\underbrace{z}_{u}\cdot\underbrace{ze^{-z^{2}/2}dz}_{dv}\\
 & =\frac{2}{\sqrt{2\pi}}\left\{ \left[z(-e^{-z^{2}/2})\right]_{0}^{\infty}+\underbrace{\int_{0}^{\infty}e^{-z^{2}/2}dz}_{\sqrt{2\pi}/2}\right\} \\
 & =1.
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
The CDF of standard normal distribution is usually denoted by 
\begin_inset Formula $\Phi$
\end_inset

.
 Therefore,
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\Phi(z)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{z}e^{-t^{2}/2}dt.
\]

\end_inset


\end_layout

\begin_layout Definition
By symmetry, we have 
\begin_inset Formula $\Phi(-z)=1-\Phi(z)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X=\mu+\sigma Z$
\end_inset

 where 
\begin_inset Formula $Z\sim N(0,1)$
\end_inset

.
 Then we say 
\begin_inset Formula $X$
\end_inset

 has the 
\series bold
Normal distribution
\series default
 with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, denoted as 
\begin_inset Formula $X\sim N(\mu,\sigma^{2})$
\end_inset

.
 The PDF of 
\begin_inset Formula $X$
\end_inset

 is given by 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
f(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
The mean and variance of 
\begin_inset Formula $X$
\end_inset

 can be easily verified by the properties of expectation and variance.
 
\begin_inset Formula 
\begin{align*}
E(X) & =E(\mu+\sigma Z)=\mu+\sigma E(Z)=\mu,\\
Var(X) & =Var(\mu+\sigma Z)=\sigma^{2}Var(Z)=\sigma^{2}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
To verify the PDF, we utilize the standard normal CDF:
\begin_inset Formula 
\[
P(X\leq x)=P\left(\frac{X-\mu}{\sigma}\leq\frac{x-\mu}{\sigma}\right)=\Phi\left(\frac{x-\mu}{\sigma}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The PDF is the derivative of the CDF,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(x)=\frac{1}{\sigma}\Phi'\left(\frac{x-\mu}{\sigma}\right)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
The shape of the normal distribution is the famous bell-shaped curve.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename img/normal.png
	width 50col%

\end_inset


\end_layout

\begin_layout Standard
The normal distribution has the 
\begin_inset Quotes eld
\end_inset

three-sigma rule
\begin_inset Quotes erd
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P(|X-\mu|\leq\sigma) & \approx0.68\\
P(|X-\mu|\leq2\sigma) & \approx0.95\\
P(|X-\mu|\leq3\sigma) & \approx0.997
\end{align*}

\end_inset

Critical values: 
\begin_inset Formula $\Phi(-1)\approx0.16,\Phi(-2)\approx0.025,\Phi(-3)\approx0.0015$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 have the Normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 Let 
\begin_inset Formula $F$
\end_inset

 be the CDF of 
\begin_inset Formula $X$
\end_inset

.
 Then the 
\series bold
standardization
\series default
 of 
\begin_inset Formula $X$
\end_inset


\begin_inset Formula 
\[
Z=\frac{X-\mu}{\sigma}
\]

\end_inset

has the standard normal distribution, and, for all 
\begin_inset Formula $x$
\end_inset

 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
F(x)=\Phi\left(\frac{x-\mu}{\sigma}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
To find the value of 
\begin_inset Formula $\Phi(z)$
\end_inset

, we need to use the normal probability table or statistical softwares.
 
\end_layout

\begin_layout Example
Suppose the test score of a class of 50 students is normally distributed
 with mean 80 and standard deviation 20 (the total mark is 100).
 A student has scored 90.
 What is his percentile in the class?
\end_layout

\begin_layout Example
Solution: 
\begin_inset Formula $X\sim N(80,20)$
\end_inset

.
 We want to find 
\begin_inset Formula $P(X<90)$
\end_inset

.
 Standardize the distribution 
\begin_inset Formula 
\[
P(X<90)=P\left(\frac{X-80}{20}<\frac{90-80}{20}\right)=\Phi(0.5)\approx0.69.
\]

\end_inset


\end_layout

\begin_layout Theorem
Suppose 
\begin_inset Formula $X\sim N(\mu,\sigma^{2})$
\end_inset

.
 If 
\begin_inset Formula $Y=aX+b$
\end_inset

, then 
\begin_inset Formula $Y$
\end_inset

 has the Normal distribution 
\begin_inset Formula $Y\sim N(a\mu+b,a^{2}\sigma^{2})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
If the random variables 
\begin_inset Formula $X_{1},\ldots,X_{k}$
\end_inset

 are independent and 
\begin_inset Formula $X_{i}\sim N(\mu_{i},\sigma_{i}^{2})$
\end_inset

.
 Then 
\begin_inset Formula 
\[
X_{1}+\cdots+X_{k}\sim N(\mu_{1}+\cdots+\mu_{k},\sigma_{1}^{2}+\cdots+\sigma_{k}^{2}).
\]

\end_inset


\end_layout

\begin_layout Example
Suppose the heights (in inches) of women and men independently follow the
 normal distribution, 
\begin_inset Formula $X\sim N(165,25)$
\end_inset

, 
\begin_inset Formula $Y\sim N(170,25)$
\end_inset

.
 Determine the probability that a randomly selected woman will be taller
 than a man.
 
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
Let 
\begin_inset Formula $W=Y-X\sim N(170-165,25+25).$
\end_inset

 Then 
\begin_inset Formula $W\sim N(5,50)$
\end_inset

.
 Therefore,
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(W<0)=P\left(\frac{W-5}{\sqrt{50}}<\frac{-5}{\sqrt{50}}\right)=P\left(Z<-\frac{1}{\sqrt{2}}\right)=\Phi(-0.707)\approx0.24.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Distribution of sample mean
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{i}$
\end_inset

 be the height of a random individual.
 Assume 
\begin_inset Formula $X_{i}\sim N(\mu,\sigma^{2})$
\end_inset

.
 Let 
\begin_inset Formula $\{X_{1},X_{2},\dots,X_{n}\}$
\end_inset

 be a sample of 
\begin_inset Formula $n$
\end_inset

 people.
 The sample mean is calculated as 
\begin_inset Formula $\overline{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

.
 Determine the mean and variance of 
\begin_inset Formula $\overline{X}_{n}$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 By the theorem above, the sum of a series of normal distributions is also
 normal: 
\begin_inset Formula 
\[
\sum_{i=1}^{n}X_{i}=nX_{i}\sim N(n\mu,n\sigma^{2})
\]

\end_inset

 since we assume all 
\begin_inset Formula $X_{i}$
\end_inset

 follow the same distribution.
 Therefore, the distribution of the sample mean is 
\begin_inset Formula 
\[
\bar{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}\sim N(\mu,\sigma^{2}/n).
\]

\end_inset

That is, 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}/n$
\end_inset

.
\end_layout

\begin_layout Example
How do we understand the sample mean is also a random variable? A sample
 is a collection of random variables (each observation is a random variable
 in the sense that the outcome is uncertain).
 If you were to choose another sample, you would have a different sample
 mean.
 Therefore, the sample mean is also a random variable.
\end_layout

\begin_layout Section
Chi-Square and Student-
\begin_inset Formula $t$
\end_inset

*
\end_layout

\begin_layout Standard
We now introduce two distributions that are closely related to the Normal
 distribution.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $V=Z_{1}^{2}+\cdots+Z_{n}^{2}$
\end_inset

 where 
\begin_inset Formula $Z_{1},Z_{2},\dots,Z_{n}$
\end_inset

 are i.i.d 
\begin_inset Formula $N(0,1)$
\end_inset

.
 Then 
\begin_inset Formula $V$
\end_inset

 is said to have the 
\series bold
Chi-Square distribution
\series default
 with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom, denoted as 
\begin_inset Formula $V\sim\chi^{2}(n)$
\end_inset

.
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\chi^{2}$
\end_inset

 distribution is a special case of the Gamma distribution that will be introduce
d in the following sections.
 In fact, 
\begin_inset Formula $\chi^{2}(1)$
\end_inset

 is 
\begin_inset Formula $\textrm{Gamma}(\frac{1}{2},\frac{1}{2})$
\end_inset

; 
\begin_inset Formula $\chi^{2}(n)$
\end_inset

 is 
\begin_inset Formula $\textrm{Gamma}(\frac{n}{2},\frac{1}{2})$
\end_inset

.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula 
\[
T=\frac{Z}{\sqrt{V/n}}
\]

\end_inset

where 
\begin_inset Formula $Z\sim N(0,1)$
\end_inset

, 
\begin_inset Formula $V\sim\chi^{2}(n)$
\end_inset

, and 
\begin_inset Formula $Z$
\end_inset

 is independent of 
\begin_inset Formula $V$
\end_inset

.
 Then 
\begin_inset Formula $T$
\end_inset

 is said to have the 
\series bold
Student-
\begin_inset Formula $t$
\end_inset

 distribution
\series default
 with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom, denoted as 
\begin_inset Formula $T\sim t_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
Student-
\begin_inset Formula $t$
\end_inset

 distribution is symmetric and has the similar bell-shaped curve of the
 Normal distribution but with heavier tail.
 As 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $t_{n}$
\end_inset

 distribution approaches the standard Normal distribution.
 
\end_layout

\begin_layout Section
Exponential distribution
\end_layout

\begin_layout Standard
Imagine you are a shop owner that waits for your next customer.
 The customers arrive randomly, with no preference for any specific time
 interval.
 What interests us is the waiting time until the next customer arrives.
 Since the customers arrives randomly, the likelihood of it coming in the
 next moment is the same whether you’ve been waiting for one minute or ten
 minutes.
 In other words, the waiting time between events that occur randomly and
 independently over time.
 The exponential distribution is the mathematical model that best describes
 such scenarios.
\end_layout

\begin_layout Standard
To model the waiting time, let 
\begin_inset Formula $X$
\end_inset

 represent the time until the next event.
 A crucial feature of this process is that the waiting time has no “memory.”
 That is, no matter how long you’ve already waited, the probability of waiting
 an additional amount of time is the same.
 Mathematically, this memoryless property is expressed as:
\begin_inset Formula 
\[
P(X\geq s+t\mid X\geq s)=P(X\geq t),\quad\text{for all }s,t\geq0.
\]

\end_inset

The conditional probability can be rewritten using the definition of conditional
 probabilities:
\begin_inset Formula 
\[
P(X\geq s+t\mid X\geq s)=\frac{P(X\geq s+t)}{P(X\geq s)}.
\]

\end_inset

Thus, the memoryless property implies:
\begin_inset Formula 
\[
\frac{P(X\geq s+t)}{P(X\geq s)}=P(X\geq t).
\]

\end_inset

Let the survival function 
\begin_inset Formula $S(x)$
\end_inset

 represent 
\begin_inset Formula $P(X\geq x)$
\end_inset

 .
 Substituting 
\begin_inset Formula $S(x)$
\end_inset

 into the equation gives:
\begin_inset Formula 
\[
\frac{S(s+t)}{S(s)}=S(t).
\]

\end_inset

This reminds us of the exponential function.
 In fact, the only continuous and non-negative solution to this equation
 is:
\begin_inset Formula 
\[
S(x)=e^{-\lambda x},\quad\lambda>0,
\]

\end_inset

where 
\begin_inset Formula $\lambda$
\end_inset

 is a positive constant.
 This solution represents the probability that the waiting time exceeds
 
\begin_inset Formula $x$
\end_inset

 , and 
\begin_inset Formula $\lambda$
\end_inset

 determines how quickly the probability decreases over time.
 
\end_layout

\begin_layout Standard
The CDF of 
\begin_inset Formula $X$
\end_inset

 is exactly the opposite of 
\begin_inset Formula $S(x)$
\end_inset

:
\begin_inset Formula 
\[
F(x)=1-S(x)=1-e^{-\lambda x}.
\]

\end_inset

Take derivative to get the PDF: 
\begin_inset Formula 
\[
f(x)=F'(x)=\lambda e^{-\lambda x}.
\]

\end_inset


\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $X$
\end_inset

 is said to have the 
\series bold
Exponential distribution
\series default
 with parameter 
\begin_inset Formula $\lambda$
\end_inset

 if its PDF is 
\begin_inset Formula 
\[
f(x)=\lambda e^{-\lambda x},\qquad x>0.
\]

\end_inset


\end_layout

\begin_layout Definition
We denote this as 
\begin_inset Formula $X\sim\textrm{Expo}(\lambda).$
\end_inset


\begin_inset Formula $\lambda$
\end_inset

 is interpreted as the 
\begin_inset Quotes eld
\end_inset

rate
\begin_inset Quotes erd
\end_inset

, i.e.
 number of events per unit of time.
 
\end_layout

\begin_layout Standard
To compute the expectation and variance, we first standardize the exponential
 distribution.
 Let 
\begin_inset Formula $Y=\lambda X$
\end_inset

, then 
\begin_inset Formula $Y\sim\textrm{Expo}(1)$
\end_inset

, because
\begin_inset Formula 
\[
P(Y\leq y)=P(X\leq y/\lambda)=1-e^{-y}.
\]

\end_inset

It follows that, 
\begin_inset Formula 
\begin{align*}
E(Y) & =\int_{0}^{\infty}ye^{-y}dy=\left[-ye^{-y}\right]_{0}^{\infty}+\int_{0}^{\infty}e^{-y}dy=1;\\
Var(Y) & =E(Y^{2})-(EY)^{2}=\int_{0}^{\infty}y^{2}e^{-y}dy-1=1.
\end{align*}

\end_inset

For 
\begin_inset Formula $X=Y/\lambda$
\end_inset

, we have 
\begin_inset Formula $E(X)=\frac{1}{\lambda}$
\end_inset

, 
\begin_inset Formula $Var(X)=\frac{1}{\lambda^{2}}$
\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Memoryless property
\end_layout

\end_inset

If 
\begin_inset Formula $X$
\end_inset

 has the exponential distribution with parameter 
\begin_inset Formula $\lambda$
\end_inset

, and let 
\begin_inset Formula $t>0$
\end_inset

, 
\begin_inset Formula $h>0$
\end_inset

, then
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
P(X\geq t+h|X\geq t)=P(X\geq h).
\]

\end_inset


\end_layout

\begin_layout Proof
For 
\begin_inset Formula $t>0$
\end_inset

 we have 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
P(X\geq t)=\int_{t}^{\infty}\lambda e^{-\lambda x}dx=e^{-\lambda t}.
\]

\end_inset


\end_layout

\begin_layout Proof
Hence for each 
\begin_inset Formula $t>0$
\end_inset

 and each 
\begin_inset Formula $h>0$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
P(X\geq t+h|X\geq t)=\frac{P(X\geq t+h)}{P(X\geq t)}=\frac{e^{-\lambda(t+h)}}{e^{-\lambda t}}=e^{-\lambda h}=P(X\geq h).
\]

\end_inset


\end_layout

\begin_layout Standard
What are the implications of the memoryless property? If human lifetimes
 were Exponential, then conditional on having survived to the age of 80,
 your remaining lifetime would have the same distribution as that of a newborn
 baby! Clearly, the memoryless property is not an appropriate description
 for human lifetimes.
\end_layout

\begin_layout Standard
The memoryless property is a very special property of the Exponential distributi
on.
 In fact, the Exponential is the only memoryless continuous distribution
 (with support 
\begin_inset Formula $(0,\infty)$
\end_inset

); and Geometric distribution is the only memoryless discrete distribution
 (with support 
\begin_inset Formula $0,1,\dots$
\end_inset

).
\end_layout

\begin_layout Example
We try to model the waiting time at a bus station.
 When any bus arrives, suppose the time until the next bus arrives is an
 Exponential random variable with mean 10 minutes.
 You arrive at the bus stop at a random time, not knowing how long ago the
 previous bus came.
 What is the distribution of your waiting time for the next bus? What is
 the average time that you have to wait? What if you know the previous bus
 left 10 minutes ago, does that change your expected waiting time?
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $X$
\end_inset

 be the waiting time and we know it is an Exponential distribution.
 Since 
\begin_inset Formula $E(X)=1/\lambda=10$
\end_inset

, the parameter 
\begin_inset Formula $\lambda=1/10$
\end_inset

.
 Thus 
\begin_inset Formula $X\sim\textrm{Expo}(0.1)$
\end_inset

.
 By the memoryless property, how much longer the next bus will take to arrive
 is independent of how long ago the previous bus arrived.
 The average time you have to wait is always 10 minutes.
\end_layout

\begin_layout Section
Poisson process 
\end_layout

\begin_layout Standard
Now we point out the connection between the Poisson process and the exponential
 distribution — Let 
\begin_inset Formula $X_{1},X_{2},\dots$
\end_inset

 be a sequence of events randomly occurred over time (random arrivals).
 If the number of events occurred in a given period of time follows a Poisson
 distribution, then the time interval between two events follows an Exponential
 distribution, 
\emph on
vice versa
\emph default
.
 
\end_layout

\begin_layout Standard
Suppose the number of events occurred in an interval 
\begin_inset Formula $t$
\end_inset

 is subject to Poisson distribution: 
\begin_inset Formula $N\sim\textrm{Pois}(\lambda t)$
\end_inset

.
 Let 
\begin_inset Formula $T$
\end_inset

 be the waiting time before any event occurs.
 The waiting time being 
\begin_inset Formula $t$
\end_inset

 is equivalent to 
\begin_inset Formula $N=0$
\end_inset

 for time period 
\begin_inset Formula $t$
\end_inset

:
\begin_inset Formula 
\[
P(T>t)=P(N_{t}=0)=e^{-\lambda t}\frac{(\lambda t)^{0}}{0!}=e^{-\lambda t}
\]

\end_inset

where 
\begin_inset Formula $N_{t}=$
\end_inset

 # emails in 
\begin_inset Formula $[0,t]$
\end_inset

.
 The CDF of 
\begin_inset Formula $T$
\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
F(t)=1-P(T>t)=1-e^{-\lambda t}.
\]

\end_inset


\end_layout

\begin_layout Standard
The PDF of 
\begin_inset Formula $T$
\end_inset

 is 
\begin_inset Formula 
\[
f(t)=F'(t)=\lambda e^{-\lambda t}.
\]

\end_inset

This indicates 
\begin_inset Formula $T\sim Expo(\lambda)$
\end_inset

.
\end_layout

\begin_layout Definition
A sequence of arrivals in continuous time is a 
\series bold
Poisson process
\series default
 with rate 
\begin_inset Formula $\lambda$
\end_inset

 if
\end_layout

\begin_layout Itemize
The number of arrivals in an interval of length 
\begin_inset Formula $t$
\end_inset

 is distributed 
\begin_inset Formula $Pois(\lambda t)$
\end_inset

;
\end_layout

\begin_layout Itemize
The numbers of arrivals in disjoint time intervals are independent.
\end_layout

\begin_layout Standard
Thus, Poisson distribution is used to model the number of random events
 in a period of time.
 Exponential distribution is used to model the time interval between two
 of these events.
 
\end_layout

\begin_layout Standard
When we introduced Poisson distribution in Chapter 3, we have said that
 Poisson distribution is used to model the scenario where the number of
 events is large and the probability of each event occurring is small.
 What is the connection here? The events occur randomly.
 Image we divide the time line into infinitely small interval (e.g.
 milliseconds), then an event either happens in a millisecond or not.
 Thus, we have a large number of Bernoulli trials.
 The total number of events occurred is approximated by a Binomial distribution,
 where 
\begin_inset Formula $n$
\end_inset

 is huge, and 
\begin_inset Formula $p$
\end_inset

 the probability that an event occurs in a particular millisecond is very
 small.
 This is the typical case of Poisson distribution.
 
\end_layout

\begin_layout Example
Suppose the number of calls to a phone number is a Poisson process with
 parameter 
\begin_inset Formula $\lambda$
\end_inset

.
 
\begin_inset Formula $\tau\sim Exp(\mu)$
\end_inset

 is the duration of each call.
 It is reasonable to assume that 
\begin_inset Formula $\tau$
\end_inset

 is independent of the Poisson process.
 What is the probability that the 
\begin_inset Formula $(n+1)$
\end_inset

-th call gets a busy signal, i.e.
 it comes when the user is still responding to the 
\begin_inset Formula $n$
\end_inset

-th call?
\end_layout

\begin_layout Example
Solution: Let 
\begin_inset Formula $T_{n}$
\end_inset

 be the arrival time of the 
\begin_inset Formula $n$
\end_inset

-th customer.
 The probability we want to find is 
\begin_inset Formula 
\[
P(T_{n}+\tau>T_{n+1}|\tau)=P(T_{n+1}-T_{n}<\tau|\tau)=P(X_{n}<\tau|\tau).
\]

\end_inset

As we have discussed, 
\begin_inset Formula $X_{n}$
\end_inset

 follows an Exponential distribution.
 Thus, 
\begin_inset Formula 
\[
P(X_{n}<\tau|\tau)=1-e^{-\lambda\tau}.
\]

\end_inset

To find the unconditional probability, 
\begin_inset Formula 
\begin{align*}
P(X_{n}<\tau) & =\int_{0}^{\infty}P(X_{n}<\tau|\tau)f(\tau)d\tau=\int_{0}^{\infty}(1-e^{-\lambda\tau})\mu e^{-\mu\tau}d\tau\\
 & =1-\mu\int_{0}^{\infty}e^{-(\lambda+\mu)\tau}d\tau=\frac{\lambda}{\lambda+\mu}.
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Gamma distribution
\end_layout

\begin_layout Standard
The Gamma distribution is a continuous distribution on the positive real
 line; it is a generalization of the Exponential distribution.
 While an Exponential RV represents the waiting time for the ﬁrst event
 to occur, we shall see that a Gamma RV represents the total waiting time
 for 
\begin_inset Formula $n$
\end_inset

 events to occur.
\end_layout

\begin_layout Standard
Let's start with a simple case.
 Suppose we want to find out the total waiting until the 2nd event occurred.
 Let 
\begin_inset Formula $Y=X_{1}+X_{2}$
\end_inset

 where 
\begin_inset Formula $X_{1},X_{2}\sim Expo(\lambda)$
\end_inset

 independently.
 If 
\begin_inset Formula $Y$
\end_inset

 is discrete, we have 
\begin_inset Formula $P(Y=y)=\sum_{k=0}^{y}P(X_{1}=k,X_{2}=y-k)$
\end_inset

.
 For continuous 
\begin_inset Formula $y$
\end_inset

, we have 
\begin_inset Formula 
\begin{align*}
f_{Y}(y) & =\int_{0}^{y}f_{X}(x)f_{X}(y-x)dx=\int_{0}^{y}\lambda e^{-\lambda x}\lambda e^{-\lambda(y-x)}dx\\
 & =\int_{0}^{y}\lambda^{2}e^{-\lambda y}dx=\lambda^{2}e^{-\lambda y}y.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If there is a third variable, 
\begin_inset Formula 
\begin{align*}
f_{Z}(z) & =\int_{0}^{z}f_{X}(x)f_{Y}(z-x)dx=\int_{0}^{z}\lambda e^{-\lambda x}\lambda^{2}e^{-\lambda(z-x)}(z-x)dx\\
 & =\lambda^{3}e^{-\lambda z}\int_{0}^{z}(z-x)dx=\lambda^{3}e^{-\lambda z}z^{2}/2.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The general pattern is the Gamma distribution.
\end_layout

\begin_layout Definition
An random variable X is said to have the 
\series bold
Gamma distribution
\series default
 with parameters 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

, 
\begin_inset Formula $a>0$
\end_inset

 and 
\begin_inset Formula $\lambda>0$
\end_inset

, if it has the PDF 
\begin_inset Formula 
\[
f(x)=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x},\quad x>0
\]

\end_inset

We write 
\begin_inset Formula $X\sim\textrm{Gamma}(a,\lambda)$
\end_inset

.
\end_layout

\begin_layout Standard
Verify this is a valid PDF:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{0}^{\infty}\frac{1}{\Gamma(a)}(\lambda x)^{a}e^{-\lambda x}\frac{dx}{x}\overset{u=\lambda x}{=}\frac{1}{\Gamma(a)}\int_{0}^{\infty}u^{a}e^{-u}\frac{du}{u}=\frac{\Gamma(a)}{\Gamma(a)}=1.
\]

\end_inset


\end_layout

\begin_layout Standard
Taking 
\begin_inset Formula $a=1$
\end_inset

, the 
\begin_inset Formula $\textrm{Gamma}(1,\lambda)$
\end_inset

 PDF is 
\begin_inset Formula $f(x)=\lambda e^{-\lambda x}$
\end_inset

, which is the same as 
\begin_inset Formula $\textrm{Expo}(\lambda)$
\end_inset

.
 So Exponential distribution is a special case of Gamma distribution.
 
\end_layout

\begin_layout Standard
Let's find the expectation and variance of the Gamma distribution.
 Let 
\begin_inset Formula $Y\sim\textrm{Gamma}(a,1)$
\end_inset

.
 Recall 
\begin_inset Formula $\Gamma$
\end_inset

 function has the property 
\begin_inset Formula $\Gamma(a+1)=a\Gamma(a)$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(Y)=\int_{0}^{\infty}y\cdot\frac{1}{\Gamma(a)}y^{a-1}e^{-y}dy=\frac{1}{\Gamma(a)}\int_{0}^{\infty}y^{a}e^{-y}dy=\frac{\Gamma(a+1)}{\Gamma(a)}=a.
\]

\end_inset


\end_layout

\begin_layout Standard
Apply LOTUS to evaluate the second moment:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(Y^{2})=\int_{0}^{\infty}y^{2}\cdot\frac{1}{\Gamma(a)}y^{a-1}e^{-y}dy=\frac{1}{\Gamma(a)}\int_{0}^{\infty}y^{a+1}e^{-y}dy=\frac{\Gamma(a+2)}{\Gamma(a)}=(a+1)a.
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, 
\begin_inset Formula 
\[
Var(Y)=(a+1)a-a^{2}=a.
\]

\end_inset


\end_layout

\begin_layout Standard
So for 
\begin_inset Formula $Y\sim\textrm{Gamma}(a,1)$
\end_inset

, 
\begin_inset Formula $E(Y)=Var(Y)=a$
\end_inset

.
 For the general case 
\begin_inset Formula $X\sim\textrm{Gamma}(a,\lambda)$
\end_inset

, we now show that 
\begin_inset Formula $X=\frac{Y}{\lambda}$
\end_inset

.
 Note that
\begin_inset Formula 
\begin{align*}
F_{X}(x)=P(X & \leq x)=P(Y\leq x/\lambda)=F_{Y}(x/\lambda)\\
f_{X}(x)=\frac{dF_{X}}{dx} & =\frac{\partial F_{Y}}{\partial y}\frac{dy}{dx}=f_{Y}(y)\lambda
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Therefore, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f_{X}(x)=\frac{1}{\Gamma(a)}y^{a-1}e^{-y}\lambda=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x}.
\]

\end_inset


\end_layout

\begin_layout Standard
Hence, we have 
\begin_inset Formula $E(X)=\frac{a}{\lambda}$
\end_inset

, 
\begin_inset Formula $Var(X)=\frac{a}{\lambda^{2}}$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X_{1},\dots,X_{n}$
\end_inset

 be independent and identical 
\begin_inset Formula $\textrm{Expo}(\lambda)$
\end_inset

.
 Then 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
X_{1}+\cdots+X_{n}\sim\textrm{Gamma}(n,\lambda).
\]

\end_inset


\end_layout

\begin_layout Proof
Let's prove by showing the MGFs are equivalent.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
M_{X}(t)=E(e^{tX})=\int_{0}^{\infty}e^{tx}\lambda e^{-\lambda x}dx=\frac{\lambda}{\lambda-t}\quad\textrm{for }t<\lambda
\]

\end_inset


\end_layout

\begin_layout Proof
Thus, the MGF of 
\begin_inset Formula $Y=X_{1}+\cdots+X_{n}$
\end_inset

 is 
\begin_inset Formula $M_{Y}(t)=\left(M_{X}(t)\right)^{n}=\left(\frac{\lambda}{\lambda-t}\right)^{n}$
\end_inset

.
 We verify this is the MGF of a Gamma distribution.
 Suppose 
\begin_inset Formula $Y\sim\textrm{Gamma}(n,\lambda)$
\end_inset

, it has MGF:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
M_{Y}(t) & =E(e^{tY})=\int_{0}^{\infty}e^{ty}\frac{\lambda^{n}}{\Gamma(a)}y^{n-1}e^{-\lambda y}dy\\
 & =\frac{\lambda^{n}}{(\lambda-t)^{n}}\int_{0}^{\infty}\frac{1}{\Gamma(a)}((\lambda-t)y)^{n-1}e^{-(\lambda-t)y}(\lambda-t)dy\\
 & =\frac{\lambda^{n}}{(\lambda-t)^{n}}\int_{0}^{\infty}\frac{1}{\Gamma(a)}u^{n-1}e^{-u}du\qquad u=(\lambda-t)y\\
 & =\left(\frac{\lambda}{\lambda-t}\right)^{n}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, if 
\begin_inset Formula $X_{i}$
\end_inset

 represents the 
\emph on
i.i.d
\emph default
 inter-arrival time.
 
\begin_inset Formula $Y$
\end_inset

 has the interpretation of the arrival time until the 
\begin_inset Formula $n$
\end_inset

-th event.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Y=\sum_{i=1}^{n}X_{i}=\sum_{i=1}^{n}\textrm{(time of the i-th arrival)}\sim\textrm{Gamma}(n,\lambda).
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Service time in a queue
\end_layout

\end_inset

Customer 
\begin_inset Formula $i$
\end_inset

 must wait time 
\begin_inset Formula $X_{i}$
\end_inset

 for service once reaching the head of the queue.
 The average service rate is 1 customer per 10 minutes.
 Assume the service for each customer is independent.
 If you are the 5th in the queue.
 What is the expected waiting to be served? 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 
\begin_inset Formula $X_{i}\sim\textrm{Expo}(0.1)$
\end_inset

.
 Then 
\begin_inset Formula $E(X_{i})=10$
\end_inset

.
 Let Y be the time until you are served.
 Then 
\begin_inset Formula $Y\sim\textrm{Gamma}(5,0.1)$
\end_inset

.
 Thus, 
\begin_inset Formula $E(Y)=\frac{5}{0.1}=50$
\end_inset

 minutes.
 The probabilities of some selected values:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(Y\leq t)=\begin{cases}
5\% & t=20\\
18\% & t=30\\
71\% & t=60
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Section
Beta distribution*
\end_layout

\begin_layout Standard
The Beta distribution is a continuous distribution on the interval 
\begin_inset Formula $(0,1)$
\end_inset

.
 It is a generalization of the 
\begin_inset Formula $\textrm{Unif}(0,1)$
\end_inset

 distribution, allowing the PDF to be non-constant on 
\begin_inset Formula $(0,1)$
\end_inset

.
\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $X$
\end_inset

 is said to have the 
\series bold
Beta distribution
\series default
 with parameters 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

, 
\begin_inset Formula $a>0$
\end_inset

 and 
\begin_inset Formula $b>0$
\end_inset

, if its PDF is 
\begin_inset Formula 
\[
f(x)=\frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},\quad0<x<1
\]

\end_inset

where the constant 
\begin_inset Formula $\beta(a,b)$
\end_inset

 is chosen to make the PDF integrate to 
\begin_inset Formula $1$
\end_inset

.
 We write this as 
\begin_inset Formula $X\sim\textrm{Beta}(a,b)$
\end_inset

.
\end_layout

\begin_layout Standard
The Beta distribution takes different shapes for different 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 values.
 Here are some general patterns:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $a=b=1$
\end_inset

, the 
\begin_inset Formula $\textrm{Beta}(1,1)$
\end_inset

 PDF is constant on 
\begin_inset Formula $(0,1)$
\end_inset

, equivalent to 
\begin_inset Formula $\textrm{Unif}(0,1)$
\end_inset

.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $a<1$
\end_inset

 and 
\begin_inset Formula $b<1$
\end_inset

, the PDF is U-shaped and opens upward.
 If 
\begin_inset Formula $a>1$
\end_inset

 and 
\begin_inset Formula $b>1$
\end_inset

, the PDF opens downward.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $a=b$
\end_inset

, the PDF is symmetric about 
\begin_inset Formula $1/2$
\end_inset

.
 If 
\begin_inset Formula $a>b$
\end_inset

, the PDF favors values larger than 
\begin_inset Formula $1/2$
\end_inset

.
 If 
\begin_inset Formula $a<b$
\end_inset

, the PDF favors values smaller than 
\begin_inset Formula $1/2$
\end_inset

.
\end_layout

\begin_layout Standard
To make the PDF integrates to 1, the constant 
\begin_inset Formula $\beta(a,b)$
\end_inset

 has to satisfy
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta(a,b)=\int_{0}^{1}x^{a-1}(1-x)^{b-1}dx.
\]

\end_inset


\end_layout

\begin_layout Standard
We now try to find this integral:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\beta(a,b) & =\int_{0}^{1}\underbrace{x^{a-1}}_{f}\underbrace{(1-x)^{b-1}}_{g'}dx\\
 & =\left[-x^{a-1}\frac{(1-x)^{b}}{b}\right]_{0}^{1}+\int_{0}^{1}(a-1)x^{a-2}\frac{(1-x)^{b}}{b}dx\\
 & =\frac{a-1}{b}\beta(a-1,b+1)\\
 & =\frac{a-1}{b}\cdot\frac{a-2}{b+1}\beta(a-2,b+2)\\
 & =\frac{a-1}{b}\cdot\frac{a-2}{b+1}\cdot\frac{a-3}{b+2}\beta(a-3,b+3)\\
 & \vdots\\
 & =\frac{(a-1)!}{b(b+1)(b+2)\cdots(b+a-2)}\underbrace{\beta(1,a+b-1)}_{\frac{1}{a+b-1}}\\
 & =\frac{(a-1)!}{\frac{(b+a-2)!}{(b-1)!}}\cdot\frac{1}{a+b-1}\\
 & =\frac{(a-1)!(b-1)!}{(a+b-1)!}\\
 & =\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $𝑋_{1},…,𝑋_{n}$
\end_inset

 be independent random variables with the uniform distribution on the interval
 
\begin_inset Formula $[0,1]$
\end_inset

.
 Find the distribution of 
\begin_inset Formula $𝑌=\max(𝑋_{1},…,𝑋_{n})$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Let's find the CDF of 
\begin_inset Formula $Y$
\end_inset

: 
\begin_inset Formula 
\begin{align*}
P(Y\leq y) & =P(X_{1}\leq y\cap X_{2}\leq y\cap\cdots\cap X_{n}\leq y)\\
 & \overset{iid}{=}P(X_{1}\leq y)P(X_{2}\leq y)\cdots P(X_{n}\leq y)\\
 & =y^{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
for 
\begin_inset Formula $𝑦\in[0,1]$
\end_inset

.
 Hence, 
\begin_inset Formula 
\[
F_{Y}(y)=P(Y\leq y)=\begin{cases}
0 & y<0\\
y^{n} & 0\leq y\leq1\\
1 & y>1
\end{cases}
\]

\end_inset

The PDF of 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula 
\[
f_{Y}(y)=F'_{Y}(y)=\begin{cases}
ny^{n-1} & 0\leq y\leq1\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $Y\sim Beta(n,1)$
\end_inset

.
\end_layout

\begin_layout Standard
Beta distributions are often used as 
\emph on
priors
\emph default
 for parameters in Bayesian inference.
 We do not cover Bayesian inference in this book.
 Nonetheless we illustrate this with an example.
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Beta-Binomial conjugacy
\end_layout

\end_inset

We have a coin that lands Heads with probability 
\begin_inset Formula $p$
\end_inset

, but we don’t know what 
\begin_inset Formula $p$
\end_inset

 is.
 Our goal is to infer the value of 
\begin_inset Formula $p$
\end_inset

 after observing the outcomes of 
\begin_inset Formula $n$
\end_inset

 tosses of the coin.
 The larger that 
\begin_inset Formula $n$
\end_inset

 is, the more accurately we should be able to estimate 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
We model the unknown parameter 
\begin_inset Formula $p$
\end_inset

 as a Beta distribution, 
\begin_inset Formula $p\sim\textrm{Beta}(a,b)$
\end_inset

.
 Since we are completely ignorant about this 
\begin_inset Formula $p$
\end_inset

, we can also model it as the uniform distribution.
 But we will see that using the Beta distribution is even simpler than the
 uniform distribution.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of heads in 
\begin_inset Formula $n$
\end_inset

 tosses of the coin.
 Then
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
X|p\sim\textrm{Bin}(n,p)
\]

\end_inset


\end_layout

\begin_layout Example
Apply the Bayes' rule to inverse the conditioning:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(p|X=k) & =\frac{P(X=k|p)f(p)}{P(X=k)}\\
 & =\frac{\binom{n}{k}p^{k}(1-p)^{n-k}\cdot\frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{\int_{0}^{1}\binom{n}{k}p^{k}(1-p)^{n-k}f(p)dp}\\
 & \propto p^{a+k-1}(1-p)^{b+n-k-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This the kernel of 
\begin_inset Formula $\textrm{Beta}(a+k,b+n-k)$
\end_inset

.
 The rest is just a normalizing constant.
 Therefore,
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
p|X=k\sim\textrm{Beta}(a+k,b+n-k).
\]

\end_inset


\end_layout

\begin_layout Example
The 
\emph on
posterior
\emph default
 distribution of 
\begin_inset Formula $p$
\end_inset

 after observing 
\begin_inset Formula $X=k$
\end_inset

 is still a Beta distribution! This is a special relationship between the
 Beta and Binomial distributions called 
\emph on
conjugacy
\emph default
: if we have a Beta prior distribution on 
\begin_inset Formula $p$
\end_inset

 and data that are conditionally Binomial given 
\begin_inset Formula $p$
\end_inset

, then when going from prior to posterior, we don’t leave the family of
 Beta distributions.
 We say that the 
\emph on
Beta is the conjugate prior of the Binomial
\emph default
.
\end_layout

\begin_layout Chapter
Joint Distributions
\end_layout

\begin_layout Section
Joint, marginal and conditional distributions
\end_layout

\begin_layout Standard
A joint distribution is a statistical concept used to describe the likelihood
 of two or more random variables occurring together.
 When we talk about joint distribution, we are considering the probability
 of different values of these variables happening simultaneously, rather
 than in isolation.
 Suppose we toss a coin and roll a die.
 Joint probability represents the probability that the two events happening
 simultaneously, e.g.
 
\begin_inset Formula $P(\textrm{Coin}=H,\textrm{Die}=6)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Given the joint distribution, we are interested in: (i) the distribution
 of multi-variables simultaneously (joint probability); (ii) the distribution
 of one variable ignoring other variables (marginal probability); (iii)
 the distribution of one variable given the value of other variables (conditiona
l probability).
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float table
placement H
wide false
sideways true
status open

\begin_layout Plain Layout
\paragraph_spacing double
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="12" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Discrete
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Continuous
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Joint CDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F_{XY}(x,y)=P(X\leq x,Y\leq y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F_{XY}(x,y)=P(X\leq x,Y\leq y)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Joint PMF/PDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $p_{XY}(x,y)=P(X=x,Y=y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{XY}(x,y)=\frac{\partial^{2}}{\partial x\partial y}F_{XY}(x,y)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sum_{x}\sum_{y}P(X=x,Y=y)=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f_{XY}(x,y)dxdy=1$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Marginal PMF/PDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x)=\sum_{y}P(X=x,Y=y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{X}(x)=\int_{-\infty}^{+\infty}f_{XY}(x,y)dy$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Conditional PMF/PDF
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x|Y=y)=\frac{P(X=x,Y=y)}{P(Y=y)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{X|Y}(x|y)=\frac{f_{XY}(x,y)}{f_{Y}(y)}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Independence
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x,Y=y)=P(X=x)P(Y=y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{XY}(x,y)=f_{X}(x)f_{Y}(y)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x|Y=y)=P(X=x)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{X|Y}(x|y)=f_{X}(x)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F_{XY}(x,y)=F_{X}(x)F_{Y}(y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $F_{XY}(x,y)=F_{X}(x)F_{Y}(y)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bayes' rule
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(Y=y|X=x)=\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{Y|X}(y|x)=\frac{f_{X|Y}(x|y)f_{Y}(y)}{f_{X}(x)}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LOTP
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P(X=x)=\sum_{y}P(X=x|Y=y)P(Y=y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f_{X}(x)=\int_{-\infty}^{+\infty}f_{X|Y}(x|y)f_{Y}(y)dy$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LOTUS
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E(g(X,Y))=\sum_{x}\sum_{y}g(x,y)P(X=x)P(y=y)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $E(g(X,Y))=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x,y)f_{XY}(x,y)dxdy$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Joint, marginal and conditional distributions
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X$
\end_inset

 be an indicator of an individual being a current smoker.
 Let 
\begin_inset Formula $Y$
\end_inset

 be the indicator of his developing lung cancer at some point in his life.
 The joint PMF of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 is as specified in the table below.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Y=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Y=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Total
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X=0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.72
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.75
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.08
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.92
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The marginal PMF for having lung cancer is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{aligned}P(Y=1)= & P(Y=1,X=0)+P(Y=1,X=1)=0.08,\\
P(Y=0)= & P(Y=0,X=0)+P(Y=0,X=1)=0.92.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
The conditional PMF of having lung cancer conditioned on being a smoker
 is 
\begin_inset Formula 
\[
P(Y=1|X=1)=\frac{P(X=x,Y=y)}{P(X=x)}=\frac{0.05}{0.25}=\frac{1}{5}.
\]

\end_inset

In this example, 
\begin_inset Formula $X,Y$
\end_inset

 are not independent, because
\begin_inset Formula 
\[
P(X=1,Y=1)\neq P(X=1)P(Y=1).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are uniformly distributed on a disk 
\begin_inset Formula $\{(x,y):x^{2}+y^{2}\leq1\}$
\end_inset

.
 Find the joint PDF, marginal distributions and conditional distributions.
 Are 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 independent? 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 The area of the disk is 
\begin_inset Formula $\pi$
\end_inset

, therefore 
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
f(x,y)=\begin{cases}
\frac{1}{\pi} & x^{2}+y^{2}\leq1\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Example
The marginal distributions are
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f_{X}(x) & =\int_{-\sqrt{1-x^{2}}}^{\sqrt{1+x^{2}}}\frac{1}{\pi}dy=\frac{2}{\pi}\sqrt{1-x^{2}},\qquad-1\leq x\leq1\\
f_{Y}(y) & =\int_{-\sqrt{1-y^{2}}}^{\sqrt{1+y^{2}}}\frac{1}{\pi}dx=\frac{2}{\pi}\sqrt{1-y^{2}},\qquad-1\leq y\leq1
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The conditional distributions are
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
f_{Y|X}(y|x)=\frac{f(x,y)}{f_{X}(x)}=\frac{\frac{1}{\pi}}{\frac{2}{\pi}\sqrt{1-x^{2}}}=\frac{1}{2\sqrt{1-x^{2}}}
\]

\end_inset


\end_layout

\begin_layout Example
Therefore, 
\begin_inset Formula $Y|X\sim\textrm{Unif}(-\sqrt{1-x^{2}},\sqrt{1-x^{2}})$
\end_inset

.
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $f(x,y)\neq f_{X}(x)f_{Y}(y)$
\end_inset

, 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are not independent.
 This is because knowing the value of 
\begin_inset Formula $X$
\end_inset

 constrains the value of 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X,Y\overset{iid}{\sim}Unif(0,1)$
\end_inset

.
 Find the probability 
\begin_inset Formula $P\left(Y\leq\frac{1}{2X}\right)$
\end_inset

.
 
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: The joint distribution is 
\begin_inset Formula 
\[
f(x,y)=\begin{cases}
1 & 0\leq x\leq1,0\leq y\leq1\\
0 & \textrm{otherwise}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P\left(Y\leq\frac{1}{2X}\right)=\int_{0}^{1/2}\int_{0}^{1}1dydx+\int_{1/2}^{1}\int_{0}^{1/2x}1dydx=\frac{1}{2}+\int_{1/2}^{1}\frac{1}{2x}dx=\frac{1}{2}+\ln\sqrt{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
For 
\begin_inset Formula $X,Y\overset{iid}{\sim}\textrm{Unif}(0,1)$
\end_inset

, find 
\begin_inset Formula $E(|X-Y|)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
Apply 2D LOTUS:
\emph on

\begin_inset Formula 
\[
\begin{aligned}E(|X-Y|)= & \int_{0}^{1}\int_{0}^{1}|x-y|dxdy\\
= & \int_{0}^{1}\int_{y}^{1}(x-y)dxdy+\int_{0}^{1}\int_{0}^{y}(y-x)dxdy\\
= & 2\int_{0}^{1}\int_{y}^{1}(x-y)dxdy\\
= & \frac{1}{3}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula $X,Y\overset{iid}{\sim}N(0,1)$
\end_inset

, find 
\begin_inset Formula $E(|X-Y|)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Since the sum or difference of independent Normals is Normal, 
\begin_inset Formula $X-Y\sim N(0,2)$
\end_inset

.
 Let 
\begin_inset Formula $Z=X-Y$
\end_inset

.
 Then 
\begin_inset Formula $Z\sim N(0,1)$
\end_inset

, and 
\begin_inset Formula $E(|X-Y|)=\sqrt{2}E(|Z|)$
\end_inset

.
 Apply LOTUS, 
\begin_inset Formula 
\[
E(|Z|)=\int_{-\infty}^{\infty}|z|\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}\,dz=2\int_{0}^{\infty}z\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}\,dz=\sqrt{\frac{2}{\pi}},
\]

\end_inset

Therefore, 
\begin_inset Formula $\mathbb{E}(|X-Y|)=\frac{2}{\sqrt{\pi}}.$
\end_inset


\end_layout

\begin_layout Section
Joint normal distribution
\end_layout

\begin_layout Definition
\begin_inset Formula $(X,Y)$
\end_inset

 is said to have a 
\series bold
Bivariate Normal 
\series default
distribution if the joint PDF satisfies 
\begin_inset Formula 
\[
f(x,y)=\frac{1}{2\pi\sqrt{1-\rho^{2}}}\exp\left(-\frac{1}{2(1-\rho^{2})}(x^{2}+y^{2}-2\rho xy)\right)
\]

\end_inset

where 
\begin_inset Formula $\rho\in(-1,1)$
\end_inset

 is the correlation between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 
\end_layout

\begin_layout Standard
A 
\series bold
Multivariate Normal (MVN)
\series default
 is fully speciﬁed by knowing the mean of each component, the variance of
 each component, and the covariance or correlation between any two components.
 In other words, the parameters of an MVN random vector 
\begin_inset Formula $(X_{1},...,X_{k})$
\end_inset

 are as follows:
\end_layout

\begin_layout Itemize
the mean vector 
\begin_inset Formula $(\mu_{1},...,\mu_{k})$
\end_inset

, where 
\begin_inset Formula $E(X_{j})=\mu_{j}$
\end_inset

;
\end_layout

\begin_layout Itemize
the covariance matrix 
\begin_inset Formula $Cov(X_{i},X_{j})$
\end_inset

 for 
\begin_inset Formula $1\leq i,j\leq k$
\end_inset

.
\end_layout

\begin_layout Standard

\bar under
If 
\begin_inset Formula $(X_{1},...,X_{k})$
\end_inset

 is MVN, then the marginal distribution of every 
\begin_inset Formula $X_{j}$
\end_inset

 is Normal.
 However, the converse is false: it is possible to have Normally distributed
 
\begin_inset Formula $X_{1},...,X_{k}$
\end_inset

 such that 
\begin_inset Formula $(X_{1},...,X_{k})$
\end_inset

 is not Multivariate Normal.
\end_layout

\begin_layout Theorem
A random vector 
\begin_inset Formula $(X_{1},...,X_{k})$
\end_inset

 is Multivariate Normal if every linear combination of the 
\begin_inset Formula $X_{j}$
\end_inset

 has a Normal distribution.
 That is, we require 
\begin_inset Formula $t_{1}X_{1}+···+t_{k}X_{k}$
\end_inset

 to have a Normal distribution for any choice of constants 
\begin_inset Formula $t_{1},...,t_{k}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
Within an MVN random vector, uncorrelated implies independent.
 In particular, if 
\begin_inset Formula $(X,Y)$
\end_inset

 is Bivariate Normal and 
\begin_inset Formula $Corr(X,Y)=0$
\end_inset

, then X and Y are independent.
\end_layout

\begin_layout Standard

\bar under
This is a special property of MVN random variables.
 In general, uncorrelated does not imply independent.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $(X,Y)$
\end_inset

 is Bivariate Normal, then the conditional expectation satisfies 
\begin_inset Formula 
\[
E(Y|X)=E(Y)+\frac{Cov(X,Y)}{Var(X)}(X-E(X)).
\]

\end_inset


\end_layout

\begin_layout Standard
This is also a special property of MVN —
\begin_inset Formula $E(Y|X)$
\end_inset

 is a linear function of 
\begin_inset Formula $X$
\end_inset

.
 This is not the case in general.
\end_layout

\begin_layout Section
Conditional expectation
\end_layout

\begin_layout Theorem
For any random variable 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, 
\begin_inset Formula 
\[
E(E(Y|X))=E(Y).
\]

\end_inset

This is known as the 
\series bold
law of iterated expectation
\series default
.
\end_layout

\begin_layout Proof

\bar under
Note that 
\begin_inset Formula $E(Y|X)=g(X)$
\end_inset

 is a function of 
\begin_inset Formula $X$
\end_inset


\bar default
.
 Apply LOTUS:
\begin_inset Formula 
\begin{align*}
E(E(Y|X)) & =\int g(x)f(x)dx\\
 & =\int\left(\int yf(y|x)dy\right)f(x)dx\\
 & =\int\int yf(y|x)f(x)dydx\\
 & =\int y\int f(y,x)dx\,dy\\
 & =\int_{-\infty}^{\infty}yf(y)dy\\
 & =E(Y).
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
For any random variable 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, and any function 
\begin_inset Formula $g$
\end_inset

,
\begin_inset Formula 
\[
E(g(X)Y|X)=g(X)E(Y|X).
\]

\end_inset


\end_layout

\begin_layout Proof
For any specific value of 
\begin_inset Formula $X=x$
\end_inset

, 
\begin_inset Formula $g(x)$
\end_inset

 is a constant.
 Thus, 
\begin_inset Formula $E(g(x)Y|X=x)=g(x)E(Y|X=x)$
\end_inset

.
 This is true for all values of 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
PG exam
\end_layout

\end_inset

Suppose 
\begin_inset Formula $X\sim\text{Unif}(0,1)$
\end_inset

, and 
\begin_inset Formula $Y|X\sim N(X,X^{2})$
\end_inset

, meaning that for a given 
\begin_inset Formula $X=x$
\end_inset

, 
\begin_inset Formula $Y$
\end_inset

 is normally distributed with mean 
\begin_inset Formula $x$
\end_inset

 and variance 
\begin_inset Formula $x^{2}.$
\end_inset

 Find 
\begin_inset Formula $E(Y)$
\end_inset

, 
\begin_inset Formula $Var(Y)$
\end_inset

 and 
\begin_inset Formula $Cov(X,Y)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
:
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $Y|X\sim N(X,X^{2})$
\end_inset

, we know 
\begin_inset Formula $E(Y|X)=X$
\end_inset

.
 By the law of iterated expectation, 
\begin_inset Formula 
\[
E(Y)=E(E(Y|X))=E(X)=\frac{1}{2}.
\]

\end_inset

For the variance, 
\begin_inset Formula 
\begin{align*}
Var(Y) & =E(Y^{2})-(E(Y))^{2}=E(E(Y^{2}|X))-\frac{1}{4}.
\end{align*}

\end_inset

Since 
\begin_inset Formula 
\[
Var(Y|X)=E(Y^{2}|X)-E^{2}(Y|X)=E(Y^{2}|X)-X^{2}=X^{2},
\]

\end_inset

we have 
\begin_inset Formula $E(Y^{2}|X)=2X^{2}$
\end_inset

.
 Meanwhile, 
\begin_inset Formula $E(X^{2})=\int_{0}^{1}x^{2}\cdot1dx=\frac{1}{3}$
\end_inset

.
 Therefore, 
\begin_inset Formula 
\[
Var(Y)=\frac{2}{3}-\frac{1}{4}=\frac{5}{12}.
\]

\end_inset

For the covariance, 
\begin_inset Formula 
\[
E(XY)=E(E(XY|X))=E(XE(Y|X))=E(X^{2})=\frac{1}{3},
\]

\end_inset


\begin_inset Formula 
\[
Cov(X,Y)=E(XY)-E(X)E(Y)=\frac{1}{3}-\frac{1}{4}=\frac{1}{12}.
\]

\end_inset


\end_layout

\begin_layout Theorem
Conditional expectation 
\begin_inset Formula $E(Y|X)$
\end_inset

 is the best predictor for 
\begin_inset Formula $Y$
\end_inset

 using 
\begin_inset Formula $X$
\end_inset

 (minimized the square loss function).
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $g(X)$
\end_inset

 be a predictor for 
\begin_inset Formula $Y$
\end_inset

 using 
\begin_inset Formula $X$
\end_inset

.
 We want to find the 
\begin_inset Formula $g$
\end_inset

 such that minimizes 
\begin_inset Formula $E(Y-g(X))^{2}$
\end_inset

.
\begin_inset Formula 
\begin{align*}
E(Y-g(X))^{2} & =E(Y-E(Y|X)+E(Y|X)-g(X))^{2}\\
 & =E(Y-E(Y|X))^{2}+2\underbrace{E(Y-E(Y|X)}_{E(Y)=E(E(Y|X))}((E(Y|X)-g(X))+E(E(Y|X)-g(X))^{2}\\
 & =E(Y-E(Y|X))^{2}+E(E(Y|X)-g(X))^{2}\\
 & \geq E(Y-E(Y|X))^{2}.
\end{align*}

\end_inset

Therefore, 
\begin_inset Formula $E(Y-g(X))^{2}$
\end_inset

 is minimized when 
\begin_inset Formula $g(X)=E(Y|X)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Linear conditional expectation model
\end_layout

\begin_layout Definition
An extremely widely used method for data analysis in statistics is linear
 regression.
 In its most basic form, we want to predict the mean of 
\begin_inset Formula $Y$
\end_inset

 using a single explanatory variable 
\begin_inset Formula $X$
\end_inset

.
 
\series bold
A linear conditional expectation model
\series default
 assumes that 
\begin_inset Formula $E(Y|X)$
\end_inset

 is linear in 
\begin_inset Formula $X$
\end_inset

: 
\begin_inset Formula 
\[
E(Y|X)=a+bX,
\]

\end_inset

or equivalently, 
\begin_inset Formula 
\[
Y=a+bX+\epsilon,
\]

\end_inset

with 
\begin_inset Formula $E(\epsilon|X)=0$
\end_inset

.
 The intercept and the slope is given by 
\begin_inset Formula 
\[
b=\frac{Cov(X,Y)}{Var(X)},a=E(Y)-bE(X).
\]

\end_inset


\end_layout

\begin_layout Standard
We first show the equivalence of the two expressions of the model.
 Let 
\begin_inset Formula $Y=a+bX+\epsilon$
\end_inset

, with 
\begin_inset Formula $E(\epsilon|X)=0$
\end_inset

.
 Then by linearity,
\begin_inset Formula 
\[
E(Y|X)=E(a|X)+E(bX|X)+E(\epsilon|X)=a+bX.
\]

\end_inset

Conversely, suppose that 
\begin_inset Formula $E(Y|X)=a+bX$
\end_inset

, and define
\begin_inset Formula 
\[
\epsilon=Y-(a+bX).
\]

\end_inset

Then 
\begin_inset Formula $Y=a+bX+\epsilon$
\end_inset

, with
\begin_inset Formula 
\[
E(\epsilon|X)=E(Y|X)-E(a+bX|X)=E(Y|X)-(a+bX)=0.
\]

\end_inset

To derive the expression for 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

, take covariance between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

,
\begin_inset Formula 
\begin{align*}
Cov(X,Y) & =Cov(X,a+bX+\epsilon)\\
 & =Cov(X,a)+bCov(X,X)+Cov(X,\epsilon)\\
 & =bVar(X)+Cov(X,\epsilon)
\end{align*}

\end_inset

Note that 
\begin_inset Formula $Cov(X,\epsilon)=0$
\end_inset

 because 
\begin_inset Formula 
\begin{align*}
Cov(X,\epsilon) & =E(X\epsilon)-E(X)E(\epsilon)\\
 & =E(E(X\epsilon|X))-E(X)E(E(\epsilon|X))\\
 & =E(XE(\epsilon|X))-E(X)E(E(\epsilon|X))\\
 & =0
\end{align*}

\end_inset

Therefore, 
\begin_inset Formula 
\[
Cov(X,Y)=bVar(X)
\]

\end_inset

Thus, 
\begin_inset Formula 
\begin{align*}
b & =\frac{Cov(X,Y)}{Var(X)},\\
a & =E(Y)-bE(X)=E(Y)-\frac{Cov(X,Y)}{Var(X)}E(X).
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Change of variables
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 be a continuous r.v.
 with PDF 
\begin_inset Formula $f_{X}$
\end_inset

, and let 
\begin_inset Formula $Y=g(X)$
\end_inset

, where 
\begin_inset Formula $g$
\end_inset

 is differentiable and 
\bar under
strictly increasing
\bar default
 (or 
\bar under
strictly decreasing
\bar default
).
 Then the PDF of 
\begin_inset Formula $Y$
\end_inset

 is given by
\begin_inset Formula 
\[
f_{Y}(y)=f_{X}(x)\left|\frac{dx}{dy}\right|,
\]

\end_inset

where 
\begin_inset Formula $x=g^{-1}(y)$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $g$
\end_inset

 be strictly increasing.
 The CDF of 
\begin_inset Formula $Y$
\end_inset

 is
\begin_inset Formula 
\[
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_{X}(g^{-1}(y))=F_{X}(x)
\]

\end_inset

By the chain rule, the PDF of 
\begin_inset Formula $Y$
\end_inset

 is
\begin_inset Formula 
\[
f_{Y}(y)=f_{X}(x)\frac{dx}{dy}.
\]

\end_inset

If 
\begin_inset Formula $g$
\end_inset

 is strictly decreasing, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula 
\[
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y)=P(X\geq g^{-1}(y))=1-F_{X}(g^{-1}(y))=1-F_{X}(x)
\]

\end_inset

Then the PDF of 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula 
\[
f_{Y}(y)=-f_{X}(x)\frac{dx}{dy}.
\]

\end_inset

But in this case, 
\begin_inset Formula $dx/dy<0$
\end_inset

.
 So taking absolute value covers both cases.
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Log-Normal PDF
\end_layout

\end_inset

 Let 
\begin_inset Formula $X\sim N(0,1)$
\end_inset

, 
\begin_inset Formula $Y=e^{X}$
\end_inset

.
 Then the distribution of 
\begin_inset Formula $Y$
\end_inset

 is called the 
\series bold
Log-Normal distribution
\series default
.
 Find the PDF of 
\begin_inset Formula $Y$
\end_inset

.
 
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $g(x)=e^{x}$
\end_inset

 is strictly increasing.
 Let 
\begin_inset Formula $y=e^{x}$
\end_inset

, so 
\begin_inset Formula $x=\log y$
\end_inset

 and 
\begin_inset Formula $dy/dx=e^{x}$
\end_inset

.
 Then
\begin_inset Formula 
\[
f_{Y}(y)=f_{X}(x)\left|\frac{dx}{dy}\right|=\varphi(x)\frac{1}{e^{x}}=\varphi(\log y)\frac{1}{y},\quad y>0.
\]

\end_inset

Note that after applying the change of variables formula, we write everything
 on the right-hand side in terms of 
\begin_inset Formula $y$
\end_inset

, and we specify the support of the distribution.
 To determine the support, we just observe that as 
\begin_inset Formula $x$
\end_inset

 ranges from 
\begin_inset Formula $-\infty$
\end_inset

 to
\begin_inset Formula $\infty$
\end_inset

, 
\begin_inset Formula $e^{x}$
\end_inset

 ranges from 
\begin_inset Formula $0$
\end_inset

 to 
\begin_inset Formula $\infty$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Chi-Square PDF
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim N(0,1)$
\end_inset

, 
\begin_inset Formula $Y=X^{2}$
\end_inset

.
 The distribution of 
\begin_inset Formula $Y$
\end_inset

 is an example of a 
\series bold
Chi-Square distribution
\series default
.
 Find the PDF of 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Example
In this case, we can no longer apply the change of variables formula because
 
\begin_inset Formula $g(x)=x^{2}$
\end_inset

 is not one-to-one.
 Instead, we use the CDF:
\begin_inset Formula 
\[
F_{Y}(y)=P(X^{2}\leq y)=P(-\sqrt{y}\leq X\leq\sqrt{y})=\Phi(\sqrt{y})-\Phi(-\sqrt{y})=2\Phi(\sqrt{y})-1
\]

\end_inset

Therefore, 
\begin_inset Formula 
\[
f_{Y}(y)=2\varphi(\sqrt{y})\cdot\frac{1}{2}y^{-1/2}=\varphi(\sqrt{y})y^{-1/2},\quad y>0.
\]

\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $\mathbf{X}=(X_{1},\dots,X_{n})$
\end_inset

 be a continuous random vector with joint PDF 
\begin_inset Formula $f_{\mathbf{X}}$
\end_inset

, and let 
\begin_inset Formula $\mathbf{Y}=g(\mathbf{X})$
\end_inset

 where 
\begin_inset Formula $g$
\end_inset

 is an invertible function from 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

 to 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

.
 Let 
\begin_inset Formula $\mathbf{y}=g(\mathbf{x})$
\end_inset

.
 Define the Jacobian matrix:
\begin_inset Formula 
\[
\frac{\partial\mathbf{x}}{\partial\mathbf{y}}=\begin{pmatrix}\frac{\partial x_{1}}{\partial y_{1}} & \frac{\partial x_{1}}{\partial y_{2}} & \dots & \frac{\partial x_{1}}{\partial y_{n}}\\
\vdots & \vdots &  & \vdots\\
\frac{\partial x_{n}}{\partial y_{1}} & \frac{\partial x_{n}}{\partial y_{2}} & \dots & \frac{\partial x_{n}}{\partial y_{n}}
\end{pmatrix}.
\]

\end_inset

Also assume that the determinant of the Jacobian matrix is never 0.
 Then the joint PDF of 
\begin_inset Formula $\mathbf{Y}$
\end_inset

 is
\begin_inset Formula 
\[
f_{\mathbf{Y}}(\mathbf{y})=f_{\mathbf{X}}(\mathbf{x})\left|\frac{\partial\mathbf{x}}{\partial\mathbf{y}}\right|,
\]

\end_inset

where 
\begin_inset Formula $\left|\frac{\partial\mathbf{x}}{\partial\mathbf{y}}\right|$
\end_inset

 is the absolute value of the determinant of the Jacobian matrix.
\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X,Y\overset{iid}{\sim}Expo(1)$
\end_inset

.
 Find the distribution of 
\begin_inset Formula $X/(X+Y)$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Solution
\emph default
: Let 
\begin_inset Formula $U=\frac{X}{X+Y}$
\end_inset

, 
\begin_inset Formula $V=X+Y$
\end_inset

.
 Then 
\begin_inset Formula $X=UV$
\end_inset

, 
\begin_inset Formula $Y=V-UV$
\end_inset

.
 The determinant of the Jacobian matrix is 
\begin_inset Formula 
\[
\left|\frac{\partial(x,y)}{\partial(u,v)}\right|=\left|\begin{array}{cc}
v & u\\
-v & 1-u
\end{array}\right|=v
\]

\end_inset

Thus, the joint distribution of 
\begin_inset Formula $(U,V)$
\end_inset

 is 
\begin_inset Formula 
\[
f_{UV}(u,v)=f_{XY}(x,y)|v|=f_{X}(x)f_{Y}(y)v=e^{-(x+y)}v=e^{-v}v.
\]

\end_inset

The distribution of 
\begin_inset Formula $X/(X+Y)$
\end_inset

 is equivalent to the marginal distribution of 
\begin_inset Formula $U$
\end_inset

: 
\begin_inset Formula 
\[
f_{U}(u)=\int_{0}^{\infty}e^{-v}vdv=1
\]

\end_inset

for 
\begin_inset Formula $0\leq u\leq1$
\end_inset

.
 Hence 
\begin_inset Formula $U$
\end_inset

 is a Uniform distribution over [0,1].
\end_layout

\begin_layout Chapter
Sampling distribution
\end_layout

\begin_layout Section
Samples and statistics
\end_layout

\begin_layout Standard
We model real-world uncertain events with random variables.
 We have also introduced various distributions suitable to model different
 kinds of events.
 However, we never observe the full distribution or the true parameters
 of the assumed distribution.
 Instead, we only observe a sample of that random variable.
 We can only infer the properties of the distribution from a limited sample.
 For example, suppose we model the hight of an Asian women with a normal
 distribution.
 But we never know exactly what the mean and variance are.
 We can only observe a sample of the distribution.
\end_layout

\begin_layout Standard
In statistics, the conceptual distribution 
\begin_inset Formula $F$
\end_inset

 is called the 
\series bold
population distribution
\series default
, or just the 
\series bold
population
\series default
.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
This section is based on Bruce Hansen's 
\emph on
Probability and Statistics for Economists
\emph default
.
\end_layout

\end_inset

 It is tempting to think of the population as all the observations (e.g.
 all the population on the planet), but this is not exactly correct.
 The population distribution is more of a mathematical abstraction or an
 assumption.
 Suppose we are modeling the height of human being, even if we have all
 the observations on the planet, that does not include the people that have
 died or yet to be born.
 Thus, it is still a sample of the assumed distribution.
 
\end_layout

\begin_layout Standard
A collection of random variables 
\begin_inset Formula $\{X_{1},X_{2},\dots,X_{n}\}$
\end_inset

 is a 
\series bold
random sample
\series default
 from the population 
\begin_inset Formula $F$
\end_inset

 if 
\begin_inset Formula $X_{i}$
\end_inset

 are 
\series bold
independent and identically distributed (
\emph on
i.i.d
\emph default
)
\series default
 with distribution 
\begin_inset Formula $F$
\end_inset

.
 What we mean by 
\emph on
i.i.d
\emph default
 is that 
\begin_inset Formula $X_{1},\dots,X_{n}$
\end_inset

 are mutually independent and have exactly the same distribution 
\begin_inset Formula $X_{i}\sim F$
\end_inset

.
 Survey sampling is an useful metaphor to understand random sampling, in
 which we randomly select a subset of the population with equal probability.
 The 
\series bold
sample size
\series default
 
\begin_inset Formula $n$
\end_inset

 is the number of individuals in the sample.
\end_layout

\begin_layout Standard
A 
\series bold
data set
\series default
 is a collection of numbers, typically organized by observation.
 We sometimes call a data set also as a sample.
 But it should not be confused with the random sample defined above.
 As the former is a collection of random variables, whereas the latter is
 one 
\series bold
realization
\series default
 of the random variables.
 
\end_layout

\begin_layout Standard
Typically, we will use 
\begin_inset Formula $X$
\end_inset

 without the subscript to denote a random variable or vector with distribution
 
\begin_inset Formula $F$
\end_inset

, 
\begin_inset Formula $X_{i}$
\end_inset

 with a subscript to denote a random observation in the sample, and 
\begin_inset Formula $x_{i}$
\end_inset

 or 
\begin_inset Formula $x$
\end_inset

 to denote a speciﬁc or realized value.
\end_layout

\begin_layout Standard
The problem of 
\series bold
statistical inference
\series default
 is to learn about the underlying process — the population distribution
 or data generating process — by examining the observations.
 In most cases, we assume the population distribution and want to learn
 about the its parameters (e.g.
 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 in the normal distribution).
 As a convention, we use greek letters to denote population parameters.
\end_layout

\begin_layout Standard
A 
\series bold
statistic
\series default
 is a function of the random sample 
\begin_inset Formula $\{X_{1},X_{2},\dots,X_{n}\}$
\end_inset

.
 Recall that there is a distinction between random variables and their realizati
ons.
 Similarly there is a distinction between a statistic as a function of a
 random sample — and is therefore a random variable as well — and a statistic
 as a function of the realized sample, which is a realized value.
 When we treat a statistic as random we are viewing it is a function of
 a sample of random variables.
 When we treat it as a realized value we are viewing it as a function of
 a set of realized values.
 One way of viewing the distinction is to think of “before viewing the data”
 and “after viewing the data”.
 When we think about a statistic “before viewing” we do not know what value
 it will take.
 From our vantage point it is unknown and random.
 After viewing the data and speciﬁcally after computing and viewing the
 statistic the latter is a speciﬁc number and is therefore a realization.
 It is what it is and it is not changing.
 The randomness is the process by which the data was generated — and the
 understanding that if this process were repeated the sample would be different
 and the speciﬁc realization would be therefore different.
 The distribution of a statistic is called the 
\series bold
sampling distribution
\series default
, since it is the distribution induced by sampling.
 
\end_layout

\begin_layout Standard
An 
\series bold
estimator
\series default
 
\begin_inset Formula $\hat{\theta}$
\end_inset

 for a population parameter 
\begin_inset Formula $\theta$
\end_inset

 is a statistic intended to infer 
\begin_inset Formula $\theta$
\end_inset

.
 It is conventional to use the hat notation 
\begin_inset Formula $\hat{\theta}$
\end_inset

 to denote an estimator.
 Note that 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is a statistic and hence also a random variable.
 We call 
\begin_inset Formula $\hat{\theta}$
\end_inset

 an 
\series bold
estimate
\series default
 when it is a specific value (or realized value) calculated in a specific
 sample.
 
\end_layout

\begin_layout Standard
A standard way to construct an estimator is by the analog principle.
 The idea is to express the parameter 
\begin_inset Formula $\theta$
\end_inset

 as a function of the population 
\begin_inset Formula $F$
\end_inset

, and then express the estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 as the analog function in the sample.
\end_layout

\begin_layout Standard
For example, suppose we want to construct an estimator for the population
 mean 
\begin_inset Formula $\mu=E(X)$
\end_inset

.
 By definition, if each value of 
\begin_inset Formula $X$
\end_inset

 is of equal probability, 
\begin_inset Formula $\mu$
\end_inset

 is simply the average.
 By analogy, we construct the 
\series bold
sample mean
\series default
 as 
\begin_inset Formula $\bar{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

.
 It is conventional to denote a sample average by the notation 
\begin_inset Quotes eld
\end_inset

X bar
\begin_inset Quotes erd
\end_inset

.
 Because it is an estimator for 
\begin_inset Formula $\mu$
\end_inset

, we also denote it as 
\begin_inset Formula $\hat{\mu}=\bar{X}_{n}$
\end_inset

.
 Note that from different samples we calculate different estimates.
 In one sample, 
\begin_inset Formula $\hat{\mu}=6.5$
\end_inset

; in another sample, 
\begin_inset Formula $\hat{\mu}=6.7$
\end_inset

.
 All of them are erroneous estimate of the true parameter 
\begin_inset Formula $\mu$
\end_inset

.
 The question is therefore how close they are to the true parameter.
 To answer this question, we need to study the distribution of the sample
 mean.
 
\end_layout

\begin_layout Section
Law of large numbers
\end_layout

\begin_layout Standard
We now introduce two important theorems describing the behavior of the sample
 mean as the sample size grows.
 Throughout this section and the next, we assume 
\begin_inset Formula $X_{1},X_{2},\dots,X_{n}$
\end_inset

 are i.i.d RVs drawn from a population with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 The sample mean is defined as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bar{X}_{n}=\frac{X_{1}+\cdots+X_{n}}{n}.
\]

\end_inset


\end_layout

\begin_layout Standard
As we have discussed previously, the sample mean is itself a random variable
 with mean and variance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
E(\bar{X}_{n}) & =\frac{1}{n}E(X_{1}+\cdots+X_{n})=\frac{1}{n}(E(X_{1})+\cdots+E(X_{n}))=\mu,\\
Var(\bar{X}_{n}) & =\frac{1}{n^{2}}Var(X_{1}+\cdots+X_{n})\overset{iid}{=}\frac{1}{n^{2}}(Var(X_{1})+\cdots+Var(X_{n}))=\frac{\sigma^{2}}{n}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The law of large numbers (LLN) says that as n grows, the sample mean 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 converges to the true mean 
\begin_inset Formula $\mu$
\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Strong law of large numbers
\end_layout

\end_inset

The sample mean 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 converges to the true mean 
\begin_inset Formula $\mu$
\end_inset

 point-wise as 
\begin_inset Formula $n\to\infty$
\end_inset

, with probability 
\begin_inset Formula $1$
\end_inset

.
 In other words, the event 
\begin_inset Formula $\bar{X}_{n}\to\mu$
\end_inset

 has probability 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Weak law of large numbers
\end_layout

\end_inset

For all 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $P(|\bar{X}_{n}-\mu|>\epsilon)\to0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
 (this is known as converge in probability).
\end_layout

\begin_layout Standard
We don't need a rigorous proof here.
 But an intuitive proof is obvious.
 As 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $Var(\bar{X}_{n})=\frac{\sigma^{2}}{n}\to0$
\end_inset

.
 The random variable 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 becomes fixed at 
\begin_inset Formula $\mu$
\end_inset

 as 
\begin_inset Formula $n$
\end_inset

 becomes large.
 Thus, it converges to 
\begin_inset Formula $\mu$
\end_inset

 in a probabilistic sense.
 
\end_layout

\begin_layout Standard
It seems that the LLN just states the obvious.
 But it has wide applications in daily time that you might not even realize.
 What it says is essentially this: the uncertainty at the individual level
 becomes certain when aggregating together; the risks that are unmanageable
 at the individual level becomes manageable collectively.
 Think about a rare disease, it happens at 1 out of a million probability.
 For each individual, no one knows if they will get the disease or not.
 But as the sample size gets large, suppose we have one billion population,
 the LLN says the sample mean will be very close the true mean.
 That is, there will be almost surely 1000 people being infected by the
 disease.
 We provide two more examples.
 
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Lottery
\end_layout

\end_inset

A lottery company is designing a game with a 6-digit format.
 Each time someone buys a ticket, they receive a randomly generated 6-digit
 number.
 Only one number will win the grand prize of 10 million dollars.
 What should the company charge per ticket to break even?
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
The probability of winning the game is 
\begin_inset Formula $p=1/10^{6}$
\end_inset

.
 Suppose the company has sold 
\begin_inset Formula $n$
\end_inset

 tickets.
 The price for each ticket is 
\begin_inset Formula $x$
\end_inset

.
 The revenue for the company is therefore 
\begin_inset Formula $xn$
\end_inset

.
 By the LLN, the cost of the company should be very close to 
\begin_inset Formula $10^{7}np$
\end_inset

.
 The break even point is 
\begin_inset Formula $xn=10^{7}np$
\end_inset

.
 So 
\begin_inset Formula $x=10^{7}p=10$
\end_inset

.
 Therefore, if the company sells each ticket above 10 dollars.
 The business is surely profitable as long as 
\begin_inset Formula $n$
\end_inset

 is large.
 If the company is a monopoly, it can reap as much profit as it desires
 as long as they know the basic probability theory! The same can be said
 about gambling companies.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Insurance
\end_layout

\end_inset

Insurance is anther great application of the LLN.
 It is essentially the same as the the lottery game but most people do not
 realize it.
 Suppose there is a disease with infection rate of 1 out of 1 million.
 The medical expenditure to cure the disease is 10 million dollars.
 How much the insurance company should charge per customer to cover this
 disease? 
\end_layout

\begin_layout Example

\emph on
Solution: 
\emph default
The solution is essentially the same as above.
 Suppose the premium for the insurance product is 
\begin_inset Formula $x$
\end_inset

.
 The revenue of the company by selling the premium is 
\begin_inset Formula $xn$
\end_inset

.
 The cost is — when one customer is infected, the company has to pay the
 medical cost —
\begin_inset Formula $10^{7}np$
\end_inset

.
 The break even price for the insurance premium is thus 
\begin_inset Formula $10$
\end_inset

 dollars.
 
\end_layout

\begin_layout Example
What is the implication of this insurance? Without the insurance, each individua
l either chooses to set aside 10 million dollars pre-cautiously for the
 disease (if he is rich enough) or be exposed to the risk completely uncovered.
 The insurance product enables everyone to get covered at a cost of just
 10 dollars.
 It is a typical example that the unmanageable risk at the individual level
 becomes manageable collectively.
 
\end_layout

\begin_layout Section
Central limit theorem
\end_layout

\begin_layout Standard
The LLN shows the convergence of the sample mean to the population mean.
 What about the entire sample distribution? This is addressed by the central
 limit theorem (CLT), which, as its name suggests, is a limit theorem of
 
\series bold
central importance
\series default
 in statistics.
\end_layout

\begin_layout Standard
The CLT states that for large 
\begin_inset Formula $n$
\end_inset

, the distribution of 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 after standardization approaches a standard Normal distribution, regardless
 of the underlying distribution of 
\begin_inset Formula $X_{i}$
\end_inset

.
 By 
\series bold
standardization
\series default
, we mean that we subtract 
\begin_inset Formula $\mu$
\end_inset

, the expected value of 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

, and divide by 
\begin_inset Formula $\sigma/\sqrt{n}$
\end_inset

, the standard deviation of 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

.
 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Central limit theorem
\end_layout

\end_inset

As 
\begin_inset Formula $n\to\infty$
\end_inset

,
\begin_inset Formula 
\[
\sqrt{n}\left(\frac{\bar{X}_{n}-\mu}{\sigma}\right)\to N(0,1)\textrm{ in distribution.}
\]

\end_inset


\end_layout

\begin_layout Theorem
In other words, the CDF of the left-hand side approaches the CDF of the
 standard normal distribution.
 
\end_layout

\begin_layout Proof
We will prove the CLT assuming the MGF of the 
\begin_inset Formula $X_{i}$
\end_inset

 exists, though the theorem holds under much weaker conditions.
 Without loss of generality let 
\begin_inset Formula $\mu=1,\sigma^{2}=1$
\end_inset

 (since we standardize it anyway).
 We show that the MGF of 
\begin_inset Formula $\sqrt{n}\bar{X}_{n}=(X_{1}+\cdots+X_{n})/\sqrt{n}$
\end_inset

 converges to the MGF of the 
\begin_inset Formula $N(0,1)$
\end_inset

.
 
\end_layout

\begin_layout Proof
The MGF of 
\begin_inset Formula $N(0,1)$
\end_inset

 is
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
E(e^{tX}) & =\int_{-\infty}^{\infty}e^{tx}\cdot\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}dx\\
 & =\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2+tx}dx\\
 & =\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(x-t)^{2}+\frac{1}{2}t^{2}}dx\\
 & =e^{\frac{t^{2}}{2}}\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(x-t)^{2}}dx\\
 & =e^{t^{2}/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Compute the MGF of 
\begin_inset Formula $\sqrt{n}\bar{X}_{n}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
E(e^{\sqrt{n}\bar{X}_{n}}) & =E(e^{t(X_{1}+\cdots+X_{n})/\sqrt{n}})\\
 & =E(e^{tX_{1}/\sqrt{n}})E(e^{tX_{2}/\sqrt{n}})\cdots E(e^{tX_{n}/\sqrt{n}})\\
 & =\left[E(e^{tX_{i}/\sqrt{n}})\right]^{n}\qquad\textrm{since }i.i.d\\
 & =\left[E\left(1+\frac{tX_{i}}{\sqrt{n}}+\frac{t^{2}X_{i}^{2}}{2n}+o(n^{-1})\right)\right]^{n}\\
 & =\left[1+\frac{t}{\sqrt{n}}E(X_{i})+\frac{t^{2}}{2n}E(X_{i}^{2})+o(n^{-1})\right]^{n}\\
 & =\left[1+\frac{t^{2}}{2n}+o(n^{-1})\right]^{n}\\
 & =\left[1+\frac{t^{2}/2}{n}+o(n^{-1})\right]^{n}\\
 & \to e^{t^{2}/2}\qquad\textrm{as }n\to\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, the MGF of 
\begin_inset Formula $\sqrt{n}\bar{X}_{n}$
\end_inset

 approaches the MGF of the standard normal.
 Since MGF determines the distribution, the distribution of 
\begin_inset Formula $\sqrt{n}\bar{X}_{n}$
\end_inset

 also approaches the standard normal distribution.
\end_layout

\begin_layout Standard
The CLT tells us about the limiting distribution of 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
 That means, we can reasonably approximate the distribution 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 with normal distribution when 
\begin_inset Formula $n$
\end_inset

 is a finite large number —
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bar{X}_{n}\approx N(\mu,\sigma^{2}/n)\quad\textrm{for large }n.
\]

\end_inset


\end_layout

\begin_layout Standard
The Central Limit Theorem was first proved by Pierre-Simon Laplace in 1810.
 Let's take a moment to admire the generality of this result.
 The distribution of the individual 
\begin_inset Formula $X_{i}$
\end_inset

 can be anything in the world, as long as the mean and variance are finite.
 This does mean the distribution of 
\begin_inset Formula $X_{i}$
\end_inset

 is irrelevant, however.
 If the distribution is fairly close to normal, the result would hold for
 smaller 
\begin_inset Formula $n$
\end_inset

.
 If the distribution is far away from normal, it would take larger 
\begin_inset Formula $n$
\end_inset

 to converge.
\end_layout

\begin_layout Standard
The CLT gives the distribution of the sample mean regardless of the underlying
 distribution.
 This allows to assess the 
\begin_inset Quotes eld
\end_inset

quality
\begin_inset Quotes erd
\end_inset

 of the sample mean — how close it is to the true mean.
 The LLN tells us the larger the sample, the closer the sample mean to the
 population mean.
 The CLT tells us the distribution of the sample mean for sample size 
\begin_inset Formula $n$
\end_inset

.
 For smaller 
\begin_inset Formula $n$
\end_inset

, the distribution is more spread-out (a normal distribution with large
 
\begin_inset Formula $\sigma^{2}$
\end_inset

); hence the uncertainty is huge, other values are more likely.
 For larger 
\begin_inset Formula $n$
\end_inset

, the uncertainty is reduced, most values would be centered around the true
 mean.
 We will delve deeper into this when we get to hypothesis testing.
 
\end_layout

\begin_layout Example
Suppose that a fair coin is tossed 900 times.
 Approximate the probability of obtaining more than 395 heads.
 
\end_layout

\begin_layout Example

\emph on
Solution:
\emph default
 Let 
\begin_inset Formula $H=\sum_{i=1}^{900}X_{i}$
\end_inset

 be the number of heads, where 
\begin_inset Formula $X_{i}\sim\textrm{Bern}(\frac{1}{2})$
\end_inset

.
 We could compute the probability by
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(H>495)=\sum_{k=496}^{900}\binom{900}{k}\left(\frac{1}{2}\right)^{k}\left(\frac{1}{2}\right)^{900-k}
\]

\end_inset


\end_layout

\begin_layout Example
But this is quite tedious.
 Because 
\begin_inset Formula $n=900$
\end_inset

 is reasonably large, we can apply the CLT: 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{1}{n}\sum_{i=1}^{900}X_{i} & \sim N(\mu,\sigma^{2}/n)\quad\textrm{or}\\
\sum_{i=1}^{900}X_{i} & \sim N(n\mu,n\sigma^{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We know 
\begin_inset Formula $\mu=E(X_{i})=\frac{1}{2}$
\end_inset

, 
\begin_inset Formula $\sigma^{2}=Var(X_{i})=\frac{1}{4}$
\end_inset

.
 Thus 
\begin_inset Formula $H\sim N(450,225)$
\end_inset

.
 Therefore,
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
P(H>495)=1-P(H\leq495)\approx1-\Phi\left(\frac{495-450}{15}\right)=0.0013.
\]

\end_inset


\end_layout

\begin_layout Section
Estimator accuracy
\end_layout

\begin_layout Standard
The central question of statistics is we want to learn about the population
 from a finite sample.
 We know sample mean is different from the population mean.
 But we also want to know how large the error could be, that is, how far
 or close the sample mean is from the true population mean.
 The question is exceedingly difficult to answer because the population
 mean is unknown.
 Fortunately, with the help of the CLT, we can say more about the distribution
 of the sample mean.
 This chapter bridges our probability theory with statistics.
 We use the theorems we have derived to infer the properties of a statistic.
 
\end_layout

\begin_layout Standard
As the purpose of statistics is to learn about the population, we want our
 sample estimator to be as good as possible.
 But what is a 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 estimator? This section we discuss two properties that we usually demand
 from a good estimator, namely, unbiasedness and consistency.
 Next section will tackle the more challenging concept of confidence interval.
 
\end_layout

\begin_layout Definition
The 
\series bold
bias
\series default
 of an estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 of a parameter 
\begin_inset Formula $\theta$
\end_inset

 is
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\textrm{Bias}[\hat{\theta}]=E(\hat{\theta})-\theta.
\]

\end_inset


\end_layout

\begin_layout Definition
We say that an estimator is 
\series bold
biased
\series default
 if its sampling is incorrectly centered.
 We say that an estimator is 
\series bold
unbiased
\series default
 is the bias is zero.
 
\end_layout

\begin_layout Theorem
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 is 
\series bold
unbiased
\series default
 for 
\begin_inset Formula $\mu=E(x)$
\end_inset

 if 
\begin_inset Formula $E(X)<\infty$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
E(\bar{X}_{n})=E\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)=\frac{1}{n}\sum_{i=1}^{n}E(X_{i})=\frac{1}{n}\sum_{i=1}^{n}\mu=\mu.
\]

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is an unbiased estimator of 
\begin_inset Formula $\theta$
\end_inset

, then 
\begin_inset Formula $\hat{\beta}=a\hat{\theta}+b$
\end_inset

 is an unbiased estimator of 
\begin_inset Formula $\beta=a\theta+b$
\end_inset

.
\end_layout

\begin_layout Standard
But obtaining an unbiased estimator is not always as straightforward as
 it seems.
 Consider the sample variance as an estimator for the population variance.
 By the analog principle, the sample variance should be 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{\sigma}^{2} & =\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}\\
 & =\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu+\mu-\bar{X_{n}})^{2}\\
 & =\frac{1}{n}\sum(X_{i}-\mu)^{2}+\frac{2}{n}\sum(X_{i}-\mu)(\mu-\bar{X_{n}})+\frac{1}{n}\sum(\mu-\bar{X_{n}})^{2}\\
 & =\frac{1}{n}\sum(X_{i}-\mu)^{2}+2(\bar{X_{n}}-\mu)(\mu-\bar{X_{n}})+(\mu-\bar{X_{n}})^{2}\\
 & =\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\mu)^{2}-(\bar{X}_{n}-\mu)^{2}\\
 & =\tilde{\sigma}^{2}-(\bar{X}_{n}-\mu)^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We know that 
\begin_inset Formula 
\[
E(\tilde{\sigma}^{2})=\frac{1}{n}\sum_{i=1}^{n}E(X_{i}-\mu)^{2}=\sigma^{2}
\]

\end_inset

Thus, if we compute the bias of this estimator:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
E[\hat{\sigma}^{2}] & =\sigma^{2}-\frac{\sigma^{2}}{n}=\left(1-\frac{1}{n}\right)\sigma^{2}\\
\textrm{Bias}[\hat{\sigma}^{2}] & =-\frac{\sigma^{2}}{n}\neq0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Therefore, the estimator 
\begin_inset Formula $\hat{\sigma}^{2}$
\end_inset

 is a biased estimator for 
\begin_inset Formula $\sigma^{2}$
\end_inset

! To correct the bias, we divide the sample sum of squares by 
\begin_inset Formula $(n-1)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s^{2}=\frac{n}{n-1}\hat{\sigma}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
It is straightforward to see that 
\begin_inset Formula $s^{2}$
\end_inset

 is an unbiased estimator for 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 We call 
\begin_inset Formula $s^{2}$
\end_inset

 the 
\series bold
bias-corrected variance estimator
\series default
.
\end_layout

\begin_layout Theorem
\begin_inset Formula $s^{2}$
\end_inset

 is an unbiased estimator for 
\begin_inset Formula $\sigma^{2}$
\end_inset

 if 
\begin_inset Formula $E(X^{2})<\infty$
\end_inset

.
\end_layout

\begin_layout Definition
The mean square error of an estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 for 
\begin_inset Formula $\theta$
\end_inset

 is 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\textrm{MSE}[\hat{\theta}]=E\left[(\hat{\theta}-\theta)^{2}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
By expanding the square we find that 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\textrm{MSE}[\hat{\theta}] & =E\left[(\hat{\theta}-\theta)^{2}\right]\\
 & =E\left[(\hat{\theta}-E[\hat{\theta}]+E[\hat{\theta}]-\theta)^{2}\right]\\
 & =E\left[(\hat{\theta}-E[\hat{\theta}])^{2}\right]+2E(\hat{\theta}-E[\hat{\theta}])(E[\hat{\theta}]-\theta)+(E[\hat{\theta}]-\theta)^{2}\\
 & =Var[\hat{\theta}]+(\textrm{Bias}[\hat{\theta}])^{2}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus the MSE is the variance plus the squared bias.
 The MSE as a measure of accuracy combines the variance and bias.
 
\end_layout

\begin_layout Theorem
For any estimator with a finite variance, we have 
\begin_inset Formula 
\[
\textrm{MSE}[\hat{\theta}]=Var[\hat{\theta}]+(\textrm{Bias}[\hat{\theta}])^{2}.
\]

\end_inset


\end_layout

\begin_layout Definition
An estimator is 
\series bold
consistent
\series default
 if 
\begin_inset Formula $\textrm{MSE}[\hat{\theta}]\to0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
\end_layout

\begin_layout Standard
Bias is the property of an estimator for finite samples.
 Consistency is the property of an estimator when the sample size gets large.
 It means that for any given data distribution, there is a sample size 
\begin_inset Formula $n$
\end_inset

 sufﬁciently large such that the estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 will be arbitrarily close to the true value 
\begin_inset Formula $\theta$
\end_inset

 with high probability.
 In practice, we usually do not know how large this 
\begin_inset Formula $n$
\end_inset

 has to be.
 But it is a desirable property for an estimator to be considered a “good”
 estimator.
\end_layout

\begin_layout Standard
For unbiased estimator, MSE is solely determined by the variance of the
 estimator.
 Recall that the variance for the sample mean is 
\begin_inset Formula $Var(\bar{X}_{n})=\sigma^{2}/n$
\end_inset

.
 But this is not a very useful formula because the it depends on unknown
 parameter 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 We need to replace these unknown parameters by estimators.
 To put the latter in the same units as the parameter estimate we typically
 take the square root before reporting.
 We thus arrive at the following concept.
\end_layout

\begin_layout Definition
A 
\series bold
standard error
\series default
 of an estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is defined as 
\begin_inset Formula 
\[
SE(\hat{\theta})=\hat{V}^{1/2}
\]

\end_inset

 where 
\begin_inset Formula $\hat{V}$
\end_inset

 is the estimator for 
\begin_inset Formula $Var[\hat{\theta}]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The 
\series bold
standard error
\series default
 for 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 is
\begin_inset Formula 
\[
SE(\bar{X}_{n})=\frac{s}{\sqrt{n}}
\]

\end_inset

where 
\begin_inset Formula $s$
\end_inset

 is the bias-corrected estimator for 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Note the difference between 
\series bold
standard error
\series default
 and 
\series bold
standard deviation
\series default
.
 Standard deviation describes the dispersion of a distribution.
 Standard error is the standard deviation of an 
\emph on
estimator
\emph default
.
 It indicates the 
\begin_inset Quotes eld
\end_inset

precision
\begin_inset Quotes erd
\end_inset

 of the estimator, thereby carrying a sense of 
\begin_inset Quotes eld
\end_inset

error
\begin_inset Quotes erd
\end_inset

.
 The smaller the standard error, the more precise the estimator.
 
\end_layout

\begin_layout Section
Confidence intervals
\end_layout

\begin_layout Standard
Confidence intervals provide a method of adding more information to an estimator
 
\begin_inset Formula $\hat{\theta}$
\end_inset

 when we wish to estimate an unknown parameter 
\begin_inset Formula $\theta$
\end_inset

.
 We can find an interval 
\begin_inset Formula $(A,B)$
\end_inset

 that we think has high probability of containing 
\begin_inset Formula $\theta$
\end_inset

.
 The length of such an interval gives us an idea of how closely we can estimate
 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Definition
A 
\begin_inset Formula $100(1-\alpha)\%$
\end_inset

 
\series bold
confidence interval (CI)
\series default
 for 
\begin_inset Formula $\theta$
\end_inset

 is an interval 
\begin_inset Formula $[L(\theta),U(\theta)]$
\end_inset

 such that the probability that the interval contains the true 
\begin_inset Formula $\theta$
\end_inset

 is 
\begin_inset Formula $(1-\alpha)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Due to randomness we rarely seek a conﬁdence interval with 100% coverage
 as this would typically need to be the entire parameter space.
 Instead we seek an interval which includes the true value with reasonably
 high probability.
 Standard choices are 
\begin_inset Formula $\alpha=0.05$
\end_inset

 and 
\begin_inset Formula $0.10$
\end_inset

, corresponding to 95% and 90% conﬁdence.
\end_layout

\begin_layout Standard
Conﬁdence intervals are reported to indicate the degree of precision of
 our estimates.
 The narrower the confidence interval, the more precise the estimate.
 Because a small range of values contains the true parameter with high probabili
ty.
 
\end_layout

\begin_layout Standard
With the help of the CLT, it is not hard to find the CI for the sample mean
 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

.
 Let's set 
\begin_inset Formula $\alpha=5\%$
\end_inset

, that is, we are trying to find the CI that contains the true mean 95%
 of the times.
 Assume our sample size 
\begin_inset Formula $n$
\end_inset

 is large enough to invoke the CLT, we thus have 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{\bar{X}_{n}-\mu}{\sigma/\sqrt{n}} & \sim N(0,1)
\end{align*}

\end_inset

Let's find the interval 
\begin_inset Formula $[a,b]$
\end_inset

 such that
\begin_inset Formula 
\[
P\left(a\leq\frac{\bar{X}_{n}-\mu}{\sigma/\sqrt{n}}\leq b\right)=1-2\Phi(L)=0.95
\]

\end_inset


\end_layout

\begin_layout Standard
since the normal distribution is symmetric, 
\begin_inset Formula $b=-a$
\end_inset

.
 By looking at the CDF of standard normal, we get 
\begin_inset Formula $a=-1.96$
\end_inset

, 
\begin_inset Formula $b=1.96$
\end_inset

.
 Thus,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(-1.96\leq\frac{\bar{X}_{n}-\mu}{\sigma/\sqrt{n}}\leq1.96\right)=0.95
\]

\end_inset


\end_layout

\begin_layout Standard
With a little rearrangement, we have 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(\bar{X}_{n}-1.96\frac{\sigma}{\sqrt{n}}\leq\mu\leq\bar{X}_{n}+1.96\frac{\sigma}{\sqrt{n}}\right)=0.95
\]

\end_inset

Therefore, the interval 
\begin_inset Formula $\left[\bar{X}_{n}-1.96\frac{\sigma}{\sqrt{n}},\bar{X}_{n}+1.96\frac{\sigma}{\sqrt{n}}\right]$
\end_inset

 contains the true mean 95% of the times.
 
\end_layout

\begin_layout Theorem
The 
\begin_inset Formula $100(1-\alpha)\%$
\end_inset

 confidence interval for the sample mean 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 is 
\begin_inset Formula $\bar{X}_{n}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$
\end_inset

, where 
\begin_inset Formula $z_{\alpha/2}$
\end_inset

 is the critical value such that 
\begin_inset Formula $\Phi(z_{\alpha/2})=\frac{\alpha}{2}$
\end_inset

.
\end_layout

\begin_layout Standard
In practice, because we do not know 
\begin_inset Formula $\sigma/\sqrt{n}$
\end_inset

, we replace it with the standard error 
\begin_inset Formula $s/\sqrt{n}$
\end_inset

.
 Thus, we compute the confidence interval as 
\begin_inset Formula $\bar{X}_{n}\pm z_{\alpha/2}SE$
\end_inset

.
 However, this replacement is not without risk.
 When the sample size is small, 
\begin_inset Formula $s$
\end_inset

 is a very poor estimate of 
\begin_inset Formula $\sigma$
\end_inset

.
 For the approximation to be valid, we require either the sample size is
 large enough (
\begin_inset Formula $n\geq30$
\end_inset

 at least) or the population distribution is nearly normal.
 Some commonly used confidence levels:
\end_layout

\begin_layout Itemize
90% CI: 
\begin_inset Formula $\alpha=0.1$
\end_inset

, 
\begin_inset Formula $z_{0.05}=1.645$
\end_inset

 
\end_layout

\begin_layout Itemize
95% CI: 
\begin_inset Formula $\alpha=0.05$
\end_inset

, 
\begin_inset Formula $z_{0.025}=1.96$
\end_inset

 
\end_layout

\begin_layout Itemize
99% CI: 
\begin_inset Formula $\alpha=0.01$
\end_inset

, 
\begin_inset Formula $z_{0.005}=2.58$
\end_inset


\end_layout

\begin_layout Standard
We go through some common misunderstandings about confidence intervals through
 an example.
 Suppose we have a sample fo size 50 with mean 3.2 and standard deviation
 1.74.
 We construct the 95% confidence interval as 
\begin_inset Formula 
\[
\bar{X}\pm1.96\times\frac{1.74}{\sqrt{50}}\approx3.2\pm0.5=(2.7,3.7).
\]

\end_inset


\end_layout

\begin_layout Standard
Now check the following interpretations (true or false):
\end_layout

\begin_layout Enumerate
We are 95% confident that the sample mean is between 2.7 and 3.7.
\end_layout

\begin_deeper
\begin_layout Standard
False.
 The CI definitely contains the sample mean 
\begin_inset Formula $\bar{X}$
\end_inset

.
 
\end_layout

\end_deeper
\begin_layout Enumerate
95% of the population observations are in 2.7 to 3.7.
\end_layout

\begin_deeper
\begin_layout Standard
False.
 The CI is about covering the population mean, not for covering 95% of the
 entire population.
 
\end_layout

\end_deeper
\begin_layout Enumerate
The true mean falls in the interval (2.7, 3.7) with probability 95%.
\end_layout

\begin_deeper
\begin_layout Standard
False.
 The true mean 
\begin_inset Formula $\mu$
\end_inset

 is a fixed number, not a random one that happens with a probability.
\end_layout

\end_deeper
\begin_layout Enumerate
If a new random sampleis taken, we are 95% confident that the new sample
 mean will be between 2.7 and 3.7.
\end_layout

\begin_deeper
\begin_layout Standard
False.
 The confidence interval is for covering the population mean, not for covering
 the mean of another sample.
\end_layout

\end_deeper
\begin_layout Enumerate
This confidence interval is not valid if the population or sample is not
 normally distributed.
 
\end_layout

\begin_deeper
\begin_layout Standard
False.
 The construction of the CI only uses the normality of the sampling distribution
 of the sample mean (by the CLT).
 Neither the population nor the sample is required to be normally distributed.
 
\end_layout

\end_deeper
\begin_layout Standard
So what is exactly the thing that has a 95% change to happen? 
\bar under
It is the procedure to construct the 95% interval.

\bar default
 About 95% of the intervals constructed following the procedure will cover
 the true population mean 
\begin_inset Formula $\mu$
\end_inset

.
 After taking the sample and an interval is constructed, the constructed
 interval either covers 
\begin_inset Formula $\mu$
\end_inset

 or it doesn't.
 But if we were able to take many such samples and reconstruct the interval
 many times, 95% of the intervals will contain the true mean.
 
\end_layout

\begin_layout Section
Hypothesis testing*
\end_layout

\begin_layout Standard
Confidence interval allows us to construct an interval estimate of a population
 parameter.
 Hypothesis testing allows us to test specific hypothesis about a population
 parameter with the evidence obtained from a sample.
 The earliest use of statistical hypothesis testing is generally credited
 to the question of whether male and female births are equally likely (null
 hypothesis), which was addressed in the 1700s by John Arbuthnot and later
 by Pierre-Simon Laplace.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $p$
\end_inset

 be the population ratio (defined as the ratio of boys to the total number
 of babies).
 We hypotheses that
\begin_inset Formula 
\[
H_{0}:p=0.5
\]

\end_inset

This is called the 
\series bold
null hypothesis
\series default
, which is the hypothesis we want to test.
 If the null hypothesis is false, we have
\begin_inset Formula 
\[
H_{1}:p\neq0.5
\]

\end_inset

This is called the 
\series bold
alternative hypothesis
\series default
.
 How am I able to test which hypothesis is true? I can answer this question
 by collecting a small sample.
 Suppose I have collected a sample of 
\begin_inset Formula $50$
\end_inset

 babies computed a sample ratio of 
\begin_inset Formula $\hat{p}=0.55$
\end_inset

.
 Does it prove or disprove the hypothesis? 
\end_layout

\begin_layout Standard
Note that the ratio 
\begin_inset Formula $\hat{p}$
\end_inset

 can be regarded as a sample mean.
 Let 
\begin_inset Formula $X_{i}$
\end_inset

 be a random variable that equals 
\begin_inset Formula $1$
\end_inset

 if the 
\begin_inset Formula $i$
\end_inset

-th baby is a boy and 
\begin_inset Formula $0$
\end_inset

 otherwise.
 Then, 
\begin_inset Formula $\hat{p}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

.
 The variance of 
\begin_inset Formula $\hat{p}$
\end_inset

 is given by 
\begin_inset Formula 
\[
Var(\hat{p})=\frac{1}{n^{2}}\sum_{i=1}^{n}Var(X_{i})=\frac{p(1-p)}{n}
\]

\end_inset

since 
\begin_inset Formula $X_{i}$
\end_inset

 is a Bernoulli random variable.
 By the Central Limit Theorem, we have 
\begin_inset Formula 
\[
\frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}}\to N(0,1)
\]

\end_inset

Suppose 
\begin_inset Formula $H_{0}$
\end_inset

 is true, then we know the distribution of 
\begin_inset Formula $\hat{p}$
\end_inset

.
 In particular, there is 95% chance that 
\begin_inset Formula $\hat{p}$
\end_inset

 would be in the interval 
\begin_inset Formula 
\[
p\pm1.96\sqrt{\frac{p(1-p)}{n}}=0.5\pm0.14
\]

\end_inset

Our observed sample mean 
\begin_inset Formula $\hat{p}=0.55$
\end_inset

 is not outrageous.
 It is well within this interval.
 
\bar under
That means the evidence is not against the null hypothesis.

\bar default
 It does not mean 
\begin_inset Formula $H_{0}$
\end_inset

 is true.
 But it is reasonable given we have observed a sample mean 
\begin_inset Formula $\hat{p}=0.55$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose we have observed 
\begin_inset Formula $\hat{p}=0.65$
\end_inset

.
 This piece of evidence does not seem to be consistent with the null hypothesis.
 Because if 
\begin_inset Formula $H_{0}$
\end_inset

 is true, we only have less than 5% chance of observing this sample mean.
 It is extremely unlikely.
 Based on this sample, we are more inclined to reject the 
\begin_inset Formula $H_{0}$
\end_inset

.
 Rejecting the null hypothesis does not mean it is false, 
\bar under
but it means our evidence does not support this hypothesis.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename img/siglevel.jpg
	width 60col%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset


\series bold
-value
\series default
: the probability of obtaining test results at least as extreme as the result
 actually observed, under the assumption that the null hypothesis is correct.
 A very small 
\begin_inset Formula $p$
\end_inset

-value means that such an extreme observed outcome would be very unlikely
 under the null hypothesis.
 Thus, 
\bar under
The smaller the 
\begin_inset Formula $p$
\end_inset

-value, the stronger the evidence against the 
\begin_inset Formula $H_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
In some studies, we can simply report the 
\begin_inset Formula $p$
\end_inset

-value and let people judge whether the evidence is strong enough.
 In other studies, we prefer to select a cut-off value 
\begin_inset Formula $\alpha$
\end_inset

, call the 
\series bold
significance level
\series default
, and follow the rule:
\end_layout

\begin_layout Itemize
If the 
\begin_inset Formula $p\textrm{-value}<\alpha$
\end_inset

, reject 
\begin_inset Formula $H_{0}$
\end_inset

; 
\end_layout

\begin_layout Itemize
If the 
\begin_inset Formula $p\textrm{-value}>\alpha$
\end_inset

, do not reject 
\begin_inset Formula $H_{0}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Commonly used significance levels: 
\begin_inset Formula $0.05$
\end_inset

 and 
\begin_inset Formula $0.01$
\end_inset

.
 And we like to use the word 
\begin_inset Quotes eld
\end_inset

significant
\begin_inset Quotes erd
\end_inset

 to describe the test result:
\end_layout

\begin_layout Itemize
A test with 
\begin_inset Formula $p\textrm{-value}<0.05$
\end_inset

 is said to be (statistically) 
\series bold
significant
\series default
;
\end_layout

\begin_layout Itemize
A test with 
\begin_inset Formula $p\textrm{-value}<0.01$
\end_inset

 is said to be highly 
\series bold
significant
\series default
.
\end_layout

\begin_layout Standard
When we make a decision about accepting or rejecting a hypothesis, there
 are chances that we make a mistake.
 There are two types of mistakes: 
\series bold
Type 1 error
\series default
 and 
\series bold
Type 2 error
\series default
.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Reject 
\begin_inset Formula $H_{0}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fail to reject 
\begin_inset Formula $H_{0}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Truth
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $H_{0}$
\end_inset

 is true
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Type 1 error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $H_{0}$
\end_inset

 is false
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\checkmark$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Type 2 error
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\series bold
Type 1 error
\series default
 is rejecting the 
\begin_inset Formula $H_{0}$
\end_inset

 when it is true.
 
\series bold
Type 2 error
\series default
 is failing to reject the 
\begin_inset Formula $H_{0}$
\end_inset

 when it is false.
 Usually, it is more important to control the Type 1 error than the the
 Type 2 error.
 That is, we want to minimize the chance of falsely rejecting the null hypothesi
s.
 
\end_layout

\begin_layout Standard
In the example above, we reject the null hypothesis on the ground that there
 is only 2.3% of the chance that we could observe this sample.
 Therefore, the probability of Type 1 error is only 2.3%.
 
\end_layout

\begin_layout Standard
If we make decisions based on a significance level, the significance level
 is the Type 1 error rate.
 In other words, when using a 5% significance level, there is 5% chance
 of making a Type 1 error.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(\textrm{Type 1 error}|H_{0}\textrm{ is true})=\alpha
\]

\end_inset


\end_layout

\begin_layout Standard
This is why we prefer small values of 
\begin_inset Formula $\alpha$
\end_inset

—smaller 
\begin_inset Formula $\alpha$
\end_inset

 reduces the Type 1 error rate.
 However, significance level doesn’t control Type 2 error rate.
\end_layout

\begin_layout Subsection*
Hypothesis testing with 
\begin_inset Formula $z$
\end_inset

-statistics
\end_layout

\begin_layout Standard
We may have noticed that, in the above example, the assumption that the
 population 
\begin_inset Formula $\sigma$
\end_inset

 is known is unrealistic.
 In practice, we approximate it with the standard error 
\begin_inset Formula $s/\sqrt{n}$
\end_inset

.
 The approximate is valid if the the sample size is large enough or the
 underlying distribution is nearly normal.
 If this is not the case, we would opt for a 
\begin_inset Formula $t$
\end_inset

-test.
 Here we summarize the steps of testing for a population mean with 
\begin_inset Formula $z$
\end_inset

-statistics.
 
\end_layout

\begin_layout Standard
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Enumerate
Set up the hypothesis: 
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $H_{0}:\mu=\mu_{0}$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $H_{1}:\mu<\textrm{or}>\textrm{or}\neq\mu_{0}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Check assumptions and conditions
\end_layout

\begin_deeper
\begin_layout Itemize
independent and identically distributed (
\begin_inset Formula $i.i.d$
\end_inset

)
\end_layout

\begin_layout Itemize
Nearly normal distribution or the sample size is large enough
\end_layout

\end_deeper
\begin_layout Enumerate
Compute the test statistic and the 
\begin_inset Formula $p$
\end_inset

-value: 
\begin_inset Formula 
\[
Z=\frac{\bar{X}-\mu}{s/\sqrt{n}}
\]

\end_inset

 
\end_layout

\begin_layout Enumerate
Make decision: 
\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $p\textrm{-value}<\alpha$
\end_inset

, reject 
\begin_inset Formula $H_{0}$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $p\textrm{-value}>\alpha$
\end_inset

, do not reject 
\begin_inset Formula $H_{0}$
\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
We notice that the 
\series bold
two-sided
\series default
 hypothesis tests are very closed related to the concept of confidence intervals.
 A two-sided test means we are interested in rejection regions on both sides
 of the tail distribution.
 Typically, the alternative hypothesis is 
\begin_inset Formula $H_{1}:\mu\neq\mu_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename img/twosides.png
	width 80col%

\end_inset


\end_layout

\begin_layout Standard
Suppose we are doing a hypothesis test under the significance level 
\begin_inset Formula $\alpha$
\end_inset

, the region of accepting the 
\begin_inset Formula $H_{0}$
\end_inset

 is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-z_{\alpha/2}\leq\frac{\bar{X}-\mu}{SE}\leq z_{\alpha/2}
\]

\end_inset


\end_layout

\begin_layout Standard
such that the rejection region (
\begin_inset Formula $p$
\end_inset

-value) has probability 
\begin_inset Formula $\alpha$
\end_inset

.
 This is equivalent to 
\begin_inset Formula 
\[
\bar{X}-z_{\alpha/2}SE\leq\mu\leq\bar{X}+z_{\alpha/2}SE
\]

\end_inset


\end_layout

\begin_layout Standard
which is exactly the 
\begin_inset Formula $100(1-\alpha)\%$
\end_inset

 confidence interval of 
\begin_inset Formula $\bar{X}$
\end_inset

.
 Therefore, for a two-sided test, we have the rule:
\end_layout

\begin_layout Itemize
Reject 
\begin_inset Formula $H_{0}$
\end_inset

 if 
\begin_inset Formula $\mu$
\end_inset

 is not in the 
\begin_inset Formula $100(1-\alpha)\%$
\end_inset

 CI: 
\begin_inset Formula $\bar{X}\pm z_{\alpha/2}SE$
\end_inset


\end_layout

\begin_layout Standard
We conclude this chapter by reiterating a couple of critical points that
 could be easily misunderstood.
 
\end_layout

\begin_layout Standard
Rejecting 
\begin_inset Formula $H_{0}$
\end_inset

 doesn’t means we are 100% sure that 
\begin_inset Formula $H_{0}$
\end_inset

 is false.
 We might make Type 1 errors.
 Setting a significance level just guarantee we won’t make Type 1 error
 too often.
\end_layout

\begin_layout Standard
Failing to reject 
\begin_inset Formula $H_{0}$
\end_inset

 does not necessarily mean 
\begin_inset Formula $H_{0}$
\end_inset

 is true.
 We could make a type 2 error when failing to reject 
\begin_inset Formula $H_{0}$
\end_inset

.
 Moreover, unlike type 1 error rate is controlled at a low level, type 2
 error rate is usually quite high.
 When we fail to reject 
\begin_inset Formula $H_{0}$
\end_inset

, it just means the data are not able to distinguish between 
\begin_inset Formula $H_{0}$
\end_inset

 and 
\begin_inset Formula $H_{1}$
\end_inset

.
 That's why we say 
\emph on
fail to reject
\emph default
.
 
\bar under

\begin_inset Formula $p$
\end_inset

-value is not the probability that the 
\begin_inset Formula $H_{0}$
\end_inset

 is true.
\end_layout

\begin_layout Standard
Saying that results are statistically significant just informs the reader
 that the findings are unlikely due to chance alone.
 However, it says nothing about the practical importance of the finding.
 For example, rejecting the 
\begin_inset Formula $H_{0}$
\end_inset

: 
\begin_inset Formula $\mu=\mu_{0}$
\end_inset

 does not tell us how big the difference 
\begin_inset Formula $|\mu-\mu_{0}|$
\end_inset

 is.
 Mostly in practice we care more about the magnitude of this difference,
 rather than the fact that they are indeed different.
 It is possible that the difference is too small to be relevant even if
 it is significant.
\end_layout

\begin_layout Subsection*
Hypothesis testing with 
\begin_inset Formula $t$
\end_inset

-statistics
\end_layout

\begin_layout Standard
When the sample size is small, we opt for 
\begin_inset Formula $t$
\end_inset

-test for more reliable hypothsis testing.
 Define test statistics
\begin_inset Formula 
\[
T=\frac{\bar{X}-\mu}{s/\sqrt{n}}
\]

\end_inset

where 
\begin_inset Formula $s$
\end_inset

 is the sample standard deviation.
 For small samples, this test statistics follows a Student 
\begin_inset Formula $t$
\end_inset

-distribution with 
\begin_inset Formula $n$
\end_inset

 degrees of freedom, 
\begin_inset Formula $T\sim t(n)$
\end_inset

.
\end_layout

\begin_layout Standard
Why Student-
\begin_inset Formula $t$
\end_inset

 distribution? Recall the definition of Student-
\begin_inset Formula $t$
\end_inset

 distribution: when the underlying distribution of 
\begin_inset Formula $X_{1},X_{2},\dots,X_{n}$
\end_inset

 is Normal, sample variance 
\begin_inset Formula $s^{2}$
\end_inset

 follows a 
\begin_inset Formula $\chi^{2}$
\end_inset

 distribution.
 
\begin_inset Formula $T$
\end_inset

 follows 
\begin_inset Formula $t$
\end_inset

 distribution by definition regardless of the sample size.
 However, if the underlying distribution is not normal, this argument loses
 ground.
 We use 
\begin_inset Formula $t$
\end_inset

-test mainly as a convention.
 But 
\begin_inset Formula $t$
\end_inset

 distribution has heavier tails than standard normal, meaning that we are
 more likely to reject a hypothesis based on 
\begin_inset Formula $t$
\end_inset

 distribution.
 In other words, 
\begin_inset Formula $t$
\end_inset

-test is a more conservative choice than 
\begin_inset Formula $z$
\end_inset

-test for small samples.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one-tail 
\begin_inset Formula $\alpha$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.025
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.005
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
two-tail 
\begin_inset Formula $\alpha$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
d.f.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.812
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.228
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.169
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.725
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.086
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.845
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.697
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.042
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.750
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $z$
\end_inset

 value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.645
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.960
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.576
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The table shows a few critical values for 
\begin_inset Formula $t$
\end_inset

-test with different degrees of freedom (d.f.).
 We can see as the sample size gets larger, 
\begin_inset Formula $t$
\end_inset

 distribution converges to standard normal.
 
\end_layout

\end_body
\end_document
